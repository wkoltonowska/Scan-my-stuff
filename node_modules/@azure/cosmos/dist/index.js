'use strict';

Object.defineProperty(exports, '__esModule', { value: true });

var crypto = require('crypto');
var logger$5 = require('@azure/logger');
var coreUtil = require('@azure/core-util');
var tslib = require('tslib');
var PriorityQueue = require('priorityqueuejs');
var semaphore = require('semaphore');
var stableStringify = require('fast-json-stable-stringify');
var coreRestPipeline = require('@azure/core-rest-pipeline');
var process$1 = require('node:process');
var JSBI = require('jsbi');
var abortController = require('@azure/abort-controller');
var keyvaultKeys = require('@azure/keyvault-keys');

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
const DEFAULT_PARTITION_KEY_PATH = "/_partitionKey"; // eslint-disable-line @typescript-eslint/prefer-as-const

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @hidden
 */
const Constants = {
    HttpHeaders: {
        Authorization: "authorization",
        ETag: "etag",
        MethodOverride: "X-HTTP-Method",
        Slug: "Slug",
        ContentType: "Content-Type",
        LastModified: "Last-Modified",
        ContentEncoding: "Content-Encoding",
        CharacterSet: "CharacterSet",
        UserAgent: "User-Agent",
        CustomUserAgent: "x-ms-useragent",
        IfModifiedSince: "If-Modified-Since",
        IfMatch: "If-Match",
        IfNoneMatch: "If-None-Match",
        ContentLength: "Content-Length",
        AcceptEncoding: "Accept-Encoding",
        KeepAlive: "Keep-Alive",
        CacheControl: "Cache-Control",
        TransferEncoding: "Transfer-Encoding",
        ContentLanguage: "Content-Language",
        ContentLocation: "Content-Location",
        ContentMd5: "Content-Md5",
        ContentRange: "Content-Range",
        Accept: "Accept",
        AcceptCharset: "Accept-Charset",
        AcceptLanguage: "Accept-Language",
        IfRange: "If-Range",
        IfUnmodifiedSince: "If-Unmodified-Since",
        MaxForwards: "Max-Forwards",
        ProxyAuthorization: "Proxy-Authorization",
        AcceptRanges: "Accept-Ranges",
        ProxyAuthenticate: "Proxy-Authenticate",
        RetryAfter: "Retry-After",
        SetCookie: "Set-Cookie",
        WwwAuthenticate: "Www-Authenticate",
        Origin: "Origin",
        Host: "Host",
        AccessControlAllowOrigin: "Access-Control-Allow-Origin",
        AccessControlAllowHeaders: "Access-Control-Allow-Headers",
        KeyValueEncodingFormat: "application/x-www-form-urlencoded",
        WrapAssertionFormat: "wrap_assertion_format",
        WrapAssertion: "wrap_assertion",
        WrapScope: "wrap_scope",
        SimpleToken: "SWT",
        HttpDate: "date",
        Prefer: "Prefer",
        Location: "Location",
        Referer: "referer",
        A_IM: "A-IM",
        // Query
        Query: "x-ms-documentdb-query",
        IsQuery: "x-ms-documentdb-isquery",
        IsQueryPlan: "x-ms-cosmos-is-query-plan-request",
        SupportedQueryFeatures: "x-ms-cosmos-supported-query-features",
        QueryVersion: "x-ms-cosmos-query-version",
        // Our custom Azure Cosmos DB headers
        Continuation: "x-ms-continuation",
        ContinuationToken: "x-ms-continuation-token",
        PageSize: "x-ms-max-item-count",
        ItemCount: "x-ms-item-count",
        ChangeFeedWireFormatVersion: "x-ms-cosmos-changefeed-wire-format-version",
        // Request sender generated. Simply echoed by backend.
        ActivityId: "x-ms-activity-id",
        CorrelatedActivityId: "x-ms-cosmos-correlated-activityid",
        PreTriggerInclude: "x-ms-documentdb-pre-trigger-include",
        PreTriggerExclude: "x-ms-documentdb-pre-trigger-exclude",
        PostTriggerInclude: "x-ms-documentdb-post-trigger-include",
        PostTriggerExclude: "x-ms-documentdb-post-trigger-exclude",
        IndexingDirective: "x-ms-indexing-directive",
        SessionToken: "x-ms-session-token",
        ConsistencyLevel: "x-ms-consistency-level",
        XDate: "x-ms-date",
        CollectionPartitionInfo: "x-ms-collection-partition-info",
        CollectionServiceInfo: "x-ms-collection-service-info",
        // Deprecated, use RetryAfterInMs instead.
        RetryAfterInMilliseconds: "x-ms-retry-after-ms",
        RetryAfterInMs: "x-ms-retry-after-ms",
        IsFeedUnfiltered: "x-ms-is-feed-unfiltered",
        ResourceTokenExpiry: "x-ms-documentdb-expiry-seconds",
        EnableScanInQuery: "x-ms-documentdb-query-enable-scan",
        EmitVerboseTracesInQuery: "x-ms-documentdb-query-emit-traces",
        EnableCrossPartitionQuery: "x-ms-documentdb-query-enablecrosspartition",
        ParallelizeCrossPartitionQuery: "x-ms-documentdb-query-parallelizecrosspartitionquery",
        ResponseContinuationTokenLimitInKB: "x-ms-documentdb-responsecontinuationtokenlimitinkb",
        SDKSupportedCapabilities: "x-ms-cosmos-sdk-supportedcapabilities",
        // QueryMetrics
        // Request header to tell backend to give you query metrics.
        PopulateQueryMetrics: "x-ms-documentdb-populatequerymetrics",
        // Response header that holds the serialized version of query metrics.
        QueryMetrics: "x-ms-documentdb-query-metrics",
        // IndexMetrics
        // Request header to tell backend to give you index metrics.
        PopulateIndexMetrics: "x-ms-cosmos-populateindexmetrics-V2",
        // Response header that holds the serialized version of index metrics.
        IndexUtilization: "x-ms-cosmos-index-utilization",
        // Version headers and values
        Version: "x-ms-version",
        // Owner name
        OwnerFullName: "x-ms-alt-content-path",
        // Owner ID used for name based request in session token.
        OwnerId: "x-ms-content-path",
        // Partition Key
        PartitionKey: "x-ms-documentdb-partitionkey",
        PartitionKeyRangeID: "x-ms-documentdb-partitionkeyrangeid",
        // Epk Range headers
        StartEpk: "x-ms-start-epk",
        EndEpk: "x-ms-end-epk",
        // Read Feed Type
        ReadFeedKeyType: "x-ms-read-key-type",
        // Quota Info
        MaxEntityCount: "x-ms-root-entity-max-count",
        CurrentEntityCount: "x-ms-root-entity-current-count",
        CollectionQuotaInMb: "x-ms-collection-quota-mb",
        CollectionCurrentUsageInMb: "x-ms-collection-usage-mb",
        MaxMediaStorageUsageInMB: "x-ms-max-media-storage-usage-mb",
        CurrentMediaStorageUsageInMB: "x-ms-media-storage-usage-mb",
        RequestCharge: "x-ms-request-charge",
        PopulateQuotaInfo: "x-ms-documentdb-populatequotainfo",
        MaxResourceQuota: "x-ms-resource-quota",
        // Offer header
        OfferType: "x-ms-offer-type",
        OfferThroughput: "x-ms-offer-throughput",
        AutoscaleSettings: "x-ms-cosmos-offer-autopilot-settings",
        // Custom RUs/minute headers
        DisableRUPerMinuteUsage: "x-ms-documentdb-disable-ru-per-minute-usage",
        IsRUPerMinuteUsed: "x-ms-documentdb-is-ru-per-minute-used",
        OfferIsRUPerMinuteThroughputEnabled: "x-ms-offer-is-ru-per-minute-throughput-enabled",
        // Index progress headers
        IndexTransformationProgress: "x-ms-documentdb-collection-index-transformation-progress",
        LazyIndexingProgress: "x-ms-documentdb-collection-lazy-indexing-progress",
        // Upsert header
        IsUpsert: "x-ms-documentdb-is-upsert",
        // Sub status of the error
        SubStatus: "x-ms-substatus",
        // StoredProcedure related headers
        EnableScriptLogging: "x-ms-documentdb-script-enable-logging",
        ScriptLogResults: "x-ms-documentdb-script-log-results",
        // Multi-Region Write
        ALLOW_MULTIPLE_WRITES: "x-ms-cosmos-allow-tentative-writes",
        // Bulk/Batch header
        IsBatchRequest: "x-ms-cosmos-is-batch-request",
        IsBatchAtomic: "x-ms-cosmos-batch-atomic",
        BatchContinueOnError: "x-ms-cosmos-batch-continue-on-error",
        // Dedicated Gateway Headers
        DedicatedGatewayPerRequestCacheStaleness: "x-ms-dedicatedgateway-max-age",
        DedicatedGatewayPerRequestBypassCache: "x-ms-dedicatedgateway-bypass-cache",
        // Cache Refresh header
        ForceRefresh: "x-ms-force-refresh",
        // Throughput related headers
        PriorityLevel: "x-ms-cosmos-priority-level",
        ThroughputBucket: "x-ms-cosmos-throughput-bucket",
        // Encryption Headers
        IsClientEncryptedHeader: "x-ms-cosmos-is-client-encrypted",
        IntendedCollectionHeader: "x-ms-cosmos-intended-collection-rid",
        DatabaseRidHeader: "x-ms-cosmos-database-rid",
        AllowCachedReadsHeader: "x-ms-cosmos-allow-cachedreads",
    },
    // ThrottledRequests Retry policy default values
    ThrottledRequestMaxRetryAttemptCount: 9,
    ThrottledRequestMaxWaitTimeInSeconds: 30,
    ThrottledRequestFixedRetryIntervalInMs: 0,
    // GlobalDB related constants
    WritableLocations: "writableLocations",
    ReadableLocations: "readableLocations",
    LocationUnavailableExpirationTimeInMs: 5 * 60 * 1000, // 5 minutes
    // ServiceDocument Resource
    ENABLE_MULTIPLE_WRITABLE_LOCATIONS: "enableMultipleWriteLocations",
    // Background refresh time
    DefaultUnavailableLocationExpirationTimeMS: 5 * 60 * 1000,
    // Client generated retry count response header
    ThrottleRetryCount: "x-ms-throttle-retry-count",
    ThrottleRetryWaitTimeInMs: "x-ms-throttle-retry-wait-time-ms",
    // Platform
    CurrentVersion: "2020-07-15",
    AzureNamespace: "Azure.Cosmos",
    AzurePackageName: "@azure/cosmos",
    SDKName: "azure-cosmos-js",
    SDKVersion: "4.3.0",
    // Diagnostics
    CosmosDbDiagnosticLevelEnvVarName: "AZURE_COSMOSDB_DIAGNOSTICS_LEVEL",
    // Bulk Operations
    DefaultMaxBulkRequestBodySizeInBytes: 220201,
    // Encryption
    Encryption: {
        DiagnosticsDecryptOperation: "Decrypt",
        DiagnosticsDuration: "Duration in milliseconds",
        DiagnosticsEncryptionDiagnostics: "EncryptionDiagnostics",
        DiagnosticsEncryptOperation: "Encrypt",
        DiagnosticsPropertiesEncryptedCount: "Properties Encrypted Count",
        DiagnosticsPropertiesDecryptedCount: "Properties Decrypted Count",
        DiagnosticsStartTime: "Start time",
    },
    Quota: {
        CollectionSize: "collectionSize",
    },
    Path: {
        Root: "/",
        DatabasesPathSegment: "dbs",
        CollectionsPathSegment: "colls",
        UsersPathSegment: "users",
        DocumentsPathSegment: "docs",
        PermissionsPathSegment: "permissions",
        StoredProceduresPathSegment: "sprocs",
        TriggersPathSegment: "triggers",
        UserDefinedFunctionsPathSegment: "udfs",
        ConflictsPathSegment: "conflicts",
        AttachmentsPathSegment: "attachments",
        PartitionKeyRangesPathSegment: "pkranges",
        SchemasPathSegment: "schemas",
        OffersPathSegment: "offers",
        TopologyPathSegment: "topology",
        DatabaseAccountPathSegment: "databaseaccount",
    },
    PartitionKeyRange: {
        // Partition Key Range Constants
        MinInclusive: "minInclusive",
        MaxExclusive: "maxExclusive",
        Id: "id",
    },
    QueryRangeConstants: {
        // Partition Key Range Constants
        MinInclusive: "minInclusive",
        MaxExclusive: "maxExclusive",
        min: "min",
    },
    /**
     * @deprecated Use EffectivePartitionKeyConstants instead
     */
    EffectiveParitionKeyConstants: {
        MinimumInclusiveEffectivePartitionKey: "",
        MaximumExclusiveEffectivePartitionKey: "FF",
    },
    EffectivePartitionKeyConstants: {
        MinimumInclusiveEffectivePartitionKey: "",
        MaximumExclusiveEffectivePartitionKey: "FF",
    },
    // Changefeed AllVersionsAndDeletesMode formatting version
    AllVersionsAndDeletesChangeFeedWireFormatVersion: "2021-09-15",
    ChangeFeedIfNoneMatchStartFromNowHeader: "*",
    // Default TTL for encryption caches is 2 hrs (7200 sec)
    DefaultEncryptionCacheTimeToLiveInSeconds: 7200,
    // Timeout to clear encryption related cache
    EncryptionCacheRefreshIntervalInMs: 60000, // 1 minute
};
/**
 * @hidden
 */
exports.ResourceType = void 0;
(function (ResourceType) {
    ResourceType["none"] = "";
    ResourceType["database"] = "dbs";
    ResourceType["offer"] = "offers";
    ResourceType["user"] = "users";
    ResourceType["permission"] = "permissions";
    ResourceType["container"] = "colls";
    ResourceType["conflicts"] = "conflicts";
    ResourceType["sproc"] = "sprocs";
    ResourceType["udf"] = "udfs";
    ResourceType["trigger"] = "triggers";
    ResourceType["item"] = "docs";
    ResourceType["pkranges"] = "pkranges";
    ResourceType["partitionkey"] = "partitionKey";
    /** resource representing client encryption keys to encrypt/decrypt data */
    ResourceType["clientencryptionkey"] = "clientencryptionkeys";
})(exports.ResourceType || (exports.ResourceType = {}));
/**
 * @hidden
 */
exports.HTTPMethod = void 0;
(function (HTTPMethod) {
    HTTPMethod["get"] = "GET";
    HTTPMethod["patch"] = "PATCH";
    HTTPMethod["post"] = "POST";
    HTTPMethod["put"] = "PUT";
    HTTPMethod["delete"] = "DELETE";
})(exports.HTTPMethod || (exports.HTTPMethod = {}));
/**
 * @hidden
 */
exports.OperationType = void 0;
(function (OperationType) {
    OperationType["Create"] = "create";
    OperationType["Replace"] = "replace";
    OperationType["Upsert"] = "upsert";
    OperationType["Delete"] = "delete";
    OperationType["Read"] = "read";
    OperationType["Query"] = "query";
    OperationType["Execute"] = "execute";
    OperationType["Batch"] = "batch";
    OperationType["Patch"] = "patch";
})(exports.OperationType || (exports.OperationType = {}));
/**
 * @hidden
 */
var CosmosKeyType;
(function (CosmosKeyType) {
    CosmosKeyType["PrimaryMaster"] = "PRIMARY_MASTER";
    CosmosKeyType["SecondaryMaster"] = "SECONDARY_MASTER";
    CosmosKeyType["PrimaryReadOnly"] = "PRIMARY_READONLY";
    CosmosKeyType["SecondaryReadOnly"] = "SECONDARY_READONLY";
})(CosmosKeyType || (CosmosKeyType = {}));
/**
 * @hidden
 */
var CosmosContainerChildResourceKind;
(function (CosmosContainerChildResourceKind) {
    CosmosContainerChildResourceKind["Item"] = "ITEM";
    CosmosContainerChildResourceKind["StoredProcedure"] = "STORED_PROCEDURE";
    CosmosContainerChildResourceKind["UserDefinedFunction"] = "USER_DEFINED_FUNCTION";
    CosmosContainerChildResourceKind["Trigger"] = "TRIGGER";
})(CosmosContainerChildResourceKind || (CosmosContainerChildResourceKind = {}));
/**
 * @hidden
 */
var PermissionScopeValues;
(function (PermissionScopeValues) {
    /**
     * Values which set permission Scope applicable to control plane related operations.
     */
    PermissionScopeValues[PermissionScopeValues["ScopeAccountReadValue"] = 1] = "ScopeAccountReadValue";
    PermissionScopeValues[PermissionScopeValues["ScopeAccountListDatabasesValue"] = 2] = "ScopeAccountListDatabasesValue";
    PermissionScopeValues[PermissionScopeValues["ScopeDatabaseReadValue"] = 4] = "ScopeDatabaseReadValue";
    PermissionScopeValues[PermissionScopeValues["ScopeDatabaseReadOfferValue"] = 8] = "ScopeDatabaseReadOfferValue";
    PermissionScopeValues[PermissionScopeValues["ScopeDatabaseListContainerValue"] = 16] = "ScopeDatabaseListContainerValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerReadValue"] = 32] = "ScopeContainerReadValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerReadOfferValue"] = 64] = "ScopeContainerReadOfferValue";
    PermissionScopeValues[PermissionScopeValues["ScopeAccountCreateDatabasesValue"] = 1] = "ScopeAccountCreateDatabasesValue";
    PermissionScopeValues[PermissionScopeValues["ScopeAccountDeleteDatabasesValue"] = 2] = "ScopeAccountDeleteDatabasesValue";
    PermissionScopeValues[PermissionScopeValues["ScopeDatabaseDeleteValue"] = 4] = "ScopeDatabaseDeleteValue";
    PermissionScopeValues[PermissionScopeValues["ScopeDatabaseReplaceOfferValue"] = 8] = "ScopeDatabaseReplaceOfferValue";
    PermissionScopeValues[PermissionScopeValues["ScopeDatabaseCreateContainerValue"] = 16] = "ScopeDatabaseCreateContainerValue";
    PermissionScopeValues[PermissionScopeValues["ScopeDatabaseDeleteContainerValue"] = 32] = "ScopeDatabaseDeleteContainerValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerReplaceValue"] = 64] = "ScopeContainerReplaceValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerDeleteValue"] = 128] = "ScopeContainerDeleteValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerReplaceOfferValue"] = 256] = "ScopeContainerReplaceOfferValue";
    PermissionScopeValues[PermissionScopeValues["ScopeAccountReadAllAccessValue"] = 65535] = "ScopeAccountReadAllAccessValue";
    PermissionScopeValues[PermissionScopeValues["ScopeDatabaseReadAllAccessValue"] = 124] = "ScopeDatabaseReadAllAccessValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainersReadAllAccessValue"] = 96] = "ScopeContainersReadAllAccessValue";
    PermissionScopeValues[PermissionScopeValues["ScopeAccountWriteAllAccessValue"] = 65535] = "ScopeAccountWriteAllAccessValue";
    PermissionScopeValues[PermissionScopeValues["ScopeDatabaseWriteAllAccessValue"] = 508] = "ScopeDatabaseWriteAllAccessValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainersWriteAllAccessValue"] = 448] = "ScopeContainersWriteAllAccessValue";
    /**
     * Values which set permission Scope applicable to data plane related operations.
     */
    PermissionScopeValues[PermissionScopeValues["ScopeContainerExecuteQueriesValue"] = 1] = "ScopeContainerExecuteQueriesValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerReadFeedsValue"] = 2] = "ScopeContainerReadFeedsValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerReadStoredProceduresValue"] = 4] = "ScopeContainerReadStoredProceduresValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerReadUserDefinedFunctionsValue"] = 8] = "ScopeContainerReadUserDefinedFunctionsValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerReadTriggersValue"] = 16] = "ScopeContainerReadTriggersValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerReadConflictsValue"] = 32] = "ScopeContainerReadConflictsValue";
    PermissionScopeValues[PermissionScopeValues["ScopeItemReadValue"] = 64] = "ScopeItemReadValue";
    PermissionScopeValues[PermissionScopeValues["ScopeStoredProcedureReadValue"] = 128] = "ScopeStoredProcedureReadValue";
    PermissionScopeValues[PermissionScopeValues["ScopeUserDefinedFunctionReadValue"] = 256] = "ScopeUserDefinedFunctionReadValue";
    PermissionScopeValues[PermissionScopeValues["ScopeTriggerReadValue"] = 512] = "ScopeTriggerReadValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerCreateItemsValue"] = 1] = "ScopeContainerCreateItemsValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerReplaceItemsValue"] = 2] = "ScopeContainerReplaceItemsValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerUpsertItemsValue"] = 4] = "ScopeContainerUpsertItemsValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerDeleteItemsValue"] = 8] = "ScopeContainerDeleteItemsValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerCreateStoredProceduresValue"] = 16] = "ScopeContainerCreateStoredProceduresValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerReplaceStoredProceduresValue"] = 32] = "ScopeContainerReplaceStoredProceduresValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerDeleteStoredProceduresValue"] = 64] = "ScopeContainerDeleteStoredProceduresValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerExecuteStoredProceduresValue"] = 128] = "ScopeContainerExecuteStoredProceduresValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerCreateTriggersValue"] = 256] = "ScopeContainerCreateTriggersValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerReplaceTriggersValue"] = 512] = "ScopeContainerReplaceTriggersValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerDeleteTriggersValue"] = 1024] = "ScopeContainerDeleteTriggersValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerCreateUserDefinedFunctionsValue"] = 2048] = "ScopeContainerCreateUserDefinedFunctionsValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerReplaceUserDefinedFunctionsValue"] = 4096] = "ScopeContainerReplaceUserDefinedFunctionsValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerDeleteUserDefinedFunctionSValue"] = 8192] = "ScopeContainerDeleteUserDefinedFunctionSValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerDeleteCONFLICTSValue"] = 16384] = "ScopeContainerDeleteCONFLICTSValue";
    PermissionScopeValues[PermissionScopeValues["ScopeItemReplaceValue"] = 65536] = "ScopeItemReplaceValue";
    PermissionScopeValues[PermissionScopeValues["ScopeItemUpsertValue"] = 131072] = "ScopeItemUpsertValue";
    PermissionScopeValues[PermissionScopeValues["ScopeItemDeleteValue"] = 262144] = "ScopeItemDeleteValue";
    PermissionScopeValues[PermissionScopeValues["ScopeStoredProcedureReplaceValue"] = 1048576] = "ScopeStoredProcedureReplaceValue";
    PermissionScopeValues[PermissionScopeValues["ScopeStoredProcedureDeleteValue"] = 2097152] = "ScopeStoredProcedureDeleteValue";
    PermissionScopeValues[PermissionScopeValues["ScopeStoredProcedureExecuteValue"] = 4194304] = "ScopeStoredProcedureExecuteValue";
    PermissionScopeValues[PermissionScopeValues["ScopeUserDefinedFunctionReplaceValue"] = 8388608] = "ScopeUserDefinedFunctionReplaceValue";
    PermissionScopeValues[PermissionScopeValues["ScopeUserDefinedFunctionDeleteValue"] = 16777216] = "ScopeUserDefinedFunctionDeleteValue";
    PermissionScopeValues[PermissionScopeValues["ScopeTriggerReplaceValue"] = 33554432] = "ScopeTriggerReplaceValue";
    PermissionScopeValues[PermissionScopeValues["ScopeTriggerDeleteValue"] = 67108864] = "ScopeTriggerDeleteValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerReadAllAccessValue"] = 4294967295] = "ScopeContainerReadAllAccessValue";
    PermissionScopeValues[PermissionScopeValues["ScopeItemReadAllAccessValue"] = 65] = "ScopeItemReadAllAccessValue";
    PermissionScopeValues[PermissionScopeValues["ScopeContainerWriteAllAccessValue"] = 4294967295] = "ScopeContainerWriteAllAccessValue";
    PermissionScopeValues[PermissionScopeValues["ScopeItemWriteAllAccessValue"] = 458767] = "ScopeItemWriteAllAccessValue";
    PermissionScopeValues[PermissionScopeValues["NoneValue"] = 0] = "NoneValue";
})(PermissionScopeValues || (PermissionScopeValues = {}));
/**
 * @hidden
 */
exports.SasTokenPermissionKind = void 0;
(function (SasTokenPermissionKind) {
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerCreateItems"] = 1] = "ContainerCreateItems";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerReplaceItems"] = 2] = "ContainerReplaceItems";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerUpsertItems"] = 4] = "ContainerUpsertItems";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerDeleteItems"] = 128] = "ContainerDeleteItems";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerExecuteQueries"] = 1] = "ContainerExecuteQueries";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerReadFeeds"] = 2] = "ContainerReadFeeds";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerCreateStoreProcedure"] = 16] = "ContainerCreateStoreProcedure";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerReadStoreProcedure"] = 4] = "ContainerReadStoreProcedure";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerReplaceStoreProcedure"] = 32] = "ContainerReplaceStoreProcedure";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerDeleteStoreProcedure"] = 64] = "ContainerDeleteStoreProcedure";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerCreateTriggers"] = 256] = "ContainerCreateTriggers";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerReadTriggers"] = 16] = "ContainerReadTriggers";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerReplaceTriggers"] = 512] = "ContainerReplaceTriggers";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerDeleteTriggers"] = 1024] = "ContainerDeleteTriggers";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerCreateUserDefinedFunctions"] = 2048] = "ContainerCreateUserDefinedFunctions";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerReadUserDefinedFunctions"] = 8] = "ContainerReadUserDefinedFunctions";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerReplaceUserDefinedFunctions"] = 4096] = "ContainerReplaceUserDefinedFunctions";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerDeleteUserDefinedFunctions"] = 8192] = "ContainerDeleteUserDefinedFunctions";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerExecuteStoredProcedure"] = 128] = "ContainerExecuteStoredProcedure";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerReadConflicts"] = 32] = "ContainerReadConflicts";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerDeleteConflicts"] = 16384] = "ContainerDeleteConflicts";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerReadAny"] = 64] = "ContainerReadAny";
    SasTokenPermissionKind[SasTokenPermissionKind["ContainerFullAccess"] = 4294967295] = "ContainerFullAccess";
    SasTokenPermissionKind[SasTokenPermissionKind["ItemReadAny"] = 65536] = "ItemReadAny";
    SasTokenPermissionKind[SasTokenPermissionKind["ItemFullAccess"] = 65] = "ItemFullAccess";
    SasTokenPermissionKind[SasTokenPermissionKind["ItemRead"] = 64] = "ItemRead";
    SasTokenPermissionKind[SasTokenPermissionKind["ItemReplace"] = 65536] = "ItemReplace";
    SasTokenPermissionKind[SasTokenPermissionKind["ItemUpsert"] = 131072] = "ItemUpsert";
    SasTokenPermissionKind[SasTokenPermissionKind["ItemDelete"] = 262144] = "ItemDelete";
    SasTokenPermissionKind[SasTokenPermissionKind["StoreProcedureRead"] = 128] = "StoreProcedureRead";
    SasTokenPermissionKind[SasTokenPermissionKind["StoreProcedureReplace"] = 1048576] = "StoreProcedureReplace";
    SasTokenPermissionKind[SasTokenPermissionKind["StoreProcedureDelete"] = 2097152] = "StoreProcedureDelete";
    SasTokenPermissionKind[SasTokenPermissionKind["StoreProcedureExecute"] = 4194304] = "StoreProcedureExecute";
    SasTokenPermissionKind[SasTokenPermissionKind["UserDefinedFuntionRead"] = 256] = "UserDefinedFuntionRead";
    SasTokenPermissionKind[SasTokenPermissionKind["UserDefinedFuntionReplace"] = 8388608] = "UserDefinedFuntionReplace";
    SasTokenPermissionKind[SasTokenPermissionKind["UserDefinedFuntionDelete"] = 16777216] = "UserDefinedFuntionDelete";
    SasTokenPermissionKind[SasTokenPermissionKind["TriggerRead"] = 512] = "TriggerRead";
    SasTokenPermissionKind[SasTokenPermissionKind["TriggerReplace"] = 33554432] = "TriggerReplace";
    SasTokenPermissionKind[SasTokenPermissionKind["TriggerDelete"] = 67108864] = "TriggerDelete";
})(exports.SasTokenPermissionKind || (exports.SasTokenPermissionKind = {}));
var QueryFeature;
(function (QueryFeature) {
    QueryFeature["NonValueAggregate"] = "NonValueAggregate";
    QueryFeature["Aggregate"] = "Aggregate";
    QueryFeature["Distinct"] = "Distinct";
    QueryFeature["MultipleOrderBy"] = "MultipleOrderBy";
    QueryFeature["OffsetAndLimit"] = "OffsetAndLimit";
    QueryFeature["OrderBy"] = "OrderBy";
    QueryFeature["Top"] = "Top";
    QueryFeature["CompositeAggregate"] = "CompositeAggregate";
    QueryFeature["GroupBy"] = "GroupBy";
    QueryFeature["MultipleAggregates"] = "MultipleAggregates";
    QueryFeature["NonStreamingOrderBy"] = "NonStreamingOrderBy";
    QueryFeature["ListAndSetAggregate"] = "ListAndSetAggregate";
    QueryFeature["CountIf"] = "CountIf";
    QueryFeature["HybridSearch"] = "HybridSearch";
})(QueryFeature || (QueryFeature = {}));
var SDKSupportedCapabilities;
(function (SDKSupportedCapabilities) {
    SDKSupportedCapabilities[SDKSupportedCapabilities["PartitionMerge"] = 1] = "PartitionMerge";
})(SDKSupportedCapabilities || (SDKSupportedCapabilities = {}));

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
class BooleanSerializer {
    serialize(value) {
        const numValue = value ? 1 : 0;
        const buffer = Buffer.alloc(8);
        buffer.writeBigInt64LE(BigInt(numValue), 0);
        return buffer;
    }
    deserialize(bytes) {
        if (!bytes || bytes.length < 1) {
            throw new Error("Invalid byte array for deserialization");
        }
        return !!bytes[0];
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
class NumberSerializer {
    deserialize(bytes) {
        if (!bytes || bytes.length < 8) {
            throw new Error("Invalid byte array for deserialization");
        }
        const num = Number(bytes.readBigInt64LE(0));
        return num;
    }
    serialize(value) {
        const newValue = BigInt(value);
        const buffer = Buffer.alloc(8);
        buffer.writeBigInt64LE(newValue, 0);
        return buffer;
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
class FloatSerializer {
    deserialize(bytes) {
        if (!bytes || bytes.length < 8) {
            throw new Error("Invalid byte array for deserialization");
        }
        const res = bytes.readDoubleLE(0);
        return res;
    }
    serialize(value) {
        if (!Number.isFinite(value)) {
            throw new Error("Value is out of range");
        }
        const buffer = Buffer.alloc(8);
        buffer.writeDoubleLE(value, 0);
        return buffer;
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
class StringSerializer {
    deserialize(bytes) {
        return bytes.toString(StringSerializer.characterEncoding);
    }
    serialize(value) {
        return Buffer.from(value, StringSerializer.characterEncoding);
    }
}
StringSerializer.characterEncoding = "utf-8";

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * The type of encryption to be performed.
 */
exports.EncryptionType = void 0;
(function (EncryptionType) {
    /** Deterministic type will always produce same encrypted value for same plaintext. */
    EncryptionType["DETERMINISTIC"] = "Deterministic";
    /** Randomized type will produce different encrypted value for same plaintext. */
    EncryptionType["RANDOMIZED"] = "Randomized";
})(exports.EncryptionType || (exports.EncryptionType = {}));

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
var TypeMarker;
(function (TypeMarker) {
    TypeMarker[TypeMarker["Null"] = 1] = "Null";
    TypeMarker[TypeMarker["Boolean"] = 2] = "Boolean";
    TypeMarker[TypeMarker["Double"] = 3] = "Double";
    TypeMarker[TypeMarker["Long"] = 4] = "Long";
    TypeMarker[TypeMarker["String"] = 5] = "String";
})(TypeMarker || (TypeMarker = {}));

class ErrorResponse extends Error {
}

const trimLeftSlashes = new RegExp("^[/]+");
const trimRightSlashes = new RegExp("[/]+$");
const illegalResourceIdCharacters = new RegExp("[/\\\\?#]");
const illegalItemResourceIdCharacters = new RegExp("[/\\\\#]");
/** @hidden */
function jsonStringifyAndEscapeNonASCII(arg) {
    // TODO: better way for this? Not sure.
    // escapes non-ASCII characters as \uXXXX
    return JSON.stringify(arg).replace(/[\u007F-\uFFFF]/g, (m) => {
        return "\\u" + ("0000" + m.charCodeAt(0).toString(16)).slice(-4);
    });
}
/**
 * @hidden
 */
function parseLink(resourcePath) {
    if (resourcePath.length === 0) {
        /* for DatabaseAccount case, both type and objectBody will be undefined. */
        return {
            type: undefined,
            objectBody: undefined,
        };
    }
    if (resourcePath[resourcePath.length - 1] !== "/") {
        resourcePath = resourcePath + "/";
    }
    if (resourcePath[0] !== "/") {
        resourcePath = "/" + resourcePath;
    }
    /*
           The path will be in the form of /[resourceType]/[resourceId]/ ....
           /[resourceType]//[resourceType]/[resourceId]/ .... /[resourceType]/[resourceId]/
           or /[resourceType]/[resourceId]/ .... /[resourceType]/[resourceId]/[resourceType]/[resourceId]/ ....
            /[resourceType]/[resourceId]/
           The result of split will be in the form of
           [[[resourceType], [resourceId] ... ,[resourceType], [resourceId], ""]
           In the first case, to extract the resourceId it will the element before last ( at length -2 )
           and the type will be before it ( at length -3 )
           In the second case, to extract the resource type it will the element before last ( at length -2 )
          */
    const pathParts = resourcePath.split("/");
    let id;
    let type;
    if (pathParts.length % 2 === 0) {
        // request in form /[resourceType]/[resourceId]/ .... /[resourceType]/[resourceId].
        id = pathParts[pathParts.length - 2];
        type = pathParts[pathParts.length - 3];
    }
    else {
        // request in form /[resourceType]/[resourceId]/ .... /[resourceType]/.
        id = pathParts[pathParts.length - 3];
        type = pathParts[pathParts.length - 2];
    }
    const result = {
        type,
        objectBody: {
            id,
            self: resourcePath,
        },
    };
    return result;
}
/**
 * @hidden
 */
function isReadRequest(operationType) {
    return operationType === exports.OperationType.Read || operationType === exports.OperationType.Query;
}
/**
 * @hidden
 */
function sleep(time) {
    return new Promise((resolve) => {
        setTimeout(() => {
            resolve();
        }, time);
    });
}
/**
 * @hidden
 */
function getContainerLink(link) {
    return link.split("/").slice(0, 4).join("/");
}
/**
 * @hidden
 */
function prepareURL(endpoint, path) {
    return trimSlashes(endpoint) + path;
}
/**
 * @hidden
 */
function trimSlashes(source) {
    return source.replace(trimLeftSlashes, "").replace(trimRightSlashes, "");
}
/**
 * @hidden
 */
function parsePath(path) {
    const pathParts = [];
    let currentIndex = 0;
    const throwError = () => {
        throw new Error("Path " + path + " is invalid at index " + currentIndex);
    };
    const getEscapedToken = () => {
        const quote = path[currentIndex];
        let newIndex = ++currentIndex;
        for (;;) {
            newIndex = path.indexOf(quote, newIndex);
            if (newIndex === -1) {
                throwError();
            }
            if (path[newIndex - 1] !== "\\") {
                break;
            }
            ++newIndex;
        }
        const token = path.substr(currentIndex, newIndex - currentIndex);
        currentIndex = newIndex + 1;
        return token;
    };
    const getToken = () => {
        const newIndex = path.indexOf("/", currentIndex);
        let token = null;
        if (newIndex === -1) {
            token = path.substr(currentIndex);
            currentIndex = path.length;
        }
        else {
            token = path.substr(currentIndex, newIndex - currentIndex);
            currentIndex = newIndex;
        }
        token = token.trim();
        return token;
    };
    while (currentIndex < path.length) {
        if (path[currentIndex] !== "/") {
            throwError();
        }
        if (++currentIndex === path.length) {
            break;
        }
        if (path[currentIndex] === '"' || path[currentIndex] === "'") {
            pathParts.push(getEscapedToken());
        }
        else {
            pathParts.push(getToken());
        }
    }
    return pathParts;
}
/**
 * @hidden
 */
function isResourceValid(resource, err) {
    // TODO: fix strictness issues so that caller contexts respects the types of the functions
    if (resource.id) {
        if (typeof resource.id !== "string") {
            err.message = "Id must be a string.";
            return false;
        }
        if (resource.id.indexOf("/") !== -1 ||
            resource.id.indexOf("\\") !== -1 ||
            resource.id.indexOf("?") !== -1 ||
            resource.id.indexOf("#") !== -1) {
            err.message = "Id contains illegal chars.";
            return false;
        }
        if (resource.id[resource.id.length - 1] === " ") {
            err.message = "Id ends with a space.";
            return false;
        }
    }
    return true;
}
/**
 * @hidden
 */
function isItemResourceValid(resource, err) {
    // TODO: fix strictness issues so that caller contexts respects the types of the functions
    if (resource.id) {
        if (typeof resource.id !== "string") {
            err.message = "Id must be a string.";
            return false;
        }
        if (resource.id.indexOf("/") !== -1 ||
            resource.id.indexOf("\\") !== -1 ||
            resource.id.indexOf("#") !== -1) {
            err.message = "Id contains illegal chars.";
            return false;
        }
    }
    return true;
}
/** @hidden */
function getIdFromLink(resourceLink) {
    resourceLink = trimSlashes(resourceLink);
    return resourceLink;
}
/** @hidden */
function getPathFromLink(resourceLink, resourceType) {
    resourceLink = trimSlashes(resourceLink);
    if (resourceType) {
        return "/" + encodeURI(resourceLink) + "/" + resourceType;
    }
    else {
        return "/" + encodeURI(resourceLink);
    }
}
/**
 * @hidden
 */
function isStringNullOrEmpty(inputString) {
    // checks whether string is null, undefined, empty or only contains space
    return !inputString || /^\s*$/.test(inputString);
}
/**
 * @hidden
 */
function trimSlashFromLeftAndRight(inputString) {
    if (typeof inputString !== "string") {
        throw new Error("invalid input: input is not string");
    }
    return inputString.replace(trimLeftSlashes, "").replace(trimRightSlashes, "");
}
/**
 * @hidden
 */
function validateResourceId(resourceId) {
    // if resourceId is not a string or is empty throw an error
    if (typeof resourceId !== "string" || isStringNullOrEmpty(resourceId)) {
        throw new Error("Resource ID must be a string and cannot be undefined, null or empty");
    }
    // if resource id contains illegal characters throw an error
    if (illegalResourceIdCharacters.test(resourceId)) {
        throw new Error("Illegal characters ['/', '\\', '#', '?'] cannot be used in Resource ID");
    }
    return true;
}
/**
 * @hidden
 */
function validateItemResourceId(resourceId) {
    // if resourceId is not a string or is empty throw an error
    if (typeof resourceId !== "string" || isStringNullOrEmpty(resourceId)) {
        throw new Error("Resource ID must be a string and cannot be undefined, null or empty");
    }
    // if resource id contains illegal characters throw an error
    if (illegalItemResourceIdCharacters.test(resourceId)) {
        throw new Error("Illegal characters ['/', '\\', '#'] cannot be used in Resource ID");
    }
    return true;
}
/**
 * @hidden
 */
function getResourceIdFromPath(resourcePath) {
    if (!resourcePath || typeof resourcePath !== "string") {
        return null;
    }
    const trimmedPath = trimSlashFromLeftAndRight(resourcePath);
    const pathSegments = trimmedPath.split("/");
    // number of segments of a path must always be even
    if (pathSegments.length % 2 !== 0) {
        return null;
    }
    return pathSegments[pathSegments.length - 1];
}
/**
 * @hidden
 */
function parseConnectionString(connectionString) {
    const keyValueStrings = connectionString.split(";");
    const { AccountEndpoint, AccountKey } = keyValueStrings.reduce((connectionObject, keyValueString) => {
        const [key, ...value] = keyValueString.split("=");
        connectionObject[key] = value.join("=");
        return connectionObject;
    }, {});
    if (!AccountEndpoint || !AccountKey) {
        throw new Error("Could not parse the provided connection string");
    }
    return {
        endpoint: AccountEndpoint,
        key: AccountKey,
    };
}
/**
 * utility function to return copy of object to avoid encryption of original object passed
 * in the CRUD methods.
 * @hidden
 */
/* eslint-disable @typescript-eslint/no-explicit-any, @typescript-eslint/explicit-module-boundary-types, @typescript-eslint/no-shadow, no-prototype-builtins */
function copyObject(obj) {
    return JSON.parse(JSON.stringify(obj, (_, value) => {
        if (typeof value === "bigint") {
            throw new Error(`BigInt type is not supported`);
        }
        return value;
    }));
}
/**
 * @hidden
 */
function createDeserializer(typeMarker) {
    switch (typeMarker) {
        case TypeMarker.Long: {
            // return instance
            return new NumberSerializer();
        }
        case TypeMarker.Double:
            return new FloatSerializer();
        case TypeMarker.String:
            return new StringSerializer();
        case TypeMarker.Boolean:
            return new BooleanSerializer();
        default:
            throw new Error("Invalid or Unsupported data type passed.");
    }
}
/**
 * @hidden
 * extracts the top-level path
 */
function extractPath(path) {
    const secondSlashIndex = path.indexOf("/", path.indexOf("/") + 1);
    return secondSlashIndex === -1 ? path : path.substring(0, secondSlashIndex);
}
function createSerializer(propertyValue, type) {
    if (type) {
        if (type === TypeMarker.Long) {
            return [TypeMarker.Long, new NumberSerializer()];
        }
        else if (type === TypeMarker.Double) {
            return [TypeMarker.Double, new FloatSerializer()];
        }
        else if (type === TypeMarker.String) {
            return [TypeMarker.String, new StringSerializer()];
        }
        else if (type === TypeMarker.Boolean) {
            return [TypeMarker.Boolean, new BooleanSerializer()];
        }
        else {
            throw new Error("Invalid or Unsupported data type passed.");
        }
    }
    else {
        switch (typeof propertyValue) {
            case "boolean":
                return [TypeMarker.Boolean, new BooleanSerializer()];
            case "string":
                return [TypeMarker.String, new StringSerializer()];
            case "object":
                if (propertyValue.constructor === Date) {
                    return [TypeMarker.String, new StringSerializer()];
                }
                throw new Error("Invalid or Unsupported data type passed.");
            case "number":
                if (!Number.isInteger(propertyValue)) {
                    return [TypeMarker.Double, new FloatSerializer()];
                }
                else {
                    return [TypeMarker.Long, new NumberSerializer()];
                }
            default:
                throw new Error("Invalid or Unsupported data type passed.");
        }
    }
}
/**
 * @hidden
 * verifies policy format version, included paths and ensures that id and partition key paths specified in the client encryption policy
 * for encryption are encrypted using Deterministic encryption algorithm.
 */
function validateClientEncryptionPolicy(clientEncryptionPolicy, partitionKey) {
    const policyFormatVersion = clientEncryptionPolicy.policyFormatVersion;
    if (policyFormatVersion < 1 || policyFormatVersion > 2) {
        throw new ErrorResponse("Supported versions of client encryption policy are 1 and 2.");
    }
    const paths = new Set();
    // checks for duplicate paths and validates the path format and clientEncryptionKeyId
    for (const includedPath of clientEncryptionPolicy.includedPaths) {
        if (paths.has(includedPath.path)) {
            throw new ErrorResponse(`Duplicate path found: ${includedPath.path} in client encryption policy.`);
        }
        if (includedPath.path === undefined ||
            includedPath.path === null ||
            includedPath.path === "" ||
            includedPath.path === "/") {
            throw new ErrorResponse("Path needs to be defined in ClientEncryptionIncludedPath.");
        }
        if (includedPath.clientEncryptionKeyId === undefined ||
            includedPath.clientEncryptionKeyId === null ||
            includedPath.clientEncryptionKeyId === "" ||
            typeof includedPath.clientEncryptionKeyId !== "string") {
            throw new ErrorResponse("ClientEncryptionKeyId needs to be defined as string type in ClientEncryptionIncludedPath.");
        }
        if (includedPath.path[0] !== "/") {
            throw new ErrorResponse("Path in ClientEncryptionIncludedPath must start with '/'.");
        }
        const pathSegments = includedPath.path.split("/").filter((segment) => segment.length > 0);
        if (pathSegments.length > 1) {
            throw new ErrorResponse("Only top-level paths are currently supported for encryption");
        }
        paths.add(includedPath.path);
    }
    // checks if id and partition key paths are encrypted using Deterministic encryption algorithm.
    const encryptedPaths = clientEncryptionPolicy.includedPaths;
    const partitionKeyPaths = partitionKey.paths.map(extractPath);
    let isPartitionKeyEncrypted = false;
    let isIdEncrypted = false;
    for (const encryptedPath of encryptedPaths) {
        if (encryptedPath.path === "/id") {
            isIdEncrypted = true;
            if (encryptedPath.encryptionType !== exports.EncryptionType.DETERMINISTIC) {
                throw new ErrorResponse("The '/id' property must be encrypted using Deterministic encryption.");
            }
        }
        if (partitionKeyPaths.includes(encryptedPath.path)) {
            isPartitionKeyEncrypted = true;
            if (encryptedPath.encryptionType !== exports.EncryptionType.DETERMINISTIC) {
                throw new ErrorResponse(`Path: ${encryptedPath.path} which is part of the partition key has to be encrypted with Deterministic type Encryption.`);
            }
        }
    }
    // Ensures that the policy format version is 2 if id or partition key paths are encrypted.
    if ((isPartitionKeyEncrypted || isIdEncrypted) &&
        clientEncryptionPolicy.policyFormatVersion === 1) {
        throw new ErrorResponse("Encryption of partition key or id is only supported with policy format version 2.");
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @hidden
 */
const StatusCodes = {
    // Success
    Ok: 200,
    Created: 201,
    Accepted: 202,
    NoContent: 204,
    NotModified: 304,
    // Client error
    BadRequest: 400,
    Unauthorized: 401,
    Forbidden: 403,
    NotFound: 404,
    MethodNotAllowed: 405,
    RequestTimeout: 408,
    Conflict: 409,
    Gone: 410,
    PreconditionFailed: 412,
    RequestEntityTooLarge: 413,
    TooManyRequests: 429,
    RetryWith: 449,
    // Server Error
    InternalServerError: 500,
    ServiceUnavailable: 503,
    // System codes
    ENOTFOUND: "ENOTFOUND",
    // Operation pause and cancel. These are FAKE status codes for QOS logging purpose only.
    OperationPaused: 1200,
    OperationCancelled: 1201,
};
/**
 * @hidden
 */
const SubStatusCodes = {
    Unknown: 0,
    // 400: Bad Request Substatus
    CrossPartitionQueryNotServable: 1004,
    IncorrectContainerRidSubstatus: 1024,
    PartitionKeyMismatch: 1001,
    // 410: StatusCodeType_Gone: substatus
    PartitionKeyRangeGone: 1002,
    CompletingSplit: 1007,
    // 404: NotFound Substatus
    ReadSessionNotAvailable: 1002,
    // 403: Forbidden Substatus
    WriteForbidden: 3,
    DatabaseAccountNotFound: 1008,
};

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Would be used when creating or deleting a DocumentCollection
 * or a User in Azure Cosmos DB database service
 * @hidden
 * Given a database id, this creates a database link.
 * @param databaseId - The database id
 * @returns A database link in the format of `dbs/{0}`
 * with `{0}` being a Uri escaped version of the databaseId
 */
function createDatabaseUri(databaseId) {
    databaseId = trimSlashFromLeftAndRight(databaseId);
    validateResourceId(databaseId);
    return Constants.Path.DatabasesPathSegment + "/" + databaseId;
}
/**
 * Given a database and collection id, this creates a collection link.
 * Would be used when updating or deleting a DocumentCollection, creating a
 * Document, a StoredProcedure, a Trigger, a UserDefinedFunction, or when executing a query
 * with CreateDocumentQuery in Azure Cosmos DB database service.
 * @param databaseId - The database id
 * @param collectionId - The collection id
 * @returns A collection link in the format of `dbs/{0}/colls/{1}`
 * with `{0}` being a Uri escaped version of the databaseId and `{1}` being collectionId
 * @hidden
 */
function createDocumentCollectionUri(databaseId, collectionId) {
    collectionId = trimSlashFromLeftAndRight(collectionId);
    validateResourceId(collectionId);
    return (createDatabaseUri(databaseId) + "/" + Constants.Path.CollectionsPathSegment + "/" + collectionId);
}
/**
 * Given a database and user id, this creates a user link.
 * Would be used when creating a Permission, or when replacing or deleting
 * a User in Azure Cosmos DB database service
 * @param databaseId - The database id
 * @param userId - The user id
 * @returns A user link in the format of `dbs/{0}/users/{1}`
 * with `{0}` being a Uri escaped version of the databaseId and `{1}` being userId
 * @hidden
 */
function createUserUri(databaseId, userId) {
    userId = trimSlashFromLeftAndRight(userId);
    validateResourceId(userId);
    return createDatabaseUri(databaseId) + "/" + Constants.Path.UsersPathSegment + "/" + userId;
}
/**
 * Given a database and collection id, this creates a collection link.
 * Would be used when creating an Attachment, or when replacing
 * or deleting a Document in Azure Cosmos DB database service
 * @param databaseId - The database id
 * @param collectionId - The collection id
 * @param documentId - The document id
 * @returns A document link in the format of
 * `dbs/{0}/colls/{1}/docs/{2}` with `{0}` being a Uri escaped version of
 * the databaseId, `{1}` being collectionId and `{2}` being the documentId
 * @hidden
 */
function createDocumentUri(databaseId, collectionId, documentId) {
    documentId = trimSlashFromLeftAndRight(documentId);
    validateItemResourceId(documentId);
    return (createDocumentCollectionUri(databaseId, collectionId) +
        "/" +
        Constants.Path.DocumentsPathSegment +
        "/" +
        documentId);
}
/**
 * Given a database, collection and document id, this creates a document link.
 * Would be used when replacing or deleting a Permission in Azure Cosmos DB database service.
 * @param databaseId    -The database Id
 * @param userId        -The user Id
 * @param permissionId  - The permissionId
 * @returns A permission link in the format of `dbs/{0}/users/{1}/permissions/{2}`
 * with `{0}` being a Uri escaped version of the databaseId, `{1}` being userId and `{2}` being permissionId
 * @hidden
 */
function createPermissionUri(databaseId, userId, permissionId) {
    permissionId = trimSlashFromLeftAndRight(permissionId);
    validateResourceId(permissionId);
    return (createUserUri(databaseId, userId) +
        "/" +
        Constants.Path.PermissionsPathSegment +
        "/" +
        permissionId);
}
/**
 * Given a database, collection and stored proc id, this creates a stored proc link.
 * Would be used when replacing, executing, or deleting a StoredProcedure in
 * Azure Cosmos DB database service.
 * @param databaseId        -The database Id
 * @param collectionId      -The collection Id
 * @param storedProcedureId -The stored procedure Id
 * @returns A stored procedure link in the format of
 * `dbs/{0}/colls/{1}/sprocs/{2}` with `{0}` being a Uri escaped version of the databaseId,
 * `{1}` being collectionId and `{2}` being the storedProcedureId
 * @hidden
 */
function createStoredProcedureUri(databaseId, collectionId, storedProcedureId) {
    storedProcedureId = trimSlashFromLeftAndRight(storedProcedureId);
    validateResourceId(storedProcedureId);
    return (createDocumentCollectionUri(databaseId, collectionId) +
        "/" +
        Constants.Path.StoredProceduresPathSegment +
        "/" +
        storedProcedureId);
}
/**
 * Given a database, collection and trigger id, this creates a trigger link.
 * Would be used when replacing, executing, or deleting a Trigger in Azure Cosmos DB database service
 * @param databaseId        -The database Id
 * @param collectionId      -The collection Id
 * @param triggerId         -The trigger Id
 * @returns A trigger link in the format of
 * `dbs/{0}/colls/{1}/triggers/{2}` with `{0}` being a Uri escaped version of the databaseId,
 * `{1}` being collectionId and `{2}` being the triggerId
 * @hidden
 */
function createTriggerUri(databaseId, collectionId, triggerId) {
    triggerId = trimSlashFromLeftAndRight(triggerId);
    validateResourceId(triggerId);
    return (createDocumentCollectionUri(databaseId, collectionId) +
        "/" +
        Constants.Path.TriggersPathSegment +
        "/" +
        triggerId);
}
/**
 * Given a database, collection and udf id, this creates a udf link.
 * Would be used when replacing, executing, or deleting a UserDefinedFunction in
 * Azure Cosmos DB database service
 * @param databaseId        -The database Id
 * @param collectionId      -The collection Id
 * @param udfId             -The User Defined Function Id
 * @returns A udf link in the format of `dbs/{0}/colls/{1}/udfs/{2}`
 * with `{0}` being a Uri escaped version of the databaseId, `{1}` being collectionId and `{2}` being the udfId
 * @hidden
 */
function createUserDefinedFunctionUri(databaseId, collectionId, udfId) {
    udfId = trimSlashFromLeftAndRight(udfId);
    validateResourceId(udfId);
    return (createDocumentCollectionUri(databaseId, collectionId) +
        "/" +
        Constants.Path.UserDefinedFunctionsPathSegment +
        "/" +
        udfId);
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
async function hmac(key, message) {
    return crypto.createHmac("sha256", Buffer.from(key, "base64")).update(message).digest("base64");
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
async function generateHeaders(masterKey, method, resourceType = exports.ResourceType.none, resourceId = "", date = new Date()) {
    if (masterKey.startsWith("type=sas&")) {
        return {
            [Constants.HttpHeaders.Authorization]: encodeURIComponent(masterKey),
            [Constants.HttpHeaders.XDate]: date.toUTCString(),
        };
    }
    const sig = await signature(masterKey, method, resourceType, resourceId, date);
    return {
        [Constants.HttpHeaders.Authorization]: sig,
        [Constants.HttpHeaders.XDate]: date.toUTCString(),
    };
}
async function signature(masterKey, method, resourceType, resourceId = "", date = new Date()) {
    const type = "master";
    const version = "1.0";
    const text = method.toLowerCase() +
        "\n" +
        resourceType.toLowerCase() +
        "\n" +
        resourceId +
        "\n" +
        date.toUTCString().toLowerCase() +
        "\n" +
        "" +
        "\n";
    const signed = await hmac(masterKey, text);
    return encodeURIComponent("type=" + type + "&ver=" + version + "&sig=" + signed);
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @hidden
 */
async function setAuthorizationHeader(clientOptions, verb, path, resourceId, resourceType, headers) {
    if (clientOptions.permissionFeed) {
        clientOptions.resourceTokens = {};
        for (const permission of clientOptions.permissionFeed) {
            const id = getResourceIdFromPath(permission.resource);
            if (!id) {
                throw new Error(`authorization error: ${id} \
                          is an invalid resourceId in permissionFeed`);
            }
            clientOptions.resourceTokens[id] = permission._token; // TODO: any
        }
    }
    if (clientOptions.key) {
        await setAuthorizationTokenHeaderUsingMasterKey(verb, resourceId, resourceType, headers, clientOptions.key);
    }
    else if (clientOptions.resourceTokens) {
        headers[Constants.HttpHeaders.Authorization] = encodeURIComponent(getAuthorizationTokenUsingResourceTokens(clientOptions.resourceTokens, path, resourceId));
    }
    else if (clientOptions.tokenProvider) {
        headers[Constants.HttpHeaders.Authorization] = encodeURIComponent(await clientOptions.tokenProvider({ verb, path, resourceId, resourceType, headers }));
    }
}
/**
 * The default function for setting header token using the masterKey
 * @hidden
 */
async function setAuthorizationTokenHeaderUsingMasterKey(verb, resourceId, resourceType, headers, masterKey) {
    // TODO This should live in cosmos-sign
    if (resourceType === exports.ResourceType.offer) {
        resourceId = resourceId && resourceId.toLowerCase();
    }
    headers = Object.assign(headers, await generateHeaders(masterKey, verb, resourceType, resourceId));
}
/**
 * @hidden
 */
// TODO: Resource tokens
function getAuthorizationTokenUsingResourceTokens(resourceTokens, path, resourceId) {
    if (resourceTokens && Object.keys(resourceTokens).length > 0) {
        // For database account access(through getDatabaseAccount API), path and resourceId are "",
        // so in this case we return the first token to be used for creating the auth header as the
        // service will accept any token in this case
        if (!path && !resourceId) {
            return resourceTokens[Object.keys(resourceTokens)[0]];
        }
        // If we have exact resource token for the path use it
        if (resourceId && resourceTokens[resourceId]) {
            return resourceTokens[resourceId];
        }
        // minimum valid path /dbs
        if (!path || path.length < 4) {
            // TODO: This should throw an error
            return null;
        }
        path = trimSlashFromLeftAndRight(path);
        const pathSegments = (path && path.split("/")) || [];
        // Item path
        if (pathSegments.length === 6) {
            // Look for a container token matching the item path
            const containerPath = pathSegments.slice(0, 4).map(decodeURIComponent).join("/");
            if (resourceTokens[containerPath]) {
                return resourceTokens[containerPath];
            }
        }
        // TODO remove in v4: This is legacy behavior that lets someone use a resource token pointing ONLY at an ID
        // It was used when _rid was exposed by the SDK, but now that we are using user provided ids it is not needed
        // However removing it now would be a breaking change
        // if it's an incomplete path like /dbs/db1/colls/, start from the parent resource
        let index = pathSegments.length % 2 === 0 ? pathSegments.length - 1 : pathSegments.length - 2;
        for (; index > 0; index -= 2) {
            const id = decodeURI(pathSegments[index]);
            if (resourceTokens[id]) {
                return resourceTokens[id];
            }
        }
    }
    // TODO: This should throw an error
    return null;
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/** Determines the connection behavior of the CosmosClient. Note, we currently only support Gateway Mode. */
exports.ConnectionMode = void 0;
(function (ConnectionMode) {
    /** Gateway mode talks to an intermediate gateway which handles the direct communication with your individual partitions. */
    ConnectionMode[ConnectionMode["Gateway"] = 0] = "Gateway";
})(exports.ConnectionMode || (exports.ConnectionMode = {}));

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @hidden
 */
const defaultConnectionPolicy = Object.freeze({
    connectionMode: exports.ConnectionMode.Gateway,
    requestTimeout: 60000,
    enableEndpointDiscovery: true,
    preferredLocations: [],
    retryOptions: {
        maxRetryAttemptCount: Constants.ThrottledRequestMaxRetryAttemptCount,
        fixedRetryIntervalInMilliseconds: Constants.ThrottledRequestFixedRetryIntervalInMs,
        maxWaitTimeInSeconds: Constants.ThrottledRequestMaxWaitTimeInSeconds,
    },
    useMultipleWriteLocations: true,
    endpointRefreshRateInMs: 300000,
    enableBackgroundEndpointRefreshing: true,
});

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Represents the consistency levels supported for Azure Cosmos DB client operations.<br>
 * The requested ConsistencyLevel must match or be weaker than that provisioned for the database account.
 * Consistency levels.
 *
 * Consistency levels by order of strength are Strong, BoundedStaleness, Session, Consistent Prefix, and Eventual.
 *
 * See https://aka.ms/cosmos-consistency for more detailed documentation on Consistency Levels.
 */
exports.ConsistencyLevel = void 0;
(function (ConsistencyLevel) {
    /**
     * Strong Consistency guarantees that read operations always return the value that was last written.
     */
    ConsistencyLevel["Strong"] = "Strong";
    /**
     * Bounded Staleness guarantees that reads are not too out-of-date.
     * This can be configured based on number of operations (MaxStalenessPrefix) or time (MaxStalenessIntervalInSeconds).
     */
    ConsistencyLevel["BoundedStaleness"] = "BoundedStaleness";
    /**
     * Session Consistency guarantees monotonic reads (you never read old data, then new, then old again),
     * monotonic writes (writes are ordered) and read your writes (your writes are immediately visible to your reads)
     * within any single session.
     */
    ConsistencyLevel["Session"] = "Session";
    /**
     * Eventual Consistency guarantees that reads will return a subset of writes.
     * All writes will be eventually be available for reads.
     */
    ConsistencyLevel["Eventual"] = "Eventual";
    /**
     * ConsistentPrefix Consistency guarantees that reads will return some prefix of all writes with no gaps.
     * All writes will be eventually be available for reads.
     */
    ConsistencyLevel["ConsistentPrefix"] = "ConsistentPrefix";
})(exports.ConsistencyLevel || (exports.ConsistencyLevel = {}));

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Represents a DatabaseAccount in the Azure Cosmos DB database service.
 */
class DatabaseAccount {
    /**
     * The self-link for Databases in the databaseAccount.
     * @deprecated Use `databasesLink`
     */
    get DatabasesLink() {
        return this.databasesLink;
    }
    /**
     * The self-link for Media in the databaseAccount.
     * @deprecated Use `mediaLink`
     */
    get MediaLink() {
        return this.mediaLink;
    }
    /**
     * Attachment content (media) storage quota in MBs ( Retrieved from gateway ).
     * @deprecated use `maxMediaStorageUsageInMB`
     */
    get MaxMediaStorageUsageInMB() {
        return this.maxMediaStorageUsageInMB;
    }
    /**
     * Current attachment content (media) usage in MBs (Retrieved from gateway )
     *
     * Value is returned from cached information updated periodically and is not guaranteed
     * to be real time.
     *
     * @deprecated use `currentMediaStorageUsageInMB`
     */
    get CurrentMediaStorageUsageInMB() {
        return this.currentMediaStorageUsageInMB;
    }
    /**
     * Gets the UserConsistencyPolicy settings.
     * @deprecated use `consistencyPolicy`
     */
    get ConsistencyPolicy() {
        return this.consistencyPolicy;
    }
    // TODO: body - any
    constructor(body, headers) {
        /** The list of writable locations for a geo-replicated database account. */
        this.writableLocations = [];
        /** The list of readable locations for a geo-replicated database account. */
        this.readableLocations = [];
        this.databasesLink = "/dbs/";
        this.mediaLink = "/media/";
        this.maxMediaStorageUsageInMB = headers[Constants.HttpHeaders.MaxMediaStorageUsageInMB];
        this.currentMediaStorageUsageInMB = headers[Constants.HttpHeaders.CurrentMediaStorageUsageInMB];
        this.consistencyPolicy = body.userConsistencyPolicy
            ? body.userConsistencyPolicy.defaultConsistencyLevel
            : exports.ConsistencyLevel.Session;
        if (body[Constants.WritableLocations] && body.id !== "localhost") {
            this.writableLocations = body[Constants.WritableLocations];
        }
        if (body[Constants.ReadableLocations] && body.id !== "localhost") {
            this.readableLocations = body[Constants.ReadableLocations];
        }
        if (body[Constants.ENABLE_MULTIPLE_WRITABLE_LOCATIONS]) {
            this.enableMultipleWritableLocations =
                body[Constants.ENABLE_MULTIPLE_WRITABLE_LOCATIONS] === true ||
                    body[Constants.ENABLE_MULTIPLE_WRITABLE_LOCATIONS] === "true";
        }
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/** Defines a target data type of an index path specification in the Azure Cosmos DB service. */
exports.DataType = void 0;
(function (DataType) {
    /** Represents a numeric data type. */
    DataType["Number"] = "Number";
    /** Represents a string data type. */
    DataType["String"] = "String";
    /** Represents a point data type. */
    DataType["Point"] = "Point";
    /** Represents a line string data type. */
    DataType["LineString"] = "LineString";
    /** Represents a polygon data type. */
    DataType["Polygon"] = "Polygon";
    /** Represents a multi-polygon data type. */
    DataType["MultiPolygon"] = "MultiPolygon";
})(exports.DataType || (exports.DataType = {}));

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Specifies the supported indexing modes.
 */
exports.IndexingMode = void 0;
(function (IndexingMode) {
    /**
     * Index is updated synchronously with a create or update operation.
     *
     * With consistent indexing, query behavior is the same as the default consistency level for the container.
     * The index is always kept up to date with the data.
     */
    IndexingMode["consistent"] = "consistent";
    /**
     * Index is updated asynchronously with respect to a create or update operation.
     *
     * With lazy indexing, queries are eventually consistent. The index is updated when the container is idle.
     */
    IndexingMode["lazy"] = "lazy";
    /** No Index is provided. */
    IndexingMode["none"] = "none";
})(exports.IndexingMode || (exports.IndexingMode = {}));

/* The target data type of a spatial path */
exports.SpatialType = void 0;
(function (SpatialType) {
    SpatialType["LineString"] = "LineString";
    SpatialType["MultiPolygon"] = "MultiPolygon";
    SpatialType["Point"] = "Point";
    SpatialType["Polygon"] = "Polygon";
})(exports.SpatialType || (exports.SpatialType = {}));
/**
 * Represents the index type of the vector.
 */
exports.VectorIndexType = void 0;
(function (VectorIndexType) {
    /**
     * Represents flat index type.
     */
    VectorIndexType["Flat"] = "flat";
    /**
     * Represents diskANN index type.
     */
    VectorIndexType["DiskANN"] = "diskANN";
    /**
     * Represents quantizedFlat index type.
     */
    VectorIndexType["QuantizedFlat"] = "quantizedFlat";
})(exports.VectorIndexType || (exports.VectorIndexType = {}));

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Specifies the supported Index types.
 */
exports.IndexKind = void 0;
(function (IndexKind) {
    /**
     * This is supplied for a path which requires sorting.
     */
    IndexKind["Range"] = "Range";
    /**
     * This is supplied for a path which requires geospatial indexing.
     */
    IndexKind["Spatial"] = "Spatial";
})(exports.IndexKind || (exports.IndexKind = {}));

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @hidden
 * None PartitionKey Literal
 */
const NonePartitionKeyLiteral = {};
/**
 * @hidden
 * Null PartitionKey Literal
 */
const NullPartitionKeyLiteral = null;
/**
 * @hidden
 * Maps PartitionKey to InternalPartitionKey.
 * @param partitionKey - PartitonKey to be converted.
 * @returns PartitionKeyInternal
 */
function convertToInternalPartitionKey(partitionKey) {
    if (Array.isArray(partitionKey)) {
        return partitionKey.map((key) => (key === undefined ? NonePartitionKeyLiteral : key));
    }
    else
        return [partitionKey];
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Builder class for building PartitionKey.
 */
class PartitionKeyBuilder {
    constructor() {
        this.values = [];
    }
    addValue(value) {
        this.values.push(value);
        return this;
    }
    addNullValue() {
        this.values.push(NullPartitionKeyLiteral);
        return this;
    }
    addNoneValue() {
        this.values.push(NonePartitionKeyLiteral);
        return this;
    }
    build() {
        return [...this.values];
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * PartitionKey Definition Version
 */
exports.PartitionKeyDefinitionVersion = void 0;
(function (PartitionKeyDefinitionVersion) {
    PartitionKeyDefinitionVersion[PartitionKeyDefinitionVersion["V1"] = 1] = "V1";
    PartitionKeyDefinitionVersion[PartitionKeyDefinitionVersion["V2"] = 2] = "V2";
})(exports.PartitionKeyDefinitionVersion || (exports.PartitionKeyDefinitionVersion = {}));

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Type of PartitionKey i.e. Hash, MultiHash
 */
exports.PartitionKeyKind = void 0;
(function (PartitionKeyKind) {
    PartitionKeyKind["Hash"] = "Hash";
    PartitionKeyKind["MultiHash"] = "MultiHash";
})(exports.PartitionKeyKind || (exports.PartitionKeyKind = {}));

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Enum for permission mode values.
 */
exports.PermissionMode = void 0;
(function (PermissionMode) {
    /** Permission not valid. */
    PermissionMode["None"] = "none";
    /** Permission applicable for read operations only. */
    PermissionMode["Read"] = "read";
    /** Permission applicable for all operations. */
    PermissionMode["All"] = "all";
})(exports.PermissionMode || (exports.PermissionMode = {}));

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Represents Priority Level associated with each Azure Cosmos DB client requests.<br>
 * The Low priority requests are always throttled before any High priority requests.
 *
 * By default all requests are considered as High priority requests.
 *
 * See https://aka.ms/CosmosDB/PriorityBasedExecution for more detailed documentation on Priority based throttling.
 */
exports.PriorityLevel = void 0;
(function (PriorityLevel) {
    /**
     * High Priority requests are throttled after Low priority requests.
     */
    PriorityLevel["High"] = "High";
    /**
     * Low Priority requests are throttled before High priority requests.
     */
    PriorityLevel["Low"] = "Low";
})(exports.PriorityLevel || (exports.PriorityLevel = {}));

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Enum for trigger operation values.
 * specifies the operations on which a trigger should be executed.
 */
exports.TriggerOperation = void 0;
(function (TriggerOperation) {
    /** All operations. */
    TriggerOperation["All"] = "all";
    /** Create operations only. */
    TriggerOperation["Create"] = "create";
    /** Update operations only. */
    TriggerOperation["Update"] = "update";
    /** Delete operations only. */
    TriggerOperation["Delete"] = "delete";
    /** Replace operations only. */
    TriggerOperation["Replace"] = "replace";
})(exports.TriggerOperation || (exports.TriggerOperation = {}));

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Enum for trigger type values.
 * Specifies the type of the trigger.
 */
exports.TriggerType = void 0;
(function (TriggerType) {
    /** Trigger should be executed before the associated operation(s). */
    TriggerType["Pre"] = "pre";
    /** Trigger should be executed after the associated operation(s). */
    TriggerType["Post"] = "post";
})(exports.TriggerType || (exports.TriggerType = {}));

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Enum for udf type values.
 * Specifies the types of user defined functions.
 */
exports.UserDefinedFunctionType = void 0;
(function (UserDefinedFunctionType) {
    /** The User Defined Function is written in JavaScript. This is currently the only option. */
    UserDefinedFunctionType["Javascript"] = "Javascript";
})(exports.UserDefinedFunctionType || (exports.UserDefinedFunctionType = {}));

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
exports.GeospatialType = void 0;
(function (GeospatialType) {
    /** Represents data in round-earth coordinate system. */
    GeospatialType["Geography"] = "Geography";
    /** Represents data in Eucledian(flat) coordinate system. */
    GeospatialType["Geometry"] = "Geometry";
})(exports.GeospatialType || (exports.GeospatialType = {}));

/**
 * Represents the data type of the vector.
 */
exports.VectorEmbeddingDataType = void 0;
(function (VectorEmbeddingDataType) {
    /**
     * 32-bit floating point number.
     */
    VectorEmbeddingDataType["Float32"] = "float32";
    /**
     * 8-bit unsigned integer.
     */
    VectorEmbeddingDataType["UInt8"] = "uint8";
    /**
     * 8-bit signed integer.
     */
    VectorEmbeddingDataType["Int8"] = "int8";
})(exports.VectorEmbeddingDataType || (exports.VectorEmbeddingDataType = {}));
/**
 * Represents the distance function to use for distance calculation in between vectors.
 */
exports.VectorEmbeddingDistanceFunction = void 0;
(function (VectorEmbeddingDistanceFunction) {
    /**
     * Represents euclidean distance function.
     */
    VectorEmbeddingDistanceFunction["Euclidean"] = "euclidean";
    /**
     * Represents cosine distance function.
     */
    VectorEmbeddingDistanceFunction["Cosine"] = "cosine";
    /**
     * Represents dot product distance function.
     */
    VectorEmbeddingDistanceFunction["DotProduct"] = "dotproduct";
})(exports.VectorEmbeddingDistanceFunction || (exports.VectorEmbeddingDistanceFunction = {}));

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
async function readPartitionKeyDefinition(diagnosticNode, container) {
    const partitionKeyDefinition = await container.readPartitionKeyDefinition(diagnosticNode);
    return partitionKeyDefinition.resource;
}

const logger$4 = logger$5.createClientLogger("extractPartitionKey");
/**
 * Function to extract PartitionKey based on {@link PartitionKeyDefinition}
 * from an object.
 * Retuns
 * 1. PartitionKeyInternal[] if extraction is successful.
 * 2. undefined if either {@link partitionKeyDefinition} is not well formed
 * or an unsupported partitionkey type is encountered.
 * @hidden
 */
function extractPartitionKeys(document, partitionKeyDefinition) {
    if (partitionKeyDefinition &&
        partitionKeyDefinition.paths &&
        partitionKeyDefinition.paths.length > 0) {
        if (partitionKeyDefinition.systemKey === true) {
            return [];
        }
        if (partitionKeyDefinition.paths.length === 1 &&
            partitionKeyDefinition.paths[0] === DEFAULT_PARTITION_KEY_PATH) {
            return [extractPartitionKey(DEFAULT_PARTITION_KEY_PATH, document)];
        }
        const partitionKeys = [];
        partitionKeyDefinition.paths.forEach((path) => {
            const obj = extractPartitionKey(path, document);
            if (obj === undefined) {
                logger$4.warning("Unsupported PartitionKey found.");
                return undefined;
            }
            partitionKeys.push(obj);
        });
        return partitionKeys;
    }
    logger$4.error("Unexpected Partition Key Definition Found.");
    return undefined;
}
function extractPartitionKey(path, obj) {
    const pathParts = parsePath(path);
    for (const part of pathParts) {
        if (typeof obj === "object" && obj !== null && part in obj) {
            obj = obj[part];
        }
        else {
            obj = undefined;
            break;
        }
    }
    if (typeof obj === "string" || typeof obj === "number" || typeof obj === "boolean") {
        return obj;
    }
    else if (obj === NullPartitionKeyLiteral) {
        return NullPartitionKeyLiteral;
    }
    else if (obj === undefined || JSON.stringify(obj) === JSON.stringify(NonePartitionKeyLiteral)) {
        return NonePartitionKeyLiteral;
    }
    return undefined;
}
/**
 * @hidden
 */
function undefinedPartitionKey(partitionKeyDefinition) {
    if (partitionKeyDefinition === null || partitionKeyDefinition === void 0 ? void 0 : partitionKeyDefinition.systemKey) {
        return [];
    }
    else {
        return partitionKeyDefinition === null || partitionKeyDefinition === void 0 ? void 0 : partitionKeyDefinition.paths.map(() => NonePartitionKeyLiteral);
    }
}
/**
 * @hidden
 */
async function setPartitionKeyIfUndefined(diagnosticNode, container, partitionKey) {
    if (partitionKey === undefined) {
        const partitionKeyDefinition = await readPartitionKeyDefinition(diagnosticNode, container);
        partitionKey = undefinedPartitionKey(partitionKeyDefinition);
    }
    return convertToInternalPartitionKey(partitionKey);
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Utility function to avoid writing boilder plate code while checking for
 * undefined values. It throws Error if the input value is undefined.
 * @param value - Value which is potentially undefined.
 * @param msg - Error Message to throw if value is undefined.
 * @returns
 */
function assertNotUndefined(value, msg) {
    if (value !== undefined) {
        return value;
    }
    throw new Error(msg || "Unexpected 'undefined' value encountered");
}
/**
 * Check for value being PrimitivePartitionKeyValue.
 * @internal
 */
function isPrimitivePartitionKeyValue(value) {
    return (isWellDefinedPartitionKeyValue(value) ||
        isNonePartitionKeyValue(value) ||
        isNullPartitionKeyValue(value));
}
/**
 * Check for value being string, number or boolean.
 * @internal
 */
function isWellDefinedPartitionKeyValue(value) {
    return typeof value === "string" || typeof value === "boolean" || typeof value === "number";
}
/**
 * Check for value being NonePartitionKeyType.
 * @internal
 */
function isNonePartitionKeyValue(value) {
    return value !== undefined && JSON.stringify(value) === JSON.stringify(NonePartitionKeyLiteral);
}
/**
 * Check for value being NullPartitionKeyType.
 * @internal
 */
function isNullPartitionKeyValue(value) {
    return value === NullPartitionKeyLiteral;
}
/**
 * Verify validity of partition key.
 * @internal
 */
function isPartitionKey(partitionKey) {
    return isPrimitivePartitionKeyValue(partitionKey) || Array.isArray(partitionKey);
}
/**
 * Check for value being PrefixPartitionKey.
 * @internal
 */
function isPrefixPartitionKey(partitionKey, partitionKeyDefinition) {
    return (partitionKeyDefinition &&
        partitionKeyDefinition.paths &&
        partitionKeyDefinition.kind === exports.PartitionKeyKind.MultiHash &&
        Array.isArray(partitionKey) &&
        partitionKey.length < partitionKeyDefinition.paths.length);
}

/**
 * The \@azure/logger configuration for this package.
 */
const defaultLogger = logger$5.createClientLogger("cosmosdb");

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @internal
 * FeedRange for which change feed is being requested.
 */
class ChangeFeedRange {
    constructor(minInclusive, maxExclusive, continuationToken, epkMinHeader, epkMaxHeader) {
        this.minInclusive = minInclusive;
        this.maxExclusive = maxExclusive;
        this.continuationToken = continuationToken;
        this.epkMinHeader = epkMinHeader;
        this.epkMaxHeader = epkMaxHeader;
    }
}

/**
 * A single response page from the Azure Cosmos DB Change Feed
 */
class ChangeFeedIteratorResponse {
    /**
     * @internal
     */
    constructor(
    /**
     * Gets the items returned in the response from Azure Cosmos DB
     */
    result, 
    /**
     * Gets the number of items returned in the response from Azure Cosmos DB
     */
    count, 
    /**
     * Gets the status code of the response from Azure Cosmos DB
     */
    statusCode, 
    /**
     * Headers related to cosmos DB and change feed.
     */
    headers, 
    /**
     * Cosmos Diagnostic Object.
     */
    diagnostics, 
    /**
     * Gets the subStatusCodes of the response from Azure Cosmos DB. Useful in partition split or partition gone.
     */
    subStatusCode) {
        this.result = result;
        this.count = count;
        this.statusCode = statusCode;
        this.diagnostics = diagnostics;
        this.subStatusCode = subStatusCode;
        this.headers = headers;
    }
    /**
     * Gets the request charge for this request from the Azure Cosmos DB service.
     */
    get requestCharge() {
        const rus = this.headers[Constants.HttpHeaders.RequestCharge];
        return rus ? parseInt(rus, 10) : null;
    }
    /**
     * Gets the activity ID for the request from the Azure Cosmos DB service.
     */
    get activityId() {
        return this.headers[Constants.HttpHeaders.ActivityId];
    }
    /**
     * Gets the continuation token to be used for continuing enumeration of the Azure Cosmos DB service.
     */
    get continuationToken() {
        return this.headers[Constants.HttpHeaders.ContinuationToken];
    }
    /**
     * Gets the session token for use in session consistency reads from the Azure Cosmos DB service.
     */
    get sessionToken() {
        return this.headers[Constants.HttpHeaders.SessionToken];
    }
}

/** @hidden */
class QueryRange {
    /**
     * Represents a QueryRange.
     *
     * @param rangeMin                - min
     * @param rangeMin                - max
     * @param isMinInclusive         - isMinInclusive
     * @param isMaxInclusive         - isMaxInclusive
     * @hidden
     */
    constructor(rangeMin, rangeMax, isMinInclusive, isMaxInclusive) {
        this.min = rangeMin;
        this.max = rangeMax;
        this.isMinInclusive = isMinInclusive;
        this.isMaxInclusive = isMaxInclusive;
    }
    overlaps(other) {
        const range1 = this; // eslint-disable-line @typescript-eslint/no-this-alias
        const range2 = other;
        if (range1 === undefined || range2 === undefined) {
            return false;
        }
        if (range1.isEmpty() || range2.isEmpty()) {
            return false;
        }
        if (range1.min <= range2.max || range2.min <= range1.max) {
            if ((range1.min === range2.max && !(range1.isMinInclusive && range2.isMaxInclusive)) ||
                (range2.min === range1.max && !(range2.isMinInclusive && range1.isMaxInclusive))) {
                return false;
            }
            return true;
        }
        return false;
    }
    isFullRange() {
        return (this.min === Constants.EffectivePartitionKeyConstants.MinimumInclusiveEffectivePartitionKey &&
            this.max === Constants.EffectivePartitionKeyConstants.MaximumExclusiveEffectivePartitionKey &&
            this.isMinInclusive === true &&
            this.isMaxInclusive === false);
    }
    isEmpty() {
        return !(this.isMinInclusive && this.isMaxInclusive) && this.min === this.max;
    }
    /**
     * Parse a QueryRange from a partitionKeyRange
     * @returns QueryRange
     * @hidden
     */
    static parsePartitionKeyRange(partitionKeyRange) {
        return new QueryRange(partitionKeyRange[Constants.PartitionKeyRange.MinInclusive], partitionKeyRange[Constants.PartitionKeyRange.MaxExclusive], true, false);
    }
    /**
     * Parse a QueryRange from a dictionary
     * @returns QueryRange
     * @hidden
     */
    static parseFromDict(queryRangeDict) {
        return new QueryRange(queryRangeDict.min, queryRangeDict.max, queryRangeDict.isMinInclusive, queryRangeDict.isMaxInclusive);
    }
}

/** @hidden */
class InMemoryCollectionRoutingMap {
    /**
     * Represents a InMemoryCollectionRoutingMap Object,
     * Stores partition key ranges in an efficient way with some additional information and provides
     * convenience methods for working with set of ranges.
     */
    constructor(orderedPartitionKeyRanges, orderedPartitionInfo) {
        this.orderedPartitionKeyRanges = orderedPartitionKeyRanges;
        this.orderedRanges = orderedPartitionKeyRanges.map((pkr) => {
            return new QueryRange(pkr[Constants.PartitionKeyRange.MinInclusive], pkr[Constants.PartitionKeyRange.MaxExclusive], true, false);
        });
        this.orderedPartitionInfo = orderedPartitionInfo;
    }
    getOrderedParitionKeyRanges() {
        return this.orderedPartitionKeyRanges;
    }
    getOverlappingRanges(providedQueryRanges) {
        // TODO This code has all kinds of smells. Multiple iterations and sorts just to grab overlapping ranges
        // stfaul attempted to bring it down to one for-loop and failed
        const pqr = Array.isArray(providedQueryRanges)
            ? providedQueryRanges
            : [providedQueryRanges];
        const minToPartitionRange = {}; // TODO: any
        // this for loop doesn't invoke any async callback
        for (const queryRange of pqr) {
            if (queryRange.isEmpty()) {
                continue;
            }
            if (queryRange.isFullRange()) {
                return this.orderedPartitionKeyRanges;
            }
            const minIndex = this.orderedRanges.findIndex((range) => {
                if (queryRange.min > range.min && queryRange.min < range.max) {
                    return true;
                }
                if (queryRange.min === range.min) {
                    return true;
                }
                if (queryRange.min === range.max) {
                    return true;
                }
            });
            if (minIndex < 0) {
                throw new Error("error in collection routing map, queried value is less than the start range.");
            }
            // Start at the end and work backwards
            let maxIndex;
            for (let i = this.orderedRanges.length - 1; i >= 0; i--) {
                const range = this.orderedRanges[i];
                if (queryRange.max > range.min && queryRange.max < range.max) {
                    maxIndex = i;
                    break;
                }
                if (queryRange.max === range.min) {
                    maxIndex = i;
                    break;
                }
                if (queryRange.max === range.max) {
                    maxIndex = i;
                    break;
                }
            }
            if (maxIndex > this.orderedRanges.length) {
                throw new Error("error in collection routing map, queried value is greater than the end range.");
            }
            for (let j = minIndex; j < maxIndex + 1; j++) {
                if (queryRange.overlaps(this.orderedRanges[j])) {
                    minToPartitionRange[this.orderedPartitionKeyRanges[j][Constants.PartitionKeyRange.MinInclusive]] = this.orderedPartitionKeyRanges[j];
                }
            }
        }
        const overlappingPartitionKeyRanges = Object.keys(minToPartitionRange).map((k) => minToPartitionRange[k]);
        return overlappingPartitionKeyRanges.sort((a, b) => {
            return a[Constants.PartitionKeyRange.MinInclusive].localeCompare(b[Constants.PartitionKeyRange.MinInclusive]);
        });
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 *  * This is a Cosmos Diagnostic type that holds collected diagnostic information during a client operations. ie. Item.read(), Container.create().
 * It has three members -
 * 1. `clientSideRequestStatistics` member contains aggregate diagnostic information, including -
 *   - metadata lookups. Here all the server requests, apart from the final intended resource are considered as metadata calls.
 *    i.e. for item.read(id), if the client makes server call to discover endpoints it would be considered as metadata call.
 *   - retries
 *   - endpoints contacted.
 *   - request, response payload stats.
 *   - gatewayStatistics - Information corresponding to main operation. For example during Item.read(), the client might perform many operations
 *    i.e. metadata lookup etc, but gatewayStatistics represents the diagnostics information for actual read operation.
 *
 * 2. diagnosticNode - Is a tree like structure which captures detailed diagnostic information. By default it is disabled, and is intended to be
 * used only for debugging on non production environments. The kind of details captured in diagnosticNode is controlled by `CosmosDbDiagnosticLevel`.
 * - CosmosDbDiagnosticLevel.info - Is default value. In this level only clientSideRequestStatistics are captured. Is is meant for production environments.
 * - CosmosDbDiagnosticLevel.debug - Captures diagnosticNode and clientConfig. No request and response payloads are captured. Is not meant to be used
 * in production environment.
 * - CosmosDbDiagnosticLevel.debug-unsafe - In addition to data captured in CosmosDbDiagnosticLevel.debug, also captures request and response payloads.
 * Is not meant to be used in production environment.
 * 3. clientConfig - Captures information related to how client was configured during initialization.
 */
class CosmosDiagnostics {
    /**
     * @internal
     */
    constructor(clientSideRequestStatistics, diagnosticNode, clientConfig) {
        this.clientSideRequestStatistics = clientSideRequestStatistics;
        this.diagnosticNode = diagnosticNode;
        this.clientConfig = clientConfig;
    }
}
/**
 * This is enum for Type of Metadata lookups possible.
 */
exports.MetadataLookUpType = void 0;
(function (MetadataLookUpType) {
    MetadataLookUpType["PartitionKeyRangeLookUp"] = "PARTITION_KEY_RANGE_LOOK_UP";
    MetadataLookUpType["DatabaseAccountLookUp"] = "DATABASE_ACCOUNT_LOOK_UP";
    MetadataLookUpType["QueryPlanLookUp"] = "QUERY_PLAN_LOOK_UP";
    MetadataLookUpType["DatabaseLookUp"] = "DATABASE_LOOK_UP";
    MetadataLookUpType["ContainerLookUp"] = "CONTAINER_LOOK_UP";
})(exports.MetadataLookUpType || (exports.MetadataLookUpType = {}));
function getRootNode(node) {
    if (node.parent)
        return getRootNode(node.parent);
    else
        return node;
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @hidden
 * Utility function to get currentTime in UTC milliseconds.
 * @returns
 */
function getCurrentTimestampInMs() {
    return Date.now();
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @hidden
 * Internal class to hold CosmosDiagnostic aggregate information all through the lifecycle of a request.
 * This object gathers diagnostic information throughout Client operation which may span across multiple
 * Server call, retries etc.
 * Functions - recordFailedAttempt, recordMetaDataQuery, recordEndpointContactEvent are used to ingest
 * data into the context. At the end of operation, getDiagnostics() is used to
 * get final CosmosDiagnostic object.
 */
class CosmosDiagnosticContext {
    constructor() {
        this.failedAttempts = [];
        this.metadataLookups = [];
        this.gaterwayStatistics = [];
        this.locationEndpointsContacted = new Set();
        this.requestStartTimeUTCinMs = getCurrentTimestampInMs();
    }
    recordFailedAttempt(gaterwayStatistics, retryAttemptNumber) {
        const attempt = {
            attemptNumber: retryAttemptNumber,
            startTimeUTCInMs: gaterwayStatistics.startTimeUTCInMs,
            durationInMs: gaterwayStatistics.durationInMs,
            statusCode: gaterwayStatistics.statusCode,
            substatusCode: gaterwayStatistics.subStatusCode,
            requestPayloadLengthInBytes: gaterwayStatistics.requestPayloadLengthInBytes,
            responsePayloadLengthInBytes: gaterwayStatistics.responsePayloadLengthInBytes,
            activityId: gaterwayStatistics.activityId,
            operationType: gaterwayStatistics.operationType,
            resourceType: gaterwayStatistics.resourceType,
        };
        this.failedAttempts.push(attempt);
    }
    recordNetworkCall(gaterwayStatistics) {
        this.gaterwayStatistics.push(gaterwayStatistics);
    }
    recordEncryptionDiagnostics(encryptionDiagnostics) {
        var _a, _b;
        const { encryptContent, decryptContent } = encryptionDiagnostics;
        const encryptionDuration = (_a = encryptContent[Constants.Encryption.DiagnosticsDuration]) !== null && _a !== void 0 ? _a : 0;
        const decryptionDuration = (_b = decryptContent[Constants.Encryption.DiagnosticsDuration]) !== null && _b !== void 0 ? _b : 0;
        encryptionDiagnostics.processingDurationInMs = encryptionDuration + decryptionDuration;
        this.encryptionDiagnostics = encryptionDiagnostics;
    }
    /**
     * Merge given DiagnosticContext to current node's DiagnosticContext, Treating GatewayRequests of
     * given DiagnosticContext, as metadata requests.
     */
    mergeDiagnostics(childDiagnostics, metadataType) {
        // Copy Location endpoints contacted.
        childDiagnostics.locationEndpointsContacted.forEach((endpoint) => this.locationEndpointsContacted.add(endpoint));
        // Copy child nodes's GatewayStatistics to parent's metadata lookups.
        childDiagnostics.gaterwayStatistics.forEach((gateway) => this.metadataLookups.push({
            activityId: gateway.activityId,
            requestPayloadLengthInBytes: gateway.requestPayloadLengthInBytes,
            responsePayloadLengthInBytes: gateway.responsePayloadLengthInBytes,
            startTimeUTCInMs: gateway.startTimeUTCInMs,
            operationType: gateway.operationType,
            resourceType: gateway.resourceType,
            durationInMs: gateway.durationInMs,
            metaDataType: metadataType,
        }));
        // Copy child nodes's metadata lookups to parent's metadata lookups.
        childDiagnostics.metadataLookups.forEach((lookup) => this.metadataLookups.push(lookup));
        // Copy child nodes's failed attempts to parent's failed attempts.
        childDiagnostics.failedAttempts.forEach((lookup) => this.failedAttempts.push(lookup));
    }
    getClientSideStats(endTimeUTCInMs = getCurrentTimestampInMs()) {
        return {
            requestStartTimeUTCInMs: this.requestStartTimeUTCinMs,
            requestDurationInMs: endTimeUTCInMs - this.requestStartTimeUTCinMs,
            totalRequestPayloadLengthInBytes: this.getTotalRequestPayloadLength(),
            totalResponsePayloadLengthInBytes: this.getTotalResponsePayloadLength(),
            locationEndpointsContacted: [...this.locationEndpointsContacted.values()],
            metadataDiagnostics: {
                metadataLookups: [...this.metadataLookups],
            },
            retryDiagnostics: {
                failedAttempts: [...this.failedAttempts],
            },
            gatewayStatistics: this.gaterwayStatistics,
            encryptionDiagnostics: this.encryptionDiagnostics,
        };
    }
    getTotalRequestPayloadLength() {
        let totalRequestPayloadLength = 0;
        this.gaterwayStatistics.forEach((req) => (totalRequestPayloadLength += req.requestPayloadLengthInBytes));
        this.metadataLookups.forEach((req) => (totalRequestPayloadLength += req.requestPayloadLengthInBytes));
        this.failedAttempts.forEach((req) => (totalRequestPayloadLength += req.requestPayloadLengthInBytes));
        return totalRequestPayloadLength;
    }
    getTotalResponsePayloadLength() {
        let totalResponsePayloadLength = 0;
        this.gaterwayStatistics.forEach((req) => (totalResponsePayloadLength += req.responsePayloadLengthInBytes));
        this.metadataLookups.forEach((req) => (totalResponsePayloadLength += req.responsePayloadLengthInBytes));
        this.failedAttempts.forEach((req) => (totalResponsePayloadLength += req.responsePayloadLengthInBytes));
        return totalResponsePayloadLength;
    }
    recordEndpointResolution(location) {
        this.locationEndpointsContacted.add(location);
    }
}

class ResourceResponse {
    constructor(resource, headers, statusCode, diagnostics, substatus) {
        this.resource = resource;
        this.headers = headers;
        this.statusCode = statusCode;
        this.diagnostics = diagnostics;
        this.substatus = substatus;
    }
    get requestCharge() {
        return Number(this.headers[Constants.HttpHeaders.RequestCharge]) || 0;
    }
    get activityId() {
        return this.headers[Constants.HttpHeaders.ActivityId];
    }
    get etag() {
        return this.headers[Constants.HttpHeaders.ETag];
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
class ClientSideMetrics {
    constructor(requestCharge) {
        this.requestCharge = requestCharge;
    }
    /**
     * Adds one or more ClientSideMetrics to a copy of this instance and returns the result.
     */
    add(...clientSideMetricsArray) {
        let requestCharge = this.requestCharge;
        for (const clientSideMetrics of clientSideMetricsArray) {
            if (clientSideMetrics == null) {
                throw new Error("clientSideMetrics has null or undefined item(s)");
            }
            requestCharge += clientSideMetrics.requestCharge;
        }
        return new ClientSideMetrics(requestCharge);
    }
    static createFromArray(...clientSideMetricsArray) {
        if (clientSideMetricsArray == null) {
            throw new Error("clientSideMetricsArray is null or undefined item(s)");
        }
        return this.zero.add(...clientSideMetricsArray);
    }
}
ClientSideMetrics.zero = new ClientSideMetrics(0);

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
var QueryMetricsConstants = {
    // QueryMetrics
    RetrievedDocumentCount: "retrievedDocumentCount",
    RetrievedDocumentSize: "retrievedDocumentSize",
    OutputDocumentCount: "outputDocumentCount",
    OutputDocumentSize: "outputDocumentSize",
    IndexHitRatio: "indexUtilizationRatio",
    IndexHitDocumentCount: "indexHitDocumentCount",
    TotalQueryExecutionTimeInMs: "totalExecutionTimeInMs",
    // QueryPreparationTimes
    QueryCompileTimeInMs: "queryCompileTimeInMs",
    LogicalPlanBuildTimeInMs: "queryLogicalPlanBuildTimeInMs",
    PhysicalPlanBuildTimeInMs: "queryPhysicalPlanBuildTimeInMs",
    QueryOptimizationTimeInMs: "queryOptimizationTimeInMs",
    // QueryTimes
    IndexLookupTimeInMs: "indexLookupTimeInMs",
    DocumentLoadTimeInMs: "documentLoadTimeInMs",
    VMExecutionTimeInMs: "VMExecutionTimeInMs",
    DocumentWriteTimeInMs: "writeOutputTimeInMs",
    // RuntimeExecutionTimes
    QueryEngineTimes: "queryEngineTimes",
    SystemFunctionExecuteTimeInMs: "systemFunctionExecuteTimeInMs",
    UserDefinedFunctionExecutionTimeInMs: "userFunctionExecuteTimeInMs",
    // QueryMetrics Text
    RetrievedDocumentCountText: "Retrieved Document Count",
    RetrievedDocumentSizeText: "Retrieved Document Size",
    OutputDocumentCountText: "Output Document Count",
    OutputDocumentSizeText: "Output Document Size",
    IndexUtilizationText: "Index Utilization",
    TotalQueryExecutionTimeText: "Total Query Execution Time",
    // QueryPreparationTimes Text
    QueryPreparationTimesText: "Query Preparation Times",
    QueryCompileTimeText: "Query Compilation Time",
    LogicalPlanBuildTimeText: "Logical Plan Build Time",
    PhysicalPlanBuildTimeText: "Physical Plan Build Time",
    QueryOptimizationTimeText: "Query Optimization Time",
    // QueryTimes Text
    QueryEngineTimesText: "Query Engine Times",
    IndexLookupTimeText: "Index Lookup Time",
    DocumentLoadTimeText: "Document Load Time",
    WriteOutputTimeText: "Document Write Time",
    // RuntimeExecutionTimes Text
    RuntimeExecutionTimesText: "Runtime Execution Times",
    TotalExecutionTimeText: "Query Engine Execution Time",
    SystemFunctionExecuteTimeText: "System Function Execution Time",
    UserDefinedFunctionExecutionTimeText: "User-defined Function Execution Time",
    // ClientSideQueryMetrics Text
    ClientSideQueryMetricsText: "Client Side Metrics",
    RetriesText: "Retry Count",
    RequestChargeText: "Request Charge",
    FetchExecutionRangesText: "Partition Execution Timeline",
    SchedulingMetricsText: "Scheduling Metrics",
};

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
// Ported this implementation to javascript:
// https://referencesource.microsoft.com/#mscorlib/system/timespan.cs,83e476c1ae112117
/** @hidden */
// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
const ticksPerMillisecond = 10000;
/** @hidden */
const millisecondsPerTick = 1.0 / ticksPerMillisecond;
/** @hidden */
const ticksPerSecond = ticksPerMillisecond * 1000; // 10,000,000
/** @hidden */
const secondsPerTick = 1.0 / ticksPerSecond; // 0.0001
/** @hidden */
const ticksPerMinute = ticksPerSecond * 60; // 600,000,000
/** @hidden */
const minutesPerTick = 1.0 / ticksPerMinute; // 1.6666666666667e-9
/** @hidden */
const ticksPerHour = ticksPerMinute * 60; // 36,000,000,000
/** @hidden */
const hoursPerTick = 1.0 / ticksPerHour; // 2.77777777777777778e-11
/** @hidden */
const ticksPerDay = ticksPerHour * 24; // 864,000,000,000
/** @hidden */
const daysPerTick = 1.0 / ticksPerDay; // 1.1574074074074074074e-12
/** @hidden */
const millisPerSecond = 1000;
/** @hidden */
const millisPerMinute = millisPerSecond * 60; //     60,000
/** @hidden */
const millisPerHour = millisPerMinute * 60; //  3,600,000
/** @hidden */
const millisPerDay = millisPerHour * 24; // 86,400,000
/** @hidden */
const maxMilliSeconds = Number.MAX_SAFE_INTEGER / ticksPerMillisecond;
/** @hidden */
const minMilliSeconds = Number.MIN_SAFE_INTEGER / ticksPerMillisecond;
/**
 * Represents a time interval.
 *
 * @param days                 - Number of days.
 * @param hours                - Number of hours.
 * @param minutes              - Number of minutes.
 * @param seconds              - Number of seconds.
 * @param milliseconds         - Number of milliseconds.
 * @hidden
 */
class TimeSpan {
    constructor(days, hours, minutes, seconds, milliseconds) {
        // Constructor
        if (!Number.isInteger(days)) {
            throw new Error("days is not an integer");
        }
        if (!Number.isInteger(hours)) {
            throw new Error("hours is not an integer");
        }
        if (!Number.isInteger(minutes)) {
            throw new Error("minutes is not an integer");
        }
        if (!Number.isInteger(seconds)) {
            throw new Error("seconds is not an integer");
        }
        if (!Number.isInteger(milliseconds)) {
            throw new Error("milliseconds is not an integer");
        }
        const totalMilliSeconds = (days * 3600 * 24 + hours * 3600 + minutes * 60 + seconds) * 1000 + milliseconds;
        if (totalMilliSeconds > maxMilliSeconds || totalMilliSeconds < minMilliSeconds) {
            throw new Error("Total number of milliseconds was either too large or too small");
        }
        this._ticks = totalMilliSeconds * ticksPerMillisecond;
    }
    /**
     * Returns a new TimeSpan object whose value is the sum of the specified TimeSpan object and this instance.
     * @param ts - The time interval to add.
     */
    add(ts) {
        if (TimeSpan.additionDoesOverflow(this._ticks, ts._ticks)) {
            throw new Error("Adding the two timestamps causes an overflow.");
        }
        const results = this._ticks + ts._ticks;
        return TimeSpan.fromTicks(results);
    }
    /**
     * Returns a new TimeSpan object whose value is the difference of the specified TimeSpan object and this instance.
     * @param ts - The time interval to subtract.
     */
    subtract(ts) {
        if (TimeSpan.subtractionDoesUnderflow(this._ticks, ts._ticks)) {
            throw new Error("Subtracting the two timestamps causes an underflow.");
        }
        const results = this._ticks - ts._ticks;
        return TimeSpan.fromTicks(results);
    }
    /**
     * Compares this instance to a specified object and returns an integer that indicates whether this
     * instance is shorter than, equal to, or longer than the specified object.
     * @param value - The time interval to add.
     */
    compareTo(value) {
        if (value == null) {
            return 1;
        }
        if (!TimeSpan.isTimeSpan(value)) {
            throw new Error("Argument must be a TimeSpan object");
        }
        return TimeSpan.compare(this, value);
    }
    /**
     * Returns a new TimeSpan object whose value is the absolute value of the current TimeSpan object.
     */
    duration() {
        return TimeSpan.fromTicks(this._ticks >= 0 ? this._ticks : -this._ticks);
    }
    /**
     * Returns a value indicating whether this instance is equal to a specified object.
     * @param value - The time interval to check for equality.
     */
    equals(value) {
        if (TimeSpan.isTimeSpan(value)) {
            return this._ticks === value._ticks;
        }
        return false;
    }
    /**
     * Returns a new TimeSpan object whose value is the negated value of this instance.
     * @param value - The time interval to check for equality.
     */
    negate() {
        return TimeSpan.fromTicks(-this._ticks);
    }
    days() {
        return Math.floor(this._ticks / ticksPerDay);
    }
    hours() {
        return Math.floor(this._ticks / ticksPerHour);
    }
    milliseconds() {
        return Math.floor(this._ticks / ticksPerMillisecond);
    }
    seconds() {
        return Math.floor(this._ticks / ticksPerSecond);
    }
    ticks() {
        return this._ticks;
    }
    totalDays() {
        return this._ticks * daysPerTick;
    }
    totalHours() {
        return this._ticks * hoursPerTick;
    }
    totalMilliseconds() {
        return this._ticks * millisecondsPerTick;
    }
    totalMinutes() {
        return this._ticks * minutesPerTick;
    }
    totalSeconds() {
        return this._ticks * secondsPerTick;
    }
    static fromTicks(value) {
        const timeSpan = new TimeSpan(0, 0, 0, 0, 0);
        timeSpan._ticks = value;
        return timeSpan;
    }
    static isTimeSpan(timespan) {
        return timespan._ticks;
    }
    static additionDoesOverflow(a, b) {
        const c = a + b;
        return a !== c - b || b !== c - a;
    }
    static subtractionDoesUnderflow(a, b) {
        const c = a - b;
        return a !== c + b || b !== a - c;
    }
    static compare(t1, t2) {
        if (t1._ticks > t2._ticks) {
            return 1;
        }
        if (t1._ticks < t2._ticks) {
            return -1;
        }
        return 0;
    }
    static interval(value, scale) {
        if (isNaN(value)) {
            throw new Error("value must be a number");
        }
        const milliseconds = value * scale;
        if (milliseconds > maxMilliSeconds || milliseconds < minMilliSeconds) {
            throw new Error("timespan too long");
        }
        return TimeSpan.fromTicks(Math.floor(milliseconds * ticksPerMillisecond));
    }
    static fromMilliseconds(value) {
        return TimeSpan.interval(value, 1);
    }
    static fromSeconds(value) {
        return TimeSpan.interval(value, millisPerSecond);
    }
    static fromMinutes(value) {
        return TimeSpan.interval(value, millisPerMinute);
    }
    static fromHours(value) {
        return TimeSpan.interval(value, millisPerHour);
    }
    static fromDays(value) {
        return TimeSpan.interval(value, millisPerDay);
    }
}
TimeSpan.zero = new TimeSpan(0, 0, 0, 0, 0);
TimeSpan.maxValue = TimeSpan.fromTicks(Number.MAX_SAFE_INTEGER);
TimeSpan.minValue = TimeSpan.fromTicks(Number.MIN_SAFE_INTEGER);

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @hidden
 */
function parseDelimitedString(delimitedString) {
    if (delimitedString == null) {
        throw new Error("delimitedString is null or undefined");
    }
    const metrics = {};
    const headerAttributes = delimitedString.split(";");
    for (const attribute of headerAttributes) {
        const attributeKeyValue = attribute.split("=");
        if (attributeKeyValue.length !== 2) {
            throw new Error("recieved a malformed delimited string");
        }
        const attributeKey = attributeKeyValue[0];
        const attributeValue = parseFloat(attributeKeyValue[1]);
        metrics[attributeKey] = attributeValue;
    }
    return metrics;
}
/**
 * @hidden
 */
function timeSpanFromMetrics(metrics /* TODO: any */, key) {
    if (key in metrics) {
        return TimeSpan.fromMilliseconds(metrics[key]);
    }
    return TimeSpan.zero;
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
class QueryPreparationTimes {
    constructor(queryCompilationTime, logicalPlanBuildTime, physicalPlanBuildTime, queryOptimizationTime) {
        this.queryCompilationTime = queryCompilationTime;
        this.logicalPlanBuildTime = logicalPlanBuildTime;
        this.physicalPlanBuildTime = physicalPlanBuildTime;
        this.queryOptimizationTime = queryOptimizationTime;
    }
    /**
     * returns a new QueryPreparationTimes instance that is the addition of this and the arguments.
     */
    add(...queryPreparationTimesArray) {
        let queryCompilationTime = this.queryCompilationTime;
        let logicalPlanBuildTime = this.logicalPlanBuildTime;
        let physicalPlanBuildTime = this.physicalPlanBuildTime;
        let queryOptimizationTime = this.queryOptimizationTime;
        for (const queryPreparationTimes of queryPreparationTimesArray) {
            if (queryPreparationTimes == null) {
                throw new Error("queryPreparationTimesArray has null or undefined item(s)");
            }
            queryCompilationTime = queryCompilationTime.add(queryPreparationTimes.queryCompilationTime);
            logicalPlanBuildTime = logicalPlanBuildTime.add(queryPreparationTimes.logicalPlanBuildTime);
            physicalPlanBuildTime = physicalPlanBuildTime.add(queryPreparationTimes.physicalPlanBuildTime);
            queryOptimizationTime = queryOptimizationTime.add(queryPreparationTimes.queryOptimizationTime);
        }
        return new QueryPreparationTimes(queryCompilationTime, logicalPlanBuildTime, physicalPlanBuildTime, queryOptimizationTime);
    }
    /**
     * Output the QueryPreparationTimes as a delimited string.
     */
    toDelimitedString() {
        return (`${QueryMetricsConstants.QueryCompileTimeInMs}=${this.queryCompilationTime.totalMilliseconds()};` +
            `${QueryMetricsConstants.LogicalPlanBuildTimeInMs}=${this.logicalPlanBuildTime.totalMilliseconds()};` +
            `${QueryMetricsConstants.PhysicalPlanBuildTimeInMs}=${this.physicalPlanBuildTime.totalMilliseconds()};` +
            `${QueryMetricsConstants.QueryOptimizationTimeInMs}=${this.queryOptimizationTime.totalMilliseconds()}`);
    }
    /**
     * Returns a new instance of the QueryPreparationTimes class that is the
     * aggregation of an array of QueryPreparationTimes.
     */
    static createFromArray(queryPreparationTimesArray) {
        if (queryPreparationTimesArray == null) {
            throw new Error("queryPreparationTimesArray is null or undefined item(s)");
        }
        return QueryPreparationTimes.zero.add(...queryPreparationTimesArray);
    }
    /**
     * Returns a new instance of the QueryPreparationTimes class this is deserialized from a delimited string.
     */
    static createFromDelimitedString(delimitedString) {
        const metrics = parseDelimitedString(delimitedString);
        return new QueryPreparationTimes(timeSpanFromMetrics(metrics, QueryMetricsConstants.QueryCompileTimeInMs), timeSpanFromMetrics(metrics, QueryMetricsConstants.LogicalPlanBuildTimeInMs), timeSpanFromMetrics(metrics, QueryMetricsConstants.PhysicalPlanBuildTimeInMs), timeSpanFromMetrics(metrics, QueryMetricsConstants.QueryOptimizationTimeInMs));
    }
}
QueryPreparationTimes.zero = new QueryPreparationTimes(TimeSpan.zero, TimeSpan.zero, TimeSpan.zero, TimeSpan.zero);

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
class RuntimeExecutionTimes {
    constructor(queryEngineExecutionTime, systemFunctionExecutionTime, userDefinedFunctionExecutionTime) {
        this.queryEngineExecutionTime = queryEngineExecutionTime;
        this.systemFunctionExecutionTime = systemFunctionExecutionTime;
        this.userDefinedFunctionExecutionTime = userDefinedFunctionExecutionTime;
    }
    /**
     * returns a new RuntimeExecutionTimes instance that is the addition of this and the arguments.
     */
    add(...runtimeExecutionTimesArray) {
        let queryEngineExecutionTime = this.queryEngineExecutionTime;
        let systemFunctionExecutionTime = this.systemFunctionExecutionTime;
        let userDefinedFunctionExecutionTime = this.userDefinedFunctionExecutionTime;
        for (const runtimeExecutionTimes of runtimeExecutionTimesArray) {
            if (runtimeExecutionTimes == null) {
                throw new Error("runtimeExecutionTimes has null or undefined item(s)");
            }
            queryEngineExecutionTime = queryEngineExecutionTime.add(runtimeExecutionTimes.queryEngineExecutionTime);
            systemFunctionExecutionTime = systemFunctionExecutionTime.add(runtimeExecutionTimes.systemFunctionExecutionTime);
            userDefinedFunctionExecutionTime = userDefinedFunctionExecutionTime.add(runtimeExecutionTimes.userDefinedFunctionExecutionTime);
        }
        return new RuntimeExecutionTimes(queryEngineExecutionTime, systemFunctionExecutionTime, userDefinedFunctionExecutionTime);
    }
    /**
     * Output the RuntimeExecutionTimes as a delimited string.
     */
    toDelimitedString() {
        return (`${QueryMetricsConstants.SystemFunctionExecuteTimeInMs}=${this.systemFunctionExecutionTime.totalMilliseconds()};` +
            `${QueryMetricsConstants.UserDefinedFunctionExecutionTimeInMs}=${this.userDefinedFunctionExecutionTime.totalMilliseconds()}`);
    }
    /**
     * Returns a new instance of the RuntimeExecutionTimes class that is
     *  the aggregation of an array of RuntimeExecutionTimes.
     */
    static createFromArray(runtimeExecutionTimesArray) {
        if (runtimeExecutionTimesArray == null) {
            throw new Error("runtimeExecutionTimesArray is null or undefined item(s)");
        }
        return RuntimeExecutionTimes.zero.add(...runtimeExecutionTimesArray);
    }
    /**
     * Returns a new instance of the RuntimeExecutionTimes class this is deserialized from a delimited string.
     */
    static createFromDelimitedString(delimitedString) {
        const metrics = parseDelimitedString(delimitedString);
        const vmExecutionTime = timeSpanFromMetrics(metrics, QueryMetricsConstants.VMExecutionTimeInMs);
        const indexLookupTime = timeSpanFromMetrics(metrics, QueryMetricsConstants.IndexLookupTimeInMs);
        const documentLoadTime = timeSpanFromMetrics(metrics, QueryMetricsConstants.DocumentLoadTimeInMs);
        const documentWriteTime = timeSpanFromMetrics(metrics, QueryMetricsConstants.DocumentWriteTimeInMs);
        let queryEngineExecutionTime = TimeSpan.zero;
        queryEngineExecutionTime = queryEngineExecutionTime.add(vmExecutionTime);
        queryEngineExecutionTime = queryEngineExecutionTime.subtract(indexLookupTime);
        queryEngineExecutionTime = queryEngineExecutionTime.subtract(documentLoadTime);
        queryEngineExecutionTime = queryEngineExecutionTime.subtract(documentWriteTime);
        return new RuntimeExecutionTimes(queryEngineExecutionTime, timeSpanFromMetrics(metrics, QueryMetricsConstants.SystemFunctionExecuteTimeInMs), timeSpanFromMetrics(metrics, QueryMetricsConstants.UserDefinedFunctionExecutionTimeInMs));
    }
}
RuntimeExecutionTimes.zero = new RuntimeExecutionTimes(TimeSpan.zero, TimeSpan.zero, TimeSpan.zero);

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
class QueryMetrics {
    constructor(retrievedDocumentCount, retrievedDocumentSize, outputDocumentCount, outputDocumentSize, indexHitDocumentCount, totalQueryExecutionTime, queryPreparationTimes, indexLookupTime, documentLoadTime, vmExecutionTime, runtimeExecutionTimes, documentWriteTime, clientSideMetrics) {
        this.retrievedDocumentCount = retrievedDocumentCount;
        this.retrievedDocumentSize = retrievedDocumentSize;
        this.outputDocumentCount = outputDocumentCount;
        this.outputDocumentSize = outputDocumentSize;
        this.indexHitDocumentCount = indexHitDocumentCount;
        this.totalQueryExecutionTime = totalQueryExecutionTime;
        this.queryPreparationTimes = queryPreparationTimes;
        this.indexLookupTime = indexLookupTime;
        this.documentLoadTime = documentLoadTime;
        this.vmExecutionTime = vmExecutionTime;
        this.runtimeExecutionTimes = runtimeExecutionTimes;
        this.documentWriteTime = documentWriteTime;
        this.clientSideMetrics = clientSideMetrics;
    }
    /**
     * Gets the IndexHitRatio
     * @hidden
     */
    get indexHitRatio() {
        return this.retrievedDocumentCount === 0
            ? 1
            : this.indexHitDocumentCount / this.retrievedDocumentCount;
    }
    /**
     * returns a new QueryMetrics instance that is the addition of this and the arguments.
     */
    add(queryMetricsArray) {
        let retrievedDocumentCount = 0;
        let retrievedDocumentSize = 0;
        let outputDocumentCount = 0;
        let outputDocumentSize = 0;
        let indexHitDocumentCount = 0;
        let totalQueryExecutionTime = TimeSpan.zero;
        const queryPreparationTimesArray = [];
        let indexLookupTime = TimeSpan.zero;
        let documentLoadTime = TimeSpan.zero;
        let vmExecutionTime = TimeSpan.zero;
        const runtimeExecutionTimesArray = [];
        let documentWriteTime = TimeSpan.zero;
        const clientSideQueryMetricsArray = [];
        queryMetricsArray.push(this);
        for (const queryMetrics of queryMetricsArray) {
            if (queryMetrics) {
                retrievedDocumentCount += queryMetrics.retrievedDocumentCount;
                retrievedDocumentSize += queryMetrics.retrievedDocumentSize;
                outputDocumentCount += queryMetrics.outputDocumentCount;
                outputDocumentSize += queryMetrics.outputDocumentSize;
                indexHitDocumentCount += queryMetrics.indexHitDocumentCount;
                totalQueryExecutionTime = totalQueryExecutionTime.add(queryMetrics.totalQueryExecutionTime);
                queryPreparationTimesArray.push(queryMetrics.queryPreparationTimes);
                indexLookupTime = indexLookupTime.add(queryMetrics.indexLookupTime);
                documentLoadTime = documentLoadTime.add(queryMetrics.documentLoadTime);
                vmExecutionTime = vmExecutionTime.add(queryMetrics.vmExecutionTime);
                runtimeExecutionTimesArray.push(queryMetrics.runtimeExecutionTimes);
                documentWriteTime = documentWriteTime.add(queryMetrics.documentWriteTime);
                clientSideQueryMetricsArray.push(queryMetrics.clientSideMetrics);
            }
        }
        return new QueryMetrics(retrievedDocumentCount, retrievedDocumentSize, outputDocumentCount, outputDocumentSize, indexHitDocumentCount, totalQueryExecutionTime, QueryPreparationTimes.createFromArray(queryPreparationTimesArray), indexLookupTime, documentLoadTime, vmExecutionTime, RuntimeExecutionTimes.createFromArray(runtimeExecutionTimesArray), documentWriteTime, ClientSideMetrics.createFromArray(...clientSideQueryMetricsArray));
    }
    /**
     * Output the QueryMetrics as a delimited string.
     * @hidden
     */
    toDelimitedString() {
        return (QueryMetricsConstants.RetrievedDocumentCount +
            "=" +
            this.retrievedDocumentCount +
            ";" +
            QueryMetricsConstants.RetrievedDocumentSize +
            "=" +
            this.retrievedDocumentSize +
            ";" +
            QueryMetricsConstants.OutputDocumentCount +
            "=" +
            this.outputDocumentCount +
            ";" +
            QueryMetricsConstants.OutputDocumentSize +
            "=" +
            this.outputDocumentSize +
            ";" +
            QueryMetricsConstants.IndexHitRatio +
            "=" +
            this.indexHitRatio +
            ";" +
            QueryMetricsConstants.TotalQueryExecutionTimeInMs +
            "=" +
            this.totalQueryExecutionTime.totalMilliseconds() +
            ";" +
            this.queryPreparationTimes.toDelimitedString() +
            ";" +
            QueryMetricsConstants.IndexLookupTimeInMs +
            "=" +
            this.indexLookupTime.totalMilliseconds() +
            ";" +
            QueryMetricsConstants.DocumentLoadTimeInMs +
            "=" +
            this.documentLoadTime.totalMilliseconds() +
            ";" +
            QueryMetricsConstants.VMExecutionTimeInMs +
            "=" +
            this.vmExecutionTime.totalMilliseconds() +
            ";" +
            this.runtimeExecutionTimes.toDelimitedString() +
            ";" +
            QueryMetricsConstants.DocumentWriteTimeInMs +
            "=" +
            this.documentWriteTime.totalMilliseconds());
    }
    /**
     * Returns a new instance of the QueryMetrics class that is the aggregation of an array of query metrics.
     */
    static createFromArray(queryMetricsArray) {
        if (!queryMetricsArray) {
            throw new Error("queryMetricsArray is null or undefined item(s)");
        }
        return QueryMetrics.zero.add(queryMetricsArray);
    }
    /**
     * Returns a new instance of the QueryMetrics class this is deserialized from a delimited string.
     */
    static createFromDelimitedString(delimitedString, clientSideMetrics) {
        const metrics = parseDelimitedString(delimitedString);
        const indexHitRatio = metrics[QueryMetricsConstants.IndexHitRatio] || 0;
        const retrievedDocumentCount = metrics[QueryMetricsConstants.RetrievedDocumentCount] || 0;
        const indexHitCount = indexHitRatio * retrievedDocumentCount;
        const outputDocumentCount = metrics[QueryMetricsConstants.OutputDocumentCount] || 0;
        const outputDocumentSize = metrics[QueryMetricsConstants.OutputDocumentSize] || 0;
        const retrievedDocumentSize = metrics[QueryMetricsConstants.RetrievedDocumentSize] || 0;
        const totalQueryExecutionTime = timeSpanFromMetrics(metrics, QueryMetricsConstants.TotalQueryExecutionTimeInMs);
        return new QueryMetrics(retrievedDocumentCount, retrievedDocumentSize, outputDocumentCount, outputDocumentSize, indexHitCount, totalQueryExecutionTime, QueryPreparationTimes.createFromDelimitedString(delimitedString), timeSpanFromMetrics(metrics, QueryMetricsConstants.IndexLookupTimeInMs), timeSpanFromMetrics(metrics, QueryMetricsConstants.DocumentLoadTimeInMs), timeSpanFromMetrics(metrics, QueryMetricsConstants.VMExecutionTimeInMs), RuntimeExecutionTimes.createFromDelimitedString(delimitedString), timeSpanFromMetrics(metrics, QueryMetricsConstants.DocumentWriteTimeInMs), clientSideMetrics || ClientSideMetrics.zero);
    }
}
QueryMetrics.zero = new QueryMetrics(0, 0, 0, 0, 0, TimeSpan.zero, QueryPreparationTimes.zero, TimeSpan.zero, TimeSpan.zero, TimeSpan.zero, RuntimeExecutionTimes.zero, TimeSpan.zero, ClientSideMetrics.zero);

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/** @hidden */
// TODO: docs
function getRequestChargeIfAny(headers) {
    if (typeof headers === "number") {
        return headers;
    }
    else if (typeof headers === "string") {
        return parseFloat(headers);
    }
    if (headers) {
        const rc = headers[Constants.HttpHeaders.RequestCharge];
        if (rc) {
            return parseFloat(rc);
        }
        else {
            return 0;
        }
    }
    else {
        return 0;
    }
}
/**
 * @hidden
 */
function getInitialHeader() {
    const headers = {};
    headers[Constants.HttpHeaders.RequestCharge] = 0;
    headers[Constants.HttpHeaders.QueryMetrics] = {};
    return headers;
}
/**
 * @hidden
 */
// TODO: The name of this method isn't very accurate to what it does
function mergeHeaders(headers, toBeMergedHeaders) {
    if (headers[Constants.HttpHeaders.RequestCharge] === undefined) {
        headers[Constants.HttpHeaders.RequestCharge] = 0;
    }
    if (headers[Constants.HttpHeaders.QueryMetrics] === undefined) {
        headers[Constants.HttpHeaders.QueryMetrics] = QueryMetrics.zero;
    }
    if (!toBeMergedHeaders) {
        return;
    }
    headers[Constants.HttpHeaders.RequestCharge] += getRequestChargeIfAny(toBeMergedHeaders);
    if (toBeMergedHeaders[Constants.HttpHeaders.IsRUPerMinuteUsed]) {
        headers[Constants.HttpHeaders.IsRUPerMinuteUsed] =
            toBeMergedHeaders[Constants.HttpHeaders.IsRUPerMinuteUsed];
    }
    if (Constants.HttpHeaders.QueryMetrics in toBeMergedHeaders) {
        const headerQueryMetrics = headers[Constants.HttpHeaders.QueryMetrics];
        const toBeMergedHeaderQueryMetrics = toBeMergedHeaders[Constants.HttpHeaders.QueryMetrics];
        for (const partitionId in toBeMergedHeaderQueryMetrics) {
            if (headerQueryMetrics[partitionId]) {
                const combinedQueryMetrics = headerQueryMetrics[partitionId].add([
                    toBeMergedHeaderQueryMetrics[partitionId],
                ]);
                headerQueryMetrics[partitionId] = combinedQueryMetrics;
            }
            else {
                headerQueryMetrics[partitionId] = toBeMergedHeaderQueryMetrics[partitionId];
            }
        }
    }
    if (Constants.HttpHeaders.IndexUtilization in toBeMergedHeaders) {
        headers[Constants.HttpHeaders.IndexUtilization] =
            toBeMergedHeaders[Constants.HttpHeaders.IndexUtilization];
    }
    if (Constants.HttpHeaders.CorrelatedActivityId in toBeMergedHeaders) {
        headers[Constants.HttpHeaders.CorrelatedActivityId] =
            toBeMergedHeaders[Constants.HttpHeaders.CorrelatedActivityId];
    }
}
/** @hidden */
function decodeAndParseJSONString(inputString) {
    try {
        if (!inputString || inputString === "") {
            return "{}";
        }
        const decodedString = decodeURIComponent(inputString);
        const parsedString = JSON.parse(decodedString);
        const indexMetrics = JSON.stringify(parsedString);
        return indexMetrics;
    }
    catch (e) {
        console.error("Error parsing JSON file:", e.message);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
class FeedResponse {
    constructor(resources, headers, hasMoreResults, diagnostics) {
        this.resources = resources;
        this.headers = headers;
        this.hasMoreResults = hasMoreResults;
        this.diagnostics = diagnostics;
    }
    get continuation() {
        return this.continuationToken;
    }
    get continuationToken() {
        return this.headers[Constants.HttpHeaders.Continuation];
    }
    get queryMetrics() {
        return this.headers[Constants.HttpHeaders.QueryMetrics];
    }
    get requestCharge() {
        return getRequestChargeIfAny(this.headers);
    }
    get activityId() {
        return this.headers[Constants.HttpHeaders.ActivityId];
    }
    get correlatedActivityId() {
        return this.headers[Constants.HttpHeaders.CorrelatedActivityId];
    }
    get indexMetrics() {
        return decodeAndParseJSONString(this.headers[Constants.HttpHeaders.IndexUtilization]);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @hidden
 */
const TimeoutErrorCode = "TimeoutError";
class TimeoutError extends Error {
    constructor(message = "Timeout Error") {
        super(message);
        this.code = TimeoutErrorCode;
        this.name = TimeoutErrorCode;
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Cosmos DB Diagnostic Level
 */
exports.CosmosDbDiagnosticLevel = void 0;
(function (CosmosDbDiagnosticLevel) {
    CosmosDbDiagnosticLevel["info"] = "info";
    CosmosDbDiagnosticLevel["debug"] = "debug";
    CosmosDbDiagnosticLevel["debugUnsafe"] = "debug-unsafe";
})(exports.CosmosDbDiagnosticLevel || (exports.CosmosDbDiagnosticLevel = {}));

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @hidden
 */
const CosmosDbDiagnosticLevelOrder = [
    exports.CosmosDbDiagnosticLevel.info,
    exports.CosmosDbDiagnosticLevel.debug,
    exports.CosmosDbDiagnosticLevel.debugUnsafe,
];
/**
 * @hidden
 */
function allowTracing(levelToCheck, clientDiagnosticLevel) {
    const indexOfDiagnosticLevelToCheck = CosmosDbDiagnosticLevelOrder.indexOf(levelToCheck);
    const indexOfClientDiagnosticLevel = CosmosDbDiagnosticLevelOrder.indexOf(clientDiagnosticLevel);
    if (indexOfDiagnosticLevelToCheck === -1 || indexOfClientDiagnosticLevel === -1) {
        return false;
    }
    return indexOfDiagnosticLevelToCheck <= indexOfClientDiagnosticLevel;
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @hidden
 * This is Internal Representation for DiagnosticNode. It contains useful helper functions to collect
 * diagnostic information throughout the lifetime of Diagnostic session.
 * The functions toDiagnosticNode() & toDiagnostic() are given to convert it to public facing counterpart.
 */
class DiagnosticNodeInternal {
    /**
     * @internal
     */
    constructor(diagnosticLevel, type, parent, data = {}, startTimeUTCInMs = getCurrentTimestampInMs(), ctx = new CosmosDiagnosticContext()) {
        this.id = coreUtil.randomUUID();
        this.nodeType = type;
        this.startTimeUTCInMs = startTimeUTCInMs;
        this.data = data;
        this.children = [];
        this.durationInMs = 0;
        this.parent = parent;
        this.diagnosticCtx = ctx;
        this.diagnosticLevel = diagnosticLevel;
        // Initialize EncryptionDiagnostics
        this.encryptionDiagnostics = {
            encryptContent: {},
            decryptContent: {},
            processingDurationInMs: 0,
        };
    }
    /**
     * @internal
     */
    addLog(msg) {
        if (!this.data.log) {
            this.data.log = [];
        }
        this.data.log.push(msg);
    }
    /**
     * @internal
     */
    sanitizeHeaders(headers) {
        return headers;
    }
    /**
     * Updated durationInMs for node, based on endTimeUTCInMs provided.
     * @internal
     */
    updateTimestamp(endTimeUTCInMs = getCurrentTimestampInMs()) {
        this.durationInMs = endTimeUTCInMs - this.startTimeUTCInMs;
    }
    /**
     * @internal
     */
    recordSuccessfulNetworkCall(startTimeUTCInMs, requestContext, pipelineResponse, substatus, url) {
        const responseHeaders = pipelineResponse.headers.toJSON();
        const gatewayRequest = {
            activityId: responseHeaders[Constants.HttpHeaders.ActivityId],
            correlateActivityId: requestContext.headers[Constants.HttpHeaders.CorrelatedActivityId],
            startTimeUTCInMs,
            durationInMs: getCurrentTimestampInMs() - startTimeUTCInMs,
            statusCode: pipelineResponse.status,
            subStatusCode: substatus,
            requestPayloadLengthInBytes: calculateRequestPayloadLength(requestContext),
            responsePayloadLengthInBytes: calculateResponsePayloadLength(pipelineResponse),
            operationType: requestContext.operationType,
            resourceType: requestContext.resourceType,
            partitionKeyRangeId: requestContext.partitionKeyRangeId,
        };
        let requestData = {
            OperationType: gatewayRequest.operationType,
            resourceType: gatewayRequest.resourceType,
            requestPayloadLengthInBytes: gatewayRequest.requestPayloadLengthInBytes,
        };
        if (allowTracing(exports.CosmosDbDiagnosticLevel.debugUnsafe, this.diagnosticLevel)) {
            requestData = Object.assign(Object.assign({}, requestData), { headers: this.sanitizeHeaders(requestContext.headers), requestBody: requestContext.body, responseBody: pipelineResponse.bodyAsText, url: url });
        }
        this.addData({
            requestPayloadLengthInBytes: gatewayRequest.requestPayloadLengthInBytes,
            responsePayloadLengthInBytes: gatewayRequest.responsePayloadLengthInBytes,
            startTimeUTCInMs: gatewayRequest.startTimeUTCInMs,
            durationInMs: gatewayRequest.durationInMs,
            requestData,
        });
        this.diagnosticCtx.recordNetworkCall(gatewayRequest);
    }
    /**
     * @internal
     */
    recordFailedNetworkCall(startTimeUTCInMs, requestContext, retryAttemptNumber, statusCode, substatusCode, responseHeaders) {
        this.addData({ failedAttempty: true });
        const requestPayloadLengthInBytes = calculateRequestPayloadLength(requestContext);
        this.diagnosticCtx.recordFailedAttempt({
            activityId: responseHeaders[Constants.HttpHeaders.ActivityId],
            correlatedActivityId: requestContext.headers[Constants.HttpHeaders.CorrelatedActivityId],
            startTimeUTCInMs,
            durationInMs: getCurrentTimestampInMs() - startTimeUTCInMs,
            statusCode,
            subStatusCode: substatusCode,
            requestPayloadLengthInBytes,
            responsePayloadLengthInBytes: 0,
            operationType: requestContext.operationType,
            resourceType: requestContext.resourceType,
        }, retryAttemptNumber);
        let requestData = {
            OperationType: requestContext.operationType,
            resourceType: requestContext.resourceType,
            requestPayloadLengthInBytes,
        };
        if (allowTracing(exports.CosmosDbDiagnosticLevel.debugUnsafe, this.diagnosticLevel)) {
            requestData = Object.assign(Object.assign({}, requestData), { headers: this.sanitizeHeaders(requestContext.headers), requestBody: requestContext.body, url: prepareURL(requestContext.endpoint, requestContext.path) });
        }
        this.addData({
            failedAttempty: true,
            requestData,
        });
    }
    /**
     * @internal
     */
    recordEndpointResolution(location) {
        this.addData({ selectedLocation: location });
        this.diagnosticCtx.recordEndpointResolution(location);
    }
    /**
     * @internal
     */
    addData(data, msg, level = this.diagnosticLevel) {
        if (level !== exports.CosmosDbDiagnosticLevel.info) {
            this.data = Object.assign(Object.assign({}, this.data), data);
            if (msg) {
                this.addLog(msg);
            }
        }
    }
    /**
     * Merge given DiagnosticNodeInternal's context to current node's DiagnosticContext, Treating GatewayRequests of
     * given DiagnosticContext, as metadata requests. Given DiagnosticNodeInternal becomes a child of this node.
     * @internal
     */
    addChildNode(child, level, metadataType) {
        this.diagnosticCtx.mergeDiagnostics(child.diagnosticCtx, metadataType);
        if (allowTracing(level, this.diagnosticLevel)) {
            child.parent = this;
            this.children.push(child);
        }
        return child;
    }
    /**
     * @internal
     */
    initializeChildNode(type, level, data = {}) {
        if (allowTracing(level, this.diagnosticLevel)) {
            const child = new DiagnosticNodeInternal(this.diagnosticLevel, type, this, data, getCurrentTimestampInMs(), this.diagnosticCtx);
            this.children.push(child);
            return child;
        }
        else {
            return this;
        }
    }
    /**
     * @internal
     */
    recordQueryResult(resources, level) {
        var _a;
        if (allowTracing(level, this.diagnosticLevel)) {
            const previousCount = (_a = this.data.queryRecordsRead) !== null && _a !== void 0 ? _a : 0;
            if (Array.isArray(resources)) {
                this.data.queryRecordsRead = previousCount + resources.length;
            }
        }
    }
    /**
     * @internal
     * record startTime for encryption in an operation
     */
    beginEncryptionDiagnostics(operation) {
        const startTime = getCurrentTimestampInMs();
        switch (operation) {
            case Constants.Encryption.DiagnosticsEncryptOperation:
                this.encryptionDiagnostics.encryptContent[Constants.Encryption.DiagnosticsStartTime] =
                    startTime;
                break;
            case Constants.Encryption.DiagnosticsDecryptOperation:
                this.encryptionDiagnostics.decryptContent[Constants.Encryption.DiagnosticsStartTime] =
                    startTime;
                break;
            default:
                throw new ErrorResponse("Invalid operation type for encryption diagnostics");
        }
    }
    /**
     * @internal
     * record duration from startTime and properties count for encryption in an operation
     */
    endEncryptionDiagnostics(operation, propertiesCount) {
        const endTime = getCurrentTimestampInMs();
        let processingDuration = 0;
        switch (operation) {
            case Constants.Encryption.DiagnosticsEncryptOperation:
                processingDuration =
                    endTime -
                        this.encryptionDiagnostics.encryptContent[Constants.Encryption.DiagnosticsStartTime];
                this.encryptionDiagnostics.encryptContent[Constants.Encryption.DiagnosticsDuration] =
                    processingDuration;
                // will be undefined in case of bulk/batch
                if (propertiesCount !== undefined) {
                    this.encryptionDiagnostics.encryptContent[Constants.Encryption.DiagnosticsPropertiesEncryptedCount] = propertiesCount;
                }
                break;
            case Constants.Encryption.DiagnosticsDecryptOperation:
                processingDuration =
                    endTime -
                        this.encryptionDiagnostics.decryptContent[Constants.Encryption.DiagnosticsStartTime];
                this.encryptionDiagnostics.decryptContent[Constants.Encryption.DiagnosticsDuration] =
                    processingDuration;
                if (propertiesCount !== undefined) {
                    this.encryptionDiagnostics.decryptContent[Constants.Encryption.DiagnosticsPropertiesDecryptedCount] = propertiesCount;
                }
                break;
            default:
                throw new ErrorResponse("Invalid operation type for encryption diagnostics");
        }
        this.diagnosticCtx.recordEncryptionDiagnostics(this.encryptionDiagnostics);
    }
    /**
     * Convert DiagnosticNodeInternal (internal representation) to DiagnosticNode (public, sanitized representation)
     * @internal
     */
    toDiagnosticNode() {
        return {
            id: this.id,
            nodeType: this.nodeType,
            children: this.children.map((child) => child.toDiagnosticNode()),
            data: this.data,
            startTimeUTCInMs: this.startTimeUTCInMs,
            durationInMs: this.durationInMs,
        };
    }
    /**
     * Convert to CosmosDiagnostics
     * @internal
     */
    toDiagnostic(clientConfigDiagnostic) {
        const rootNode = getRootNode(this);
        const diagnostiNode = allowTracing(exports.CosmosDbDiagnosticLevel.debug, this.diagnosticLevel)
            ? rootNode.toDiagnosticNode()
            : undefined;
        const clientConfig = allowTracing(exports.CosmosDbDiagnosticLevel.debug, this.diagnosticLevel)
            ? clientConfigDiagnostic
            : undefined;
        const cosmosDiagnostic = new CosmosDiagnostics(this.diagnosticCtx.getClientSideStats(), diagnostiNode, clientConfig);
        return cosmosDiagnostic;
    }
}
/**
 * @hidden
 */
exports.DiagnosticNodeType = void 0;
(function (DiagnosticNodeType) {
    DiagnosticNodeType["CLIENT_REQUEST_NODE"] = "CLIENT_REQUEST_NODE";
    DiagnosticNodeType["METADATA_REQUEST_NODE"] = "METADATA_REQUEST_NODE";
    DiagnosticNodeType["HTTP_REQUEST"] = "HTTP_REQUEST";
    DiagnosticNodeType["BATCH_REQUEST"] = "BATCH_REQUEST";
    DiagnosticNodeType["PARALLEL_QUERY_NODE"] = "PARALLEL_QUERY_NODE";
    DiagnosticNodeType["DEFAULT_QUERY_NODE"] = "DEFAULT_QUERY_NODE";
    DiagnosticNodeType["QUERY_REPAIR_NODE"] = "QUERY_REPAIR_NODE";
    DiagnosticNodeType["BACKGROUND_REFRESH_THREAD"] = "BACKGROUND_REFRESH_THREAD";
    DiagnosticNodeType["REQUEST_ATTEMPTS"] = "REQUEST_ATTEMPTS";
})(exports.DiagnosticNodeType || (exports.DiagnosticNodeType = {}));
function calculateResponsePayloadLength(response) {
    var _a;
    return ((_a = response === null || response === void 0 ? void 0 : response.bodyAsText) === null || _a === void 0 ? void 0 : _a.length) || 0;
}
function calculateRequestPayloadLength(requestContext) {
    return requestContext.body ? requestContext.body.length : 0;
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @hidden
 * Utility function to create an Empty CosmosDiagnostic object.
 */
function getEmptyCosmosDiagnostics() {
    return new CosmosDiagnostics({
        requestDurationInMs: 0,
        requestStartTimeUTCInMs: getCurrentTimestampInMs(),
        totalRequestPayloadLengthInBytes: 0,
        totalResponsePayloadLengthInBytes: 0,
        locationEndpointsContacted: [],
        retryDiagnostics: {
            failedAttempts: [],
        },
        metadataDiagnostics: {
            metadataLookups: [],
        },
        gatewayStatistics: [],
    }, {
        id: coreUtil.randomUUID(),
        nodeType: exports.DiagnosticNodeType.CLIENT_REQUEST_NODE,
        children: [],
        data: {},
        startTimeUTCInMs: getCurrentTimestampInMs(),
        durationInMs: 0,
    });
}
/**
 * A supporting utility wrapper function, to be used inside a diagnostic session started
 * by `withDiagnostics` function.
 * Created a Diagnostic node and add it as a child to existing diagnostic session.
 * @hidden
 */
async function addDignosticChild(callback, node, type, data = {}) {
    const childNode = node.initializeChildNode(type, exports.CosmosDbDiagnosticLevel.debug, data);
    try {
        const response = await callback(childNode);
        childNode.updateTimestamp();
        return response;
    }
    catch (e) {
        childNode.addData({
            failure: true,
        });
        childNode.updateTimestamp();
        throw e;
    }
}
/**
 * A supporting utility wrapper function, to be used inside a diagnostic session started
 * by `withDiagnostics` function.
 * Treats requests originating in  provided `callback` as metadata calls.
 * To realize this, starts a temporary diagnostic session, after execution of callback is
 * finished. Merges this temporary diagnostic session to the original diagnostic session
 * represented by the input parameter `node`.
 * @hidden
 */
async function withMetadataDiagnostics(callback, node, type) {
    const diagnosticNodeForMetadataCall = new DiagnosticNodeInternal(node.diagnosticLevel, exports.DiagnosticNodeType.METADATA_REQUEST_NODE, null);
    try {
        const response = await callback(diagnosticNodeForMetadataCall);
        node.addChildNode(diagnosticNodeForMetadataCall, exports.CosmosDbDiagnosticLevel.debug, type);
        return response;
    }
    catch (e) {
        node.addChildNode(diagnosticNodeForMetadataCall, exports.CosmosDbDiagnosticLevel.debug, type);
        throw e;
    }
}
/**
 * Utility wrapper function to managed lifecycle of a Diagnostic session.
 * Meant to be used at the root of the client operation. i.e. item.read(),
 * queryIterator.fetchAll().
 *
 * This utility starts a new diagnostic session. So using it any where else
 * other than start of operation, will result is different diagnostic sessions.
 *
 * Workings :
 * 1. Takes a callback function as input.
 * 2. Creates a new instance of DiagnosticNodeInternal, which can be though as starting
 * a new diagnostic session.
 * 3. Executes the callback function.
 * 4. If execution was successful. Converts DiagnosticNodeInternal to CosmosDiagnostics
 * and injects it to the response object and returns this object.
 * 5. If execution threw an exception. Sill converts DiagnosticNodeInternal to CosmosDiagnostics
 * and injects it to the Error object, and rethrows the Error object.
 *
 * @hidden
 */
async function withDiagnostics(callback, clientContext, type = exports.DiagnosticNodeType.CLIENT_REQUEST_NODE) {
    const diagnosticNode = new DiagnosticNodeInternal(clientContext.diagnosticLevel, type, null);
    try {
        const response = await callback(diagnosticNode);
        diagnosticNode.updateTimestamp();
        const diagnostics = diagnosticNode.toDiagnostic(clientContext.getClientConfig());
        if (typeof response === "object" && response !== null) {
            response.diagnostics = diagnostics;
        }
        clientContext.recordDiagnostics(diagnostics);
        return response;
    }
    catch (e) {
        diagnosticNode.updateTimestamp();
        diagnosticNode.addData({
            failure: true,
        });
        const diagnostics = diagnosticNode.toDiagnostic(clientContext.getClientConfig());
        e.diagnostics = diagnostics;
        clientContext.recordDiagnostics(diagnostics);
        throw e;
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @hidden
 */
function compareRanges(a, b) {
    const aVal = a[0][Constants.PartitionKeyRange.MinInclusive];
    const bVal = b[0][Constants.PartitionKeyRange.MinInclusive];
    if (aVal > bVal) {
        return 1;
    }
    if (aVal < bVal) {
        return -1;
    }
    return 0;
}
/** @hidden */
function createCompleteRoutingMap(partitionKeyRangeInfoTuppleList) {
    const rangeById = {}; // TODO: any
    const rangeByInfo = {}; // TODO: any
    let sortedRanges = [];
    // the for loop doesn't invoke any async callback
    for (const r of partitionKeyRangeInfoTuppleList) {
        rangeById[r[0][Constants.PartitionKeyRange.Id]] = r;
        rangeByInfo[r[1]] = r[0];
        sortedRanges.push(r);
    }
    sortedRanges = sortedRanges.sort(compareRanges);
    const partitionKeyOrderedRange = sortedRanges.map((r) => r[0]);
    const orderedPartitionInfo = sortedRanges.map((r) => r[1]);
    if (!isCompleteSetOfRange(partitionKeyOrderedRange)) {
        return undefined;
    }
    return new InMemoryCollectionRoutingMap(partitionKeyOrderedRange, orderedPartitionInfo);
}
/**
 * @hidden
 */
function isCompleteSetOfRange(partitionKeyOrderedRange) {
    // TODO: any
    let isComplete = false;
    if (partitionKeyOrderedRange.length > 0) {
        const firstRange = partitionKeyOrderedRange[0];
        const lastRange = partitionKeyOrderedRange[partitionKeyOrderedRange.length - 1];
        isComplete =
            firstRange[Constants.PartitionKeyRange.MinInclusive] ===
                Constants.EffectivePartitionKeyConstants.MinimumInclusiveEffectivePartitionKey;
        isComplete =
            isComplete &&
                lastRange[Constants.PartitionKeyRange.MaxExclusive] ===
                    Constants.EffectivePartitionKeyConstants.MaximumExclusiveEffectivePartitionKey;
        for (let i = 1; i < partitionKeyOrderedRange.length; i++) {
            const previousRange = partitionKeyOrderedRange[i - 1];
            const currentRange = partitionKeyOrderedRange[i];
            isComplete =
                isComplete &&
                    previousRange[Constants.PartitionKeyRange.MaxExclusive] ===
                        currentRange[Constants.PartitionKeyRange.MinInclusive];
            if (!isComplete) {
                if (previousRange[Constants.PartitionKeyRange.MaxExclusive] >
                    currentRange[Constants.PartitionKeyRange.MinInclusive]) {
                    throw Error("Ranges overlap");
                }
                break;
            }
        }
    }
    return isComplete;
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/** @hidden */
class PartitionKeyRangeCache {
    constructor(clientContext) {
        this.clientContext = clientContext;
        this.collectionRoutingMapByCollectionId = {};
    }
    /**
     * Finds or Instantiates the requested Collection Routing Map
     * @param collectionLink - Requested collectionLink
     * @hidden
     */
    async onCollectionRoutingMap(collectionLink, diagnosticNode, forceRefresh = false) {
        const collectionId = getIdFromLink(collectionLink);
        if (this.collectionRoutingMapByCollectionId[collectionId] === undefined || forceRefresh) {
            this.collectionRoutingMapByCollectionId[collectionId] = this.requestCollectionRoutingMap(collectionLink, diagnosticNode);
        }
        return this.collectionRoutingMapByCollectionId[collectionId];
    }
    /**
     * Given the query ranges and a collection, invokes the callback on the list of overlapping partition key ranges
     * @hidden
     */
    async getOverlappingRanges(collectionLink, queryRange, diagnosticNode, forceRefresh = false) {
        const crm = await this.onCollectionRoutingMap(collectionLink, diagnosticNode, forceRefresh);
        return crm.getOverlappingRanges(queryRange);
    }
    async requestCollectionRoutingMap(collectionLink, diagnosticNode) {
        const { resources } = await withMetadataDiagnostics(async (metadataDiagnostics) => {
            return this.clientContext
                .queryPartitionKeyRanges(collectionLink)
                .fetchAllInternal(metadataDiagnostics);
        }, diagnosticNode, exports.MetadataLookUpType.PartitionKeyRangeLookUp);
        return createCompleteRoutingMap(resources.map((r) => [r, true]));
    }
}

/** @hidden */
const PARITIONKEYRANGE = Constants.PartitionKeyRange;
/** @hidden */
class SmartRoutingMapProvider {
    constructor(clientContext) {
        this.partitionKeyRangeCache = new PartitionKeyRangeCache(clientContext);
    }
    static _secondRangeIsAfterFirstRange(range1, range2) {
        if (typeof range1.max === "undefined") {
            throw new Error("range1 must have max");
        }
        if (typeof range2.min === "undefined") {
            throw new Error("range2 must have min");
        }
        if (range1.max > range2.min) {
            // r.min < #previous_r.max
            return false;
        }
        else {
            if (range1.max === range2.min && range1.isMaxInclusive && range2.isMinInclusive) {
                // the inclusive ending endpoint of previous_r is the same as the inclusive beginning endpoint of r
                // they share a point
                return false;
            }
            return true;
        }
    }
    static _isSortedAndNonOverlapping(ranges) {
        for (let idx = 1; idx < ranges.length; idx++) {
            const previousR = ranges[idx - 1];
            const r = ranges[idx];
            if (!this._secondRangeIsAfterFirstRange(previousR, r)) {
                return false;
            }
        }
        return true;
    }
    static _stringMax(a, b) {
        return a >= b ? a : b;
    }
    static _stringCompare(a, b) {
        return a === b ? 0 : a > b ? 1 : -1;
    }
    static _subtractRange(r, partitionKeyRange) {
        const left = this._stringMax(partitionKeyRange[PARITIONKEYRANGE.MaxExclusive], r.min);
        const leftInclusive = this._stringCompare(left, r.min) === 0 ? r.isMinInclusive : false;
        return new QueryRange(left, r.max, leftInclusive, r.isMaxInclusive);
    }
    /**
     * Given the sorted ranges and a collection, invokes the callback on the list of overlapping partition key ranges
     * @param callback - Function execute on the overlapping partition key ranges result,
     *                   takes two parameters error, partition key ranges
     * @hidden
     */
    async getOverlappingRanges(collectionLink, sortedRanges, diagnosticNode) {
        // validate if the list is non- overlapping and sorted                             TODO: any PartitionKeyRanges
        if (!SmartRoutingMapProvider._isSortedAndNonOverlapping(sortedRanges)) {
            throw new Error("the list of ranges is not a non-overlapping sorted ranges");
        }
        let partitionKeyRanges = []; // TODO: any ParitionKeyRanges
        if (sortedRanges.length === 0) {
            return partitionKeyRanges;
        }
        const collectionRoutingMap = await this.partitionKeyRangeCache.onCollectionRoutingMap(collectionLink, diagnosticNode);
        let index = 0;
        let currentProvidedRange = sortedRanges[index];
        for (;;) {
            if (currentProvidedRange.isEmpty()) {
                // skip and go to the next item
                if (++index >= sortedRanges.length) {
                    return partitionKeyRanges;
                }
                currentProvidedRange = sortedRanges[index];
                continue;
            }
            let queryRange;
            if (partitionKeyRanges.length > 0) {
                queryRange = SmartRoutingMapProvider._subtractRange(currentProvidedRange, partitionKeyRanges[partitionKeyRanges.length - 1]);
            }
            else {
                queryRange = currentProvidedRange;
            }
            const overlappingRanges = collectionRoutingMap.getOverlappingRanges(queryRange);
            if (overlappingRanges.length <= 0) {
                throw new Error(`error: returned overlapping ranges for queryRange ${queryRange} is empty`);
            }
            partitionKeyRanges = partitionKeyRanges.concat(overlappingRanges);
            const lastKnownTargetRange = QueryRange.parsePartitionKeyRange(partitionKeyRanges[partitionKeyRanges.length - 1]);
            if (!lastKnownTargetRange) {
                throw new Error("expected lastKnowTargetRange to be truthy");
            }
            // the overlapping ranges must contain the requested range
            if (SmartRoutingMapProvider._stringCompare(currentProvidedRange.max, lastKnownTargetRange.max) >
                0) {
                throw new Error(`error: returned overlapping ranges ${overlappingRanges} \
        does not contain the requested range ${queryRange}`);
            }
            // the current range is contained in partitionKeyRanges just move forward
            if (++index >= sortedRanges.length) {
                return partitionKeyRanges;
            }
            currentProvidedRange = sortedRanges[index];
            while (SmartRoutingMapProvider._stringCompare(currentProvidedRange.max, lastKnownTargetRange.max) <= 0) {
                // the current range is covered too.just move forward
                if (++index >= sortedRanges.length) {
                    return partitionKeyRanges;
                }
                currentProvidedRange = sortedRanges[index];
            }
        }
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @hidden
 * A queue for iterating over specified Epk ranges and fetch change feed for the given epk ranges.
 */
class FeedRangeQueue {
    constructor() {
        this.elements = [];
    }
    modifyFirstElement(newItem) {
        if (!this.isEmpty()) {
            this.elements[0] = newItem;
        }
    }
    enqueue(item) {
        this.elements.push(item);
    }
    dequeue() {
        return this.elements.shift();
    }
    peek() {
        return !this.isEmpty() ? this.elements[0] : undefined;
    }
    isEmpty() {
        return this.elements.length === 0;
    }
    moveFirstElementToTheEnd() {
        if (!this.isEmpty()) {
            this.elements.push(this.dequeue());
        }
    }
    /**
     * Returns a snapshot of the queue as an array to be used as Continuation token.
     */
    returnSnapshot() {
        const allFeedRanges = [];
        this.elements.map((element) => {
            const minInclusive = element.epkMinHeader ? element.epkMinHeader : element.minInclusive;
            const maxExclusive = element.epkMaxHeader ? element.epkMaxHeader : element.maxExclusive;
            const feedRangeElement = new ChangeFeedRange(minInclusive, maxExclusive, element.continuationToken);
            allFeedRanges.push(feedRangeElement);
        });
        return allFeedRanges;
    }
}

/**
 * Continuation token for change feed of entire container, or a specific Epk Range.
 * @internal
 */
class CompositeContinuationToken {
    constructor(rid, Continuation) {
        this.rid = rid;
        this.Continuation = Continuation;
    }
}

/**
 * @hidden
 * Class which specifies the ChangeFeedIterator to start reading changes from beginning of time.
 */
class ChangeFeedStartFromBeginning {
    constructor(cfResource) {
        this.cfResource = cfResource;
    }
    getCfResource() {
        return this.cfResource;
    }
}

/**
 * @hidden
 * Class which specifies the ChangeFeedIterator to start reading changes from a particular point of time.
 */
class ChangeFeedStartFromTime {
    constructor(startTime, cfResource) {
        this.startTime = startTime;
        this.cfResource = cfResource;
    }
    getCfResource() {
        return this.cfResource;
    }
    getStartTime() {
        return this.startTime;
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Specifies a feed range for the changefeed.
 */
class FeedRange {
    /**
     * @internal
     */
    constructor(minInclusive, maxExclusive) {
        // only way to explictly block users from creating FeedRange directly in JS
        if (new.target === FeedRange) {
            throw new ErrorResponse("Cannot instantiate abstract class FeedRange");
        }
        this.minInclusive = minInclusive;
        this.maxExclusive = maxExclusive;
    }
}
/**
 * @hidden
 * Specifies a feed range for the changefeed.
 */
class FeedRangeInternal extends FeedRange {
    /* eslint-disable @typescript-eslint/no-useless-constructor */
    constructor(minInclusive, maxExclusive) {
        super(minInclusive, maxExclusive);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
const BytePrefix = {
    Undefined: "00",
    Null: "01",
    False: "02",
    True: "03",
    Number: "05",
    String: "08",
    Infinity: "FF",
};

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
function writeNumberForBinaryEncodingJSBI(hash) {
    let payload = encodeNumberAsUInt64JSBI(hash);
    let outputStream = Buffer.from(BytePrefix.Number, "hex");
    const firstChunk = JSBI.asUintN(64, JSBI.signedRightShift(payload, JSBI.BigInt(56)));
    outputStream = Buffer.concat([outputStream, Buffer.from(firstChunk.toString(16), "hex")]);
    payload = JSBI.asUintN(64, JSBI.leftShift(JSBI.BigInt(payload), JSBI.BigInt(0x8)));
    let byteToWrite = JSBI.BigInt(0);
    let shifted;
    let padded;
    do {
        {
            // we pad because after shifting because we will produce characters like "f" or similar,
            // which cannot be encoded as hex in a buffer because they are invalid hex
            // https://github.com/nodejs/node/issues/24491
            padded = byteToWrite.toString(16).padStart(2, "0");
            if (padded !== "00") {
                outputStream = Buffer.concat([outputStream, Buffer.from(padded, "hex")]);
            }
        }
        shifted = JSBI.asUintN(64, JSBI.signedRightShift(payload, JSBI.BigInt(56)));
        byteToWrite = JSBI.asUintN(64, JSBI.bitwiseOr(shifted, JSBI.BigInt(0x01)));
        payload = JSBI.asUintN(64, JSBI.leftShift(payload, JSBI.BigInt(7)));
    } while (JSBI.notEqual(payload, JSBI.BigInt(0)));
    const lastChunk = JSBI.asUintN(64, JSBI.bitwiseAnd(byteToWrite, JSBI.BigInt(0xfe)));
    // we pad because after shifting because we will produce characters like "f" or similar,
    // which cannot be encoded as hex in a buffer because they are invalid hex
    // https://github.com/nodejs/node/issues/24491
    padded = lastChunk.toString(16).padStart(2, "0");
    if (padded !== "00") {
        outputStream = Buffer.concat([outputStream, Buffer.from(padded, "hex")]);
    }
    return outputStream;
}
function encodeNumberAsUInt64JSBI(value) {
    const rawValueBits = getRawBitsJSBI(value);
    const mask = JSBI.BigInt(0x8000000000000000);
    const returned = JSBI.greaterThan(mask, rawValueBits)
        ? JSBI.bitwiseXor(rawValueBits, mask)
        : JSBI.add(JSBI.bitwiseNot(rawValueBits), JSBI.BigInt(1));
    return returned;
}
function doubleToByteArrayJSBI(double) {
    const output = Buffer.alloc(8);
    const lng = getRawBitsJSBI(double);
    for (let i = 0; i < 8; i++) {
        output[i] = JSBI.toNumber(JSBI.bitwiseAnd(JSBI.signedRightShift(lng, JSBI.multiply(JSBI.BigInt(i), JSBI.BigInt(8))), JSBI.BigInt(0xff)));
    }
    return output;
}
function getRawBitsJSBI(value) {
    const view = new DataView(new ArrayBuffer(8));
    view.setFloat64(0, value);
    return JSBI.BigInt(`0x${buf2hex(view.buffer)}`);
}
function buf2hex(buffer) {
    return Array.prototype.map
        .call(new Uint8Array(buffer), (x) => ("00" + x.toString(16)).slice(-2))
        .join("");
}

// +----------------------------------------------------------------------+
// | murmurHash3js.js v3.0.1 // https://github.com/pid/murmurHash3js
// | A javascript implementation of MurmurHash3's x86 hashing algorithms. |
// |----------------------------------------------------------------------|
// | Copyright (c) 2012-2015 Karan Lyons                                       |
// | https://github.com/karanlyons/murmurHash3.js/blob/c1778f75792abef7bdd74bc85d2d4e1a3d25cfe9/murmurHash3.js |
// | Freely distributable under the MIT license.                          |
// +----------------------------------------------------------------------+
// PRIVATE FUNCTIONS
// -----------------
function _x86Multiply(m, n) {
    //
    // Given two 32bit ints, returns the two multiplied together as a
    // 32bit int.
    //
    return (m & 0xffff) * n + ((((m >>> 16) * n) & 0xffff) << 16);
}
function _x86Rotl(m, n) {
    //
    // Given a 32bit int and an int representing a number of bit positions,
    // returns the 32bit int rotated left by that number of positions.
    //
    return (m << n) | (m >>> (32 - n));
}
function _x86Fmix(h) {
    //
    // Given a block, returns murmurHash3's final x86 mix of that block.
    //
    h ^= h >>> 16;
    h = _x86Multiply(h, 0x85ebca6b);
    h ^= h >>> 13;
    h = _x86Multiply(h, 0xc2b2ae35);
    h ^= h >>> 16;
    return h;
}
function _x64Add(m, n) {
    //
    // Given two 64bit ints (as an array of two 32bit ints) returns the two
    // added together as a 64bit int (as an array of two 32bit ints).
    //
    m = [m[0] >>> 16, m[0] & 0xffff, m[1] >>> 16, m[1] & 0xffff];
    n = [n[0] >>> 16, n[0] & 0xffff, n[1] >>> 16, n[1] & 0xffff];
    const o = [0, 0, 0, 0];
    o[3] += m[3] + n[3];
    o[2] += o[3] >>> 16;
    o[3] &= 0xffff;
    o[2] += m[2] + n[2];
    o[1] += o[2] >>> 16;
    o[2] &= 0xffff;
    o[1] += m[1] + n[1];
    o[0] += o[1] >>> 16;
    o[1] &= 0xffff;
    o[0] += m[0] + n[0];
    o[0] &= 0xffff;
    return [(o[0] << 16) | o[1], (o[2] << 16) | o[3]];
}
function _x64Multiply(m, n) {
    //
    // Given two 64bit ints (as an array of two 32bit ints) returns the two
    // multiplied together as a 64bit int (as an array of two 32bit ints).
    //
    m = [m[0] >>> 16, m[0] & 0xffff, m[1] >>> 16, m[1] & 0xffff];
    n = [n[0] >>> 16, n[0] & 0xffff, n[1] >>> 16, n[1] & 0xffff];
    const o = [0, 0, 0, 0];
    o[3] += m[3] * n[3];
    o[2] += o[3] >>> 16;
    o[3] &= 0xffff;
    o[2] += m[2] * n[3];
    o[1] += o[2] >>> 16;
    o[2] &= 0xffff;
    o[2] += m[3] * n[2];
    o[1] += o[2] >>> 16;
    o[2] &= 0xffff;
    o[1] += m[1] * n[3];
    o[0] += o[1] >>> 16;
    o[1] &= 0xffff;
    o[1] += m[2] * n[2];
    o[0] += o[1] >>> 16;
    o[1] &= 0xffff;
    o[1] += m[3] * n[1];
    o[0] += o[1] >>> 16;
    o[1] &= 0xffff;
    o[0] += m[0] * n[3] + m[1] * n[2] + m[2] * n[1] + m[3] * n[0];
    o[0] &= 0xffff;
    return [(o[0] << 16) | o[1], (o[2] << 16) | o[3]];
}
function _x64Rotl(m, n) {
    //
    // Given a 64bit int (as an array of two 32bit ints) and an int
    // representing a number of bit positions, returns the 64bit int (as an
    // array of two 32bit ints) rotated left by that number of positions.
    //
    n %= 64;
    if (n === 32) {
        return [m[1], m[0]];
    }
    else if (n < 32) {
        return [(m[0] << n) | (m[1] >>> (32 - n)), (m[1] << n) | (m[0] >>> (32 - n))];
    }
    else {
        n -= 32;
        return [(m[1] << n) | (m[0] >>> (32 - n)), (m[0] << n) | (m[1] >>> (32 - n))];
    }
}
function _x64LeftShift(m, n) {
    //
    // Given a 64bit int (as an array of two 32bit ints) and an int
    // representing a number of bit positions, returns the 64bit int (as an
    // array of two 32bit ints) shifted left by that number of positions.
    //
    n %= 64;
    if (n === 0) {
        return m;
    }
    else if (n < 32) {
        return [(m[0] << n) | (m[1] >>> (32 - n)), m[1] << n];
    }
    else {
        return [m[1] << (n - 32), 0];
    }
}
function _x64Xor(m, n) {
    //
    // Given two 64bit ints (as an array of two 32bit ints) returns the two
    // xored together as a 64bit int (as an array of two 32bit ints).
    //
    return [m[0] ^ n[0], m[1] ^ n[1]];
}
function _x64Fmix(h) {
    //
    // Given a block, returns murmurHash3's final x64 mix of that block.
    // (`[0, h[0] >>> 1]` is a 33 bit unsigned right shift. This is the
    // only place where we need to right shift 64bit ints.)
    //
    h = _x64Xor(h, [0, h[0] >>> 1]);
    h = _x64Multiply(h, [0xff51afd7, 0xed558ccd]);
    h = _x64Xor(h, [0, h[0] >>> 1]);
    h = _x64Multiply(h, [0xc4ceb9fe, 0x1a85ec53]);
    h = _x64Xor(h, [0, h[0] >>> 1]);
    return h;
}
// PUBLIC FUNCTIONS
// ----------------
function x86Hash32(bytes, seed) {
    //
    // Given a string and an optional seed as an int, returns a 32 bit hash
    // using the x86 flavor of MurmurHash3, as an unsigned int.
    //
    seed = seed || 0;
    const remainder = bytes.length % 4;
    const blocks = bytes.length - remainder;
    let h1 = seed;
    let k1 = 0;
    const c1 = 0xcc9e2d51;
    const c2 = 0x1b873593;
    let j = 0;
    for (let i = 0; i < blocks; i = i + 4) {
        k1 = bytes[i] | (bytes[i + 1] << 8) | (bytes[i + 2] << 16) | (bytes[i + 3] << 24);
        k1 = _x86Multiply(k1, c1);
        k1 = _x86Rotl(k1, 15);
        k1 = _x86Multiply(k1, c2);
        h1 ^= k1;
        h1 = _x86Rotl(h1, 13);
        h1 = _x86Multiply(h1, 5) + 0xe6546b64;
        j = i + 4;
    }
    k1 = 0;
    switch (remainder) {
        case 3:
            k1 ^= bytes[j + 2] << 16;
        case 2:
            k1 ^= bytes[j + 1] << 8;
        case 1:
            k1 ^= bytes[j];
            k1 = _x86Multiply(k1, c1);
            k1 = _x86Rotl(k1, 15);
            k1 = _x86Multiply(k1, c2);
            h1 ^= k1;
    }
    h1 ^= bytes.length;
    h1 = _x86Fmix(h1);
    return h1 >>> 0;
}
function x86Hash128(bytes, seed) {
    //
    // Given a string and an optional seed as an int, returns a 128 bit
    // hash using the x86 flavor of MurmurHash3, as an unsigned hex.
    //
    seed = seed || 0;
    const remainder = bytes.length % 16;
    const blocks = bytes.length - remainder;
    let h1 = seed;
    let h2 = seed;
    let h3 = seed;
    let h4 = seed;
    let k1 = 0;
    let k2 = 0;
    let k3 = 0;
    let k4 = 0;
    const c1 = 0x239b961b;
    const c2 = 0xab0e9789;
    const c3 = 0x38b34ae5;
    const c4 = 0xa1e38b93;
    let j = 0;
    for (let i = 0; i < blocks; i = i + 16) {
        k1 = bytes[i] | (bytes[i + 1] << 8) | (bytes[i + 2] << 16) | (bytes[i + 3] << 24);
        k2 = bytes[i + 4] | (bytes[i + 5] << 8) | (bytes[i + 6] << 16) | (bytes[i + 7] << 24);
        k3 = bytes[i + 8] | (bytes[i + 9] << 8) | (bytes[i + 10] << 16) | (bytes[i + 11] << 24);
        k4 = bytes[i + 12] | (bytes[i + 13] << 8) | (bytes[i + 14] << 16) | (bytes[i + 15] << 24);
        k1 = _x86Multiply(k1, c1);
        k1 = _x86Rotl(k1, 15);
        k1 = _x86Multiply(k1, c2);
        h1 ^= k1;
        h1 = _x86Rotl(h1, 19);
        h1 += h2;
        h1 = _x86Multiply(h1, 5) + 0x561ccd1b;
        k2 = _x86Multiply(k2, c2);
        k2 = _x86Rotl(k2, 16);
        k2 = _x86Multiply(k2, c3);
        h2 ^= k2;
        h2 = _x86Rotl(h2, 17);
        h2 += h3;
        h2 = _x86Multiply(h2, 5) + 0x0bcaa747;
        k3 = _x86Multiply(k3, c3);
        k3 = _x86Rotl(k3, 17);
        k3 = _x86Multiply(k3, c4);
        h3 ^= k3;
        h3 = _x86Rotl(h3, 15);
        h3 += h4;
        h3 = _x86Multiply(h3, 5) + 0x96cd1c35;
        k4 = _x86Multiply(k4, c4);
        k4 = _x86Rotl(k4, 18);
        k4 = _x86Multiply(k4, c1);
        h4 ^= k4;
        h4 = _x86Rotl(h4, 13);
        h4 += h1;
        h4 = _x86Multiply(h4, 5) + 0x32ac3b17;
        j = i + 16;
    }
    k1 = 0;
    k2 = 0;
    k3 = 0;
    k4 = 0;
    switch (remainder) {
        case 15:
            k4 ^= bytes[j + 14] << 16;
        case 14:
            k4 ^= bytes[j + 13] << 8;
        case 13:
            k4 ^= bytes[j + 12];
            k4 = _x86Multiply(k4, c4);
            k4 = _x86Rotl(k4, 18);
            k4 = _x86Multiply(k4, c1);
            h4 ^= k4;
        case 12:
            k3 ^= bytes[j + 11] << 24;
        case 11:
            k3 ^= bytes[j + 10] << 16;
        case 10:
            k3 ^= bytes[j + 9] << 8;
        case 9:
            k3 ^= bytes[j + 8];
            k3 = _x86Multiply(k3, c3);
            k3 = _x86Rotl(k3, 17);
            k3 = _x86Multiply(k3, c4);
            h3 ^= k3;
        case 8:
            k2 ^= bytes[j + 7] << 24;
        case 7:
            k2 ^= bytes[j + 6] << 16;
        case 6:
            k2 ^= bytes[j + 5] << 8;
        case 5:
            k2 ^= bytes[j + 4];
            k2 = _x86Multiply(k2, c2);
            k2 = _x86Rotl(k2, 16);
            k2 = _x86Multiply(k2, c3);
            h2 ^= k2;
        case 4:
            k1 ^= bytes[j + 3] << 24;
        case 3:
            k1 ^= bytes[j + 2] << 16;
        case 2:
            k1 ^= bytes[j + 1] << 8;
        case 1:
            k1 ^= bytes[j];
            k1 = _x86Multiply(k1, c1);
            k1 = _x86Rotl(k1, 15);
            k1 = _x86Multiply(k1, c2);
            h1 ^= k1;
    }
    h1 ^= bytes.length;
    h2 ^= bytes.length;
    h3 ^= bytes.length;
    h4 ^= bytes.length;
    h1 += h2;
    h1 += h3;
    h1 += h4;
    h2 += h1;
    h3 += h1;
    h4 += h1;
    h1 = _x86Fmix(h1);
    h2 = _x86Fmix(h2);
    h3 = _x86Fmix(h3);
    h4 = _x86Fmix(h4);
    h1 += h2;
    h1 += h3;
    h1 += h4;
    h2 += h1;
    h3 += h1;
    h4 += h1;
    return (("00000000" + (h1 >>> 0).toString(16)).slice(-8) +
        ("00000000" + (h2 >>> 0).toString(16)).slice(-8) +
        ("00000000" + (h3 >>> 0).toString(16)).slice(-8) +
        ("00000000" + (h4 >>> 0).toString(16)).slice(-8));
}
function x64Hash128(bytes, seed) {
    //
    // Given a string and an optional seed as an int, returns a 128 bit
    // hash using the x64 flavor of MurmurHash3, as an unsigned hex.
    //
    seed = seed || 0;
    const remainder = bytes.length % 16;
    const blocks = bytes.length - remainder;
    let h1 = [0, seed];
    let h2 = [0, seed];
    let k1 = [0, 0];
    let k2 = [0, 0];
    const c1 = [0x87c37b91, 0x114253d5];
    const c2 = [0x4cf5ad43, 0x2745937f];
    let j = 0;
    for (let i = 0; i < blocks; i = i + 16) {
        k1 = [
            bytes[i + 4] | (bytes[i + 5] << 8) | (bytes[i + 6] << 16) | (bytes[i + 7] << 24),
            bytes[i] | (bytes[i + 1] << 8) | (bytes[i + 2] << 16) | (bytes[i + 3] << 24),
        ];
        k2 = [
            bytes[i + 12] | (bytes[i + 13] << 8) | (bytes[i + 14] << 16) | (bytes[i + 15] << 24),
            bytes[i + 8] | (bytes[i + 9] << 8) | (bytes[i + 10] << 16) | (bytes[i + 11] << 24),
        ];
        k1 = _x64Multiply(k1, c1);
        k1 = _x64Rotl(k1, 31);
        k1 = _x64Multiply(k1, c2);
        h1 = _x64Xor(h1, k1);
        h1 = _x64Rotl(h1, 27);
        h1 = _x64Add(h1, h2);
        h1 = _x64Add(_x64Multiply(h1, [0, 5]), [0, 0x52dce729]);
        k2 = _x64Multiply(k2, c2);
        k2 = _x64Rotl(k2, 33);
        k2 = _x64Multiply(k2, c1);
        h2 = _x64Xor(h2, k2);
        h2 = _x64Rotl(h2, 31);
        h2 = _x64Add(h2, h1);
        h2 = _x64Add(_x64Multiply(h2, [0, 5]), [0, 0x38495ab5]);
        j = i + 16;
    }
    k1 = [0, 0];
    k2 = [0, 0];
    switch (remainder) {
        case 15:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[j + 14]], 48));
        case 14:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[j + 13]], 40));
        case 13:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[j + 12]], 32));
        case 12:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[j + 11]], 24));
        case 11:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[j + 10]], 16));
        case 10:
            k2 = _x64Xor(k2, _x64LeftShift([0, bytes[j + 9]], 8));
        case 9:
            k2 = _x64Xor(k2, [0, bytes[j + 8]]);
            k2 = _x64Multiply(k2, c2);
            k2 = _x64Rotl(k2, 33);
            k2 = _x64Multiply(k2, c1);
            h2 = _x64Xor(h2, k2);
        case 8:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[j + 7]], 56));
        case 7:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[j + 6]], 48));
        case 6:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[j + 5]], 40));
        case 5:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[j + 4]], 32));
        case 4:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[j + 3]], 24));
        case 3:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[j + 2]], 16));
        case 2:
            k1 = _x64Xor(k1, _x64LeftShift([0, bytes[j + 1]], 8));
        case 1:
            k1 = _x64Xor(k1, [0, bytes[j]]);
            k1 = _x64Multiply(k1, c1);
            k1 = _x64Rotl(k1, 31);
            k1 = _x64Multiply(k1, c2);
            h1 = _x64Xor(h1, k1);
    }
    h1 = _x64Xor(h1, [0, bytes.length]);
    h2 = _x64Xor(h2, [0, bytes.length]);
    h1 = _x64Add(h1, h2);
    h2 = _x64Add(h2, h1);
    h1 = _x64Fmix(h1);
    h2 = _x64Fmix(h2);
    h1 = _x64Add(h1, h2);
    h2 = _x64Add(h2, h1);
    // Here we reverse h1 and h2 in Cosmos
    // This is an implementation detail and not part of the public spec
    const h1Buff = Buffer.from(("00000000" + (h1[0] >>> 0).toString(16)).slice(-8) +
        ("00000000" + (h1[1] >>> 0).toString(16)).slice(-8), "hex");
    const h1Reversed = reverse$1(h1Buff).toString("hex");
    const h2Buff = Buffer.from(("00000000" + (h2[0] >>> 0).toString(16)).slice(-8) +
        ("00000000" + (h2[1] >>> 0).toString(16)).slice(-8), "hex");
    const h2Reversed = reverse$1(h2Buff).toString("hex");
    return h1Reversed + h2Reversed;
}
function reverse$1(buff) {
    const buffer = Buffer.allocUnsafe(buff.length);
    for (let i = 0, j = buff.length - 1; i <= j; ++i, --j) {
        buffer[i] = buff[j];
        buffer[j] = buff[i];
    }
    return buffer;
}
var MurmurHash = {
    x86: {
        hash32: x86Hash32,
        hash128: x86Hash128,
    },
    x64: {
        hash128: x64Hash128,
    }};

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
function hashV2PartitionKey(partitionKey) {
    const toHash = Buffer.concat(partitionKey.map(prefixKeyByType$1));
    const hash = MurmurHash.x64.hash128(toHash);
    const reverseBuff = reverse(Buffer.from(hash, "hex"));
    reverseBuff[0] &= 0x3f;
    return reverseBuff.toString("hex").toUpperCase();
}
function prefixKeyByType$1(key) {
    let bytes;
    switch (typeof key) {
        case "string": {
            bytes = Buffer.concat([
                Buffer.from(BytePrefix.String, "hex"),
                Buffer.from(key),
                Buffer.from(BytePrefix.Infinity, "hex"),
            ]);
            return bytes;
        }
        case "number": {
            const numberBytes = doubleToByteArrayJSBI(key);
            bytes = Buffer.concat([Buffer.from(BytePrefix.Number, "hex"), numberBytes]);
            return bytes;
        }
        case "boolean": {
            const prefix = key ? BytePrefix.True : BytePrefix.False;
            return Buffer.from(prefix, "hex");
        }
        case "object": {
            if (key === null) {
                return Buffer.from(BytePrefix.Null, "hex");
            }
            return Buffer.from(BytePrefix.Undefined, "hex");
        }
        case "undefined": {
            return Buffer.from(BytePrefix.Undefined, "hex");
        }
        default:
            throw new Error(`Unexpected type: ${typeof key}`);
    }
}
function reverse(buff) {
    const buffer = Buffer.allocUnsafe(buff.length);
    for (let i = 0, j = buff.length - 1; i <= j; ++i, --j) {
        buffer[i] = buff[j];
        buffer[j] = buff[i];
    }
    return buffer;
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
exports.ChangeFeedMode = void 0;
(function (ChangeFeedMode) {
    ChangeFeedMode["LatestVersion"] = "Incremental Feed";
    ChangeFeedMode["AllVersionsAndDeletes"] = "Full-Fidelity Feed";
})(exports.ChangeFeedMode || (exports.ChangeFeedMode = {}));

/**
 * @hidden
 * Validates the change feed options passed by the user
 */
function validateChangeFeedIteratorOptions(options) {
    if (!isChangeFeedIteratorOptions(options)) {
        throw new ErrorResponse("Invalid Changefeed Iterator Options.");
    }
    if ((options === null || options === void 0 ? void 0 : options.maxItemCount) && typeof (options === null || options === void 0 ? void 0 : options.maxItemCount) !== "number") {
        throw new ErrorResponse("maxItemCount must be number");
    }
    if ((options === null || options === void 0 ? void 0 : options.maxItemCount) !== undefined && (options === null || options === void 0 ? void 0 : options.maxItemCount) < 1) {
        throw new ErrorResponse("maxItemCount must be a positive number");
    }
}
function isChangeFeedIteratorOptions(options) {
    if (typeof options !== "object") {
        return false;
    }
    if (Object.keys(options).length === 0 && JSON.stringify(options) === "{}") {
        return true;
    }
    return options && !(isPrimitivePartitionKeyValue(options) || Array.isArray(options));
}
/**
 * @hidden
 * Checks if pkRange entirely covers the given overLapping range or there is only partial overlap.
 *
 * If no complete overlap, exact range which overlaps is retured which is used to set minEpk and maxEpk headers while quering change feed.
 */
async function extractOverlappingRanges(epkRange, overLappingRange) {
    if (overLappingRange.minInclusive >= epkRange.min &&
        overLappingRange.maxExclusive <= epkRange.max) {
        return [undefined, undefined];
    }
    else if (overLappingRange.minInclusive <= epkRange.min &&
        overLappingRange.maxExclusive >= epkRange.max) {
        return [epkRange.min, epkRange.max];
    }
    // Right Side of overlapping range is covered
    else if (overLappingRange.minInclusive <= epkRange.min &&
        overLappingRange.maxExclusive <= epkRange.max &&
        overLappingRange.maxExclusive >= epkRange.min) {
        return [epkRange.min, overLappingRange.maxExclusive];
    }
    // Left Side of overlapping range is covered
    else {
        return [overLappingRange.minInclusive, epkRange.max];
    }
}
/**
 * @hidden
 * Checks if the object is a valid EpkRange
 */
function isEpkRange(obj) {
    return (obj instanceof FeedRangeInternal &&
        typeof obj.minInclusive === "string" &&
        typeof obj.maxExclusive === "string" &&
        obj.minInclusive >=
            Constants.EffectivePartitionKeyConstants.MinimumInclusiveEffectivePartitionKey &&
        obj.maxExclusive <=
            Constants.EffectivePartitionKeyConstants.MaximumExclusiveEffectivePartitionKey &&
        obj.maxExclusive > obj.minInclusive);
}
/**
 * @hidden
 */
function buildInternalChangeFeedOptions(options, continuationToken, startTime, startFromNow) {
    const internalCfOptions = {};
    internalCfOptions.maxItemCount = options === null || options === void 0 ? void 0 : options.maxItemCount;
    internalCfOptions.sessionToken = options === null || options === void 0 ? void 0 : options.sessionToken;
    internalCfOptions.continuationToken = continuationToken;
    internalCfOptions.changeFeedMode = options === null || options === void 0 ? void 0 : options.changeFeedMode;
    // Default option of changefeed is to start from now.
    if (startFromNow) {
        internalCfOptions.startFromNow = true;
    }
    else {
        internalCfOptions.startTime = startTime;
    }
    return internalCfOptions;
}
/**
 * @hidden
 */
function fetchStartTime(changeFeedStartFrom) {
    if (changeFeedStartFrom instanceof ChangeFeedStartFromBeginning) {
        return undefined;
    }
    else if (changeFeedStartFrom instanceof ChangeFeedStartFromTime) {
        return changeFeedStartFrom.getStartTime();
    }
}
/**
 * @hidden
 */
function isNullOrEmpty(text) {
    return text === null || text === undefined || text.trim() === "";
}
/**
 * @hidden
 */
async function getEPKRangeForPrefixPartitionKey(internalPartitionKey) {
    const minEPK = getEffectivePartitionKeyForMultiHashPartitioning(internalPartitionKey);
    const maxEPK = minEPK + Constants.EffectivePartitionKeyConstants.MaximumExclusiveEffectivePartitionKey;
    return new QueryRange(minEPK, maxEPK, true, false);
}
/**
 * @hidden
 */
function getEffectivePartitionKeyForMultiHashPartitioning(partitionKeyInternal) {
    const hashArray = partitionKeyInternal.map((item) => hashV2PartitionKey([item]));
    return hashArray.join("");
}
/**
 * @hidden
 */
async function decryptChangeFeedResponse(result, diagnosticNode, changeFeedMode, encryptionProcessor) {
    let count = 0;
    diagnosticNode.beginEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation);
    for (let item of result.result) {
        if (changeFeedMode === exports.ChangeFeedMode.AllVersionsAndDeletes) {
            if ("current" in item && item.current !== null) {
                const { body, propertiesDecryptedCount } = await encryptionProcessor.decrypt(item.current);
                item.current = body;
                count += propertiesDecryptedCount;
            }
            if ("previous" in item && item.previous !== null) {
                const { body, propertiesDecryptedCount } = await encryptionProcessor.decrypt(item.previous);
                item.previous = body;
                count += propertiesDecryptedCount;
            }
        }
        else {
            const { body, propertiesDecryptedCount } = await encryptionProcessor.decrypt(item);
            item = body;
            count += propertiesDecryptedCount;
        }
    }
    diagnosticNode.endEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation, count);
}

/**
 * @hidden
 * Provides iterator for change feed for entire container or an epk range.
 *
 * Use `Items.getChangeFeedIterator()` to get an instance of the iterator.
 */
class ChangeFeedForEpkRange {
    /**
     * @internal
     */
    constructor(clientContext, container, partitionKeyRangeCache, resourceId, resourceLink, url, changeFeedOptions, epkRange) {
        this.clientContext = clientContext;
        this.container = container;
        this.partitionKeyRangeCache = partitionKeyRangeCache;
        this.resourceId = resourceId;
        this.resourceLink = resourceLink;
        this.url = url;
        this.changeFeedOptions = changeFeedOptions;
        this.epkRange = epkRange;
        this.generateContinuationToken = () => {
            return JSON.stringify(new CompositeContinuationToken(this.rId, this.queue.returnSnapshot()));
        };
        this.queue = new FeedRangeQueue();
        this.continuationToken = changeFeedOptions.continuationToken
            ? JSON.parse(changeFeedOptions.continuationToken)
            : undefined;
        this.isInstantiated = false;
        // startTime is used to store and specify time from which change feed should start reading new changes. StartFromNow flag is used to indicate fetching changes from now.
        if (changeFeedOptions.startFromNow) {
            this.startFromNow = true;
        }
        else if (changeFeedOptions.startTime) {
            this.startTime = changeFeedOptions.startTime.toUTCString();
        }
    }
    async setIteratorRid(diagnosticNode) {
        const { resource } = await this.container.readInternal(diagnosticNode);
        this.rId = resource._rid;
    }
    continuationTokenRidMatchContainerRid() {
        if (this.continuationToken.rid !== this.rId) {
            return false;
        }
        return true;
    }
    async fillChangeFeedQueue(diagnosticNode) {
        if (this.continuationToken) {
            // fill the queue with feed ranges in continuation token.
            await this.fetchContinuationTokenFeedRanges(diagnosticNode);
        }
        else {
            // fill the queue with feed ranges overlapping the given epk range.
            await this.fetchOverLappingFeedRanges(diagnosticNode);
        }
        this.isInstantiated = true;
    }
    /**
     * Fill the queue with the feed ranges overlapping with the given epk range.
     */
    async fetchOverLappingFeedRanges(diagnosticNode) {
        try {
            const overLappingRanges = await this.partitionKeyRangeCache.getOverlappingRanges(this.url, this.epkRange, diagnosticNode);
            for (const overLappingRange of overLappingRanges) {
                const [epkMinHeader, epkMaxHeader] = await extractOverlappingRanges(this.epkRange, overLappingRange);
                const feedRange = new ChangeFeedRange(overLappingRange.minInclusive, overLappingRange.maxExclusive, "", epkMinHeader, epkMaxHeader);
                this.queue.enqueue(feedRange);
            }
        }
        catch (err) {
            throw new ErrorResponse(err.message);
        }
    }
    /**
     * Fill the queue with feed ranges from continuation token
     */
    async fetchContinuationTokenFeedRanges(diagnosticNode) {
        const contToken = this.continuationToken;
        if (!this.continuationTokenRidMatchContainerRid()) {
            throw new ErrorResponse("The continuation token is not for the current container definition");
        }
        else {
            for (const cToken of contToken.Continuation) {
                const queryRange = new QueryRange(cToken.minInclusive, cToken.maxExclusive, true, false);
                try {
                    const overLappingRanges = await this.partitionKeyRangeCache.getOverlappingRanges(this.url, queryRange, diagnosticNode);
                    for (const overLappingRange of overLappingRanges) {
                        // check if the epk range present in continuation token entirely covers the overlapping range.
                        // If yes, minInclusive and maxExclusive of the overlapping range will be set.
                        // If no, i.e. there is only partial overlap, epkMinHeader and epkMaxHeader are set as min and max of overlap.
                        // This will be used when we make a call to fetch change feed.
                        const [epkMinHeader, epkMaxHeader] = await extractOverlappingRanges(queryRange, overLappingRange);
                        const feedRange = new ChangeFeedRange(overLappingRange.minInclusive, overLappingRange.maxExclusive, cToken.continuationToken, epkMinHeader, epkMaxHeader);
                        this.queue.enqueue(feedRange);
                    }
                }
                catch (err) {
                    throw new ErrorResponse(err.message);
                }
            }
        }
    }
    /**
     * Change feed is an infinite feed. hasMoreResults is always true.
     */
    get hasMoreResults() {
        return true;
    }
    /**
     * Gets an async iterator which will yield change feed results.
     */
    getAsyncIterator() {
        return tslib.__asyncGenerator(this, arguments, function* getAsyncIterator_1() {
            do {
                const result = yield tslib.__await(this.readNext());
                yield yield tslib.__await(result);
            } while (this.hasMoreResults);
        });
    }
    /**
     * Gets an async iterator which will yield pages of results from Azure Cosmos DB.
     *
     * Keeps iterating over the feedranges and checks if any feed range has new result. Keeps note of the last feed range which returned non 304 result.
     *
     * When same feed range is reached and no new changes are found, a 304 (not Modified) is returned to the end user. Then starts process all over again.
     */
    async readNext() {
        return withDiagnostics(async (diagnosticNode) => {
            // validate if the internal queue is filled up with feed ranges.
            if (!this.isInstantiated) {
                await this.setIteratorRid(diagnosticNode);
                await this.fillChangeFeedQueue(diagnosticNode);
            }
            // stores the last feedRange for which statusCode is not 304 i.e. there were new changes in that feed range.
            let firstNotModifiedFeedRange = undefined;
            let result;
            do {
                const [processedFeedRange, response] = await this.fetchNext(diagnosticNode);
                result = response;
                if (result !== undefined) {
                    {
                        if (firstNotModifiedFeedRange === undefined) {
                            firstNotModifiedFeedRange = processedFeedRange;
                        }
                        // move current feed range to end of queue to fetch result of next feed range.
                        // This is done to fetch changes in breadth first manner and avoid starvation.
                        this.queue.moveFirstElementToTheEnd();
                        // check if there are new results for the given feed range.
                        if (result.statusCode === StatusCodes.Ok) {
                            result.headers[Constants.HttpHeaders.ContinuationToken] =
                                this.generateContinuationToken();
                            if (this.clientContext.enableEncryption) {
                                await decryptChangeFeedResponse(result, diagnosticNode, this.changeFeedOptions.changeFeedMode, this.container.encryptionProcessor);
                            }
                            return result;
                        }
                    }
                }
            } while (!this.checkedAllFeedRanges(firstNotModifiedFeedRange));
            // set the continuation token after processing.
            result.headers[Constants.HttpHeaders.ContinuationToken] = this.generateContinuationToken();
            return result;
        }, this.clientContext);
    }
    /**
     * Read feed and retrieves the next page of results in Azure Cosmos DB.
     */
    async fetchNext(diagnosticNode) {
        const feedRange = this.queue.peek();
        if (feedRange) {
            // fetch results for feed range at the beginning of the queue.
            const result = await this.getFeedResponse(feedRange, diagnosticNode);
            // check if results need to be fetched again depending on status code returned.
            // Eg. in case of paritionSplit, results need to be fetched for the child partitions.
            const shouldRetry = await this.shouldRetryOnFailure(feedRange, result, diagnosticNode);
            if (shouldRetry) {
                this.queue.dequeue();
                return this.fetchNext(diagnosticNode);
            }
            else {
                // update the continuation value for the current feed range.
                const continuationValueForFeedRange = result.headers[Constants.HttpHeaders.ETag];
                const newFeedRange = this.queue.peek();
                newFeedRange.continuationToken = continuationValueForFeedRange;
                return [[newFeedRange.minInclusive, newFeedRange.maxExclusive], result];
            }
        }
        else {
            return [[undefined, undefined], undefined];
        }
    }
    checkedAllFeedRanges(firstNotModifiedFeedRange) {
        if (firstNotModifiedFeedRange === undefined) {
            return false;
        }
        const feedRangeQueueFirstElement = this.queue.peek();
        return (firstNotModifiedFeedRange[0] === (feedRangeQueueFirstElement === null || feedRangeQueueFirstElement === void 0 ? void 0 : feedRangeQueueFirstElement.minInclusive) &&
            firstNotModifiedFeedRange[1] === (feedRangeQueueFirstElement === null || feedRangeQueueFirstElement === void 0 ? void 0 : feedRangeQueueFirstElement.maxExclusive));
    }
    /**
     * Checks whether the current EpkRange is split into multiple ranges or not.
     *
     * If yes, it force refreshes the partitionKeyRange cache and enqueue children epk ranges.
     */
    async shouldRetryOnFailure(feedRange, response, diagnosticNode) {
        if (response.statusCode === StatusCodes.Ok || response.statusCode === StatusCodes.NotModified) {
            return false;
        }
        const partitionSplit = response.statusCode === StatusCodes.Gone &&
            (response.subStatusCode === SubStatusCodes.PartitionKeyRangeGone ||
                response.subStatusCode === SubStatusCodes.CompletingSplit);
        if (partitionSplit) {
            const queryRange = new QueryRange(feedRange.epkMinHeader ? feedRange.epkMinHeader : feedRange.minInclusive, feedRange.epkMaxHeader ? feedRange.epkMaxHeader : feedRange.maxExclusive, true, false);
            const resolvedRanges = await this.partitionKeyRangeCache.getOverlappingRanges(this.url, queryRange, diagnosticNode, true);
            if (resolvedRanges.length < 1) {
                throw new ErrorResponse("Partition split/merge detected but no overlapping ranges found.");
            }
            // This covers both cases of merge and split.
            // resolvedRanges.length > 1 in case of split.
            // resolvedRanges.length === 1 in case of merge. EpkRange headers will be added in this case.
            if (resolvedRanges.length >= 1) {
                await this.handleSplit(false, resolvedRanges, queryRange, feedRange.continuationToken);
            }
            return true;
        }
        return false;
    }
    /*
     * Enqueues all the children feed ranges for the given feed range.
     */
    async handleSplit(shiftLeft, resolvedRanges, oldFeedRange, continuationToken) {
        let flag = 0;
        if (shiftLeft) {
            // This section is only applicable when handleSplit is called by getPartitionRangeId().
            // used only when existing partition key range cache is used to check for any overlapping ranges.
            // Modifies the first element with the first overlapping range.
            const [epkMinHeader, epkMaxHeader] = await extractOverlappingRanges(oldFeedRange, resolvedRanges[0]);
            const newFeedRange = new ChangeFeedRange(resolvedRanges[0].minInclusive, resolvedRanges[0].maxExclusive, continuationToken, epkMinHeader, epkMaxHeader);
            this.queue.modifyFirstElement(newFeedRange);
            flag = 1;
        }
        // Enqueue the overlapping ranges.
        for (let i = flag; i < resolvedRanges.length; i++) {
            const [epkMinHeader, epkMaxHeader] = await extractOverlappingRanges(oldFeedRange, resolvedRanges[i]);
            const newFeedRange = new ChangeFeedRange(resolvedRanges[i].minInclusive, resolvedRanges[i].maxExclusive, continuationToken, epkMinHeader, epkMaxHeader);
            this.queue.enqueue(newFeedRange);
        }
    }
    /**
     * Fetch the partitionKeyRangeId for the given feed range.
     *
     * This partitionKeyRangeId is passed to queryFeed to fetch the results.
     */
    async getPartitionRangeId(feedRange, diagnosticNode) {
        const min = feedRange.epkMinHeader ? feedRange.epkMinHeader : feedRange.minInclusive;
        const max = feedRange.epkMaxHeader ? feedRange.epkMaxHeader : feedRange.maxExclusive;
        const queryRange = new QueryRange(min, max, true, false);
        const resolvedRanges = await this.partitionKeyRangeCache.getOverlappingRanges(this.url, queryRange, diagnosticNode, false);
        if (resolvedRanges.length < 1) {
            throw new ErrorResponse("No overlapping ranges found.");
        }
        const firstResolvedRange = resolvedRanges[0];
        if (resolvedRanges.length > 1) {
            await this.handleSplit(true, resolvedRanges, queryRange, feedRange.continuationToken);
        }
        return firstResolvedRange.id;
    }
    async getFeedResponse(feedRange, diagnosticNode) {
        const feedOptions = {
            initialHeaders: {},
            useLatestVersionFeed: true,
            useAllVersionsAndDeletesFeed: false,
        };
        if (typeof this.changeFeedOptions.maxItemCount === "number") {
            feedOptions.maxItemCount = this.changeFeedOptions.maxItemCount;
        }
        if (this.changeFeedOptions.sessionToken) {
            feedOptions.sessionToken = this.changeFeedOptions.sessionToken;
        }
        if (feedRange.continuationToken) {
            feedOptions.accessCondition = {
                type: Constants.HttpHeaders.IfNoneMatch,
                condition: feedRange.continuationToken,
            };
        }
        else if (this.startFromNow) {
            feedOptions.initialHeaders[Constants.HttpHeaders.IfNoneMatch] =
                Constants.ChangeFeedIfNoneMatchStartFromNowHeader;
        }
        if (this.startTime) {
            feedOptions.initialHeaders[Constants.HttpHeaders.IfModifiedSince] = this.startTime;
        }
        if (this.changeFeedOptions.changeFeedMode &&
            this.changeFeedOptions.changeFeedMode === exports.ChangeFeedMode.AllVersionsAndDeletes) {
            feedOptions.useAllVersionsAndDeletesFeed = true;
            feedOptions.useLatestVersionFeed = false;
        }
        const rangeId = await this.getPartitionRangeId(feedRange, diagnosticNode);
        if (this.clientContext.enableEncryption) {
            await this.container.checkAndInitializeEncryption();
            feedOptions.containerRid = this.container._rid;
        }
        try {
            // startEpk and endEpk are only valid in case we want to fetch result for a part of partition and not the entire partition.
            const response = await this.clientContext.queryFeed({
                path: this.resourceLink,
                resourceType: exports.ResourceType.item,
                resourceId: this.resourceId,
                resultFn: (result) => (result ? result.Documents : []),
                query: undefined,
                options: feedOptions,
                diagnosticNode,
                partitionKey: undefined,
                partitionKeyRangeId: rangeId,
                startEpk: feedRange.epkMinHeader,
                endEpk: feedRange.epkMaxHeader,
            });
            return new ChangeFeedIteratorResponse(response.result, response.result ? response.result.length : 0, response.code, response.headers, getEmptyCosmosDiagnostics());
        }
        catch (err) {
            // If partition split/merge is encountered, handle it gracefully and continue fetching results.
            if (err.code === StatusCodes.Gone) {
                return new ChangeFeedIteratorResponse([], 0, err.code, err.headers, getEmptyCosmosDiagnostics(), err.substatus);
            }
            // If any other errors are encountered, throw the error.
            const errorResponse = new ErrorResponse(err.message);
            errorResponse.code = err.code;
            errorResponse.headers = err.headers;
            throw errorResponse;
        }
    }
}

/**
 * Continuation token for change feed of entire container, or a specific Epk Range.
 * @internal
 */
class ContinuationTokenForPartitionKey {
    constructor(rid, partitionKey, continuation) {
        this.rid = rid;
        this.partitionKey = partitionKey;
        this.Continuation = continuation;
    }
}

/**
 * @hidden
 * Provides iterator for change feed for one partition key.
 *
 * Use `Items.getChangeFeedIterator()` to get an instance of the iterator.
 */
class ChangeFeedForPartitionKey {
    /**
     * @internal
     */
    constructor(clientContext, container, resourceId, resourceLink, partitionKey, changeFeedOptions) {
        this.clientContext = clientContext;
        this.container = container;
        this.resourceId = resourceId;
        this.resourceLink = resourceLink;
        this.partitionKey = partitionKey;
        this.changeFeedOptions = changeFeedOptions;
        this.continuationToken = changeFeedOptions.continuationToken
            ? JSON.parse(changeFeedOptions.continuationToken)
            : undefined;
        this.isInstantiated = false;
        // startTime is used to store and specify time from which change feed should start reading new changes. StartFromNow flag is used to indicate fetching changes from now.
        if (changeFeedOptions.startFromNow) {
            this.startFromNow = true;
        }
        else if (changeFeedOptions.startTime) {
            this.startTime = changeFeedOptions.startTime.toUTCString();
        }
    }
    async instantiateIterator(diagnosticNode) {
        await this.setIteratorRid(diagnosticNode);
        if (this.clientContext.enableEncryption) {
            await this.container.checkAndInitializeEncryption();
            // returns copy of object to avoid encryption of original partition key passed
            this.partitionKey = copyObject(this.partitionKey);
            diagnosticNode.beginEncryptionDiagnostics(Constants.Encryption.DiagnosticsEncryptOperation);
            const { partitionKeyList, encryptedCount } = await this.container.encryptionProcessor.getEncryptedPartitionKeyValue(convertToInternalPartitionKey(this.partitionKey));
            this.partitionKey = partitionKeyList;
            diagnosticNode.endEncryptionDiagnostics(Constants.Encryption.DiagnosticsEncryptOperation, encryptedCount);
        }
        if (this.continuationToken) {
            if (!this.continuationTokenRidMatchContainerRid()) {
                throw new ErrorResponse("The continuation is not for the current container definition.");
            }
        }
        else {
            this.continuationToken = new ContinuationTokenForPartitionKey(this.rId, this.partitionKey, "");
        }
        this.isInstantiated = true;
    }
    continuationTokenRidMatchContainerRid() {
        if (this.continuationToken.rid !== this.rId) {
            return false;
        }
        return true;
    }
    async setIteratorRid(diagnosticNode) {
        const { resource } = await this.container.readInternal(diagnosticNode);
        this.rId = resource._rid;
    }
    /**
     * Change feed is an infinite feed. hasMoreResults is always true.
     */
    get hasMoreResults() {
        return true;
    }
    /**
     * Gets an async iterator which will yield change feed results.
     */
    getAsyncIterator() {
        return tslib.__asyncGenerator(this, arguments, function* getAsyncIterator_1() {
            do {
                const result = yield tslib.__await(this.readNext());
                yield yield tslib.__await(result);
            } while (this.hasMoreResults);
        });
    }
    /**
     * Returns the result of change feed from Azure Cosmos DB.
     */
    async readNext() {
        return withDiagnostics(async (diagnosticNode) => {
            if (!this.isInstantiated) {
                await this.instantiateIterator(diagnosticNode);
            }
            const result = await this.fetchNext(diagnosticNode);
            if (result.statusCode === StatusCodes.Ok) {
                if (this.clientContext.enableEncryption) {
                    await decryptChangeFeedResponse(result, diagnosticNode, this.changeFeedOptions.changeFeedMode, this.container.encryptionProcessor);
                }
            }
            return result;
        }, this.clientContext);
    }
    /**
     * Read feed and retrieves the next set of results in Azure Cosmos DB.
     */
    async fetchNext(diagnosticNode) {
        const response = await this.getFeedResponse(diagnosticNode);
        this.continuationToken.Continuation = response.headers[Constants.HttpHeaders.ETag];
        response.headers[Constants.HttpHeaders.ContinuationToken] = JSON.stringify(this.continuationToken);
        return response;
    }
    async getFeedResponse(diagnosticNode) {
        const feedOptions = {
            initialHeaders: {},
            useLatestVersionFeed: true,
            useAllVersionsAndDeletesFeed: false,
        };
        if (typeof this.changeFeedOptions.maxItemCount === "number") {
            feedOptions.maxItemCount = this.changeFeedOptions.maxItemCount;
        }
        if (this.changeFeedOptions.sessionToken) {
            feedOptions.sessionToken = this.changeFeedOptions.sessionToken;
        }
        const continuation = this.continuationToken.Continuation;
        if (continuation) {
            feedOptions.accessCondition = {
                type: Constants.HttpHeaders.IfNoneMatch,
                condition: continuation,
            };
        }
        else if (this.startFromNow) {
            feedOptions.initialHeaders[Constants.HttpHeaders.IfNoneMatch] =
                Constants.ChangeFeedIfNoneMatchStartFromNowHeader;
        }
        if (this.startTime) {
            feedOptions.initialHeaders[Constants.HttpHeaders.IfModifiedSince] = this.startTime;
        }
        if (this.changeFeedOptions.changeFeedMode &&
            this.changeFeedOptions.changeFeedMode === exports.ChangeFeedMode.AllVersionsAndDeletes) {
            feedOptions.useAllVersionsAndDeletesFeed = true;
            feedOptions.useLatestVersionFeed = false;
        }
        if (this.clientContext.enableEncryption) {
            feedOptions.containerRid = this.container._rid;
        }
        try {
            const response = await this.clientContext.queryFeed({
                path: this.resourceLink,
                resourceType: exports.ResourceType.item,
                resourceId: this.resourceId,
                resultFn: (result) => (result ? result.Documents : []),
                diagnosticNode,
                query: undefined,
                options: feedOptions,
                partitionKey: this.partitionKey,
            });
            return new ChangeFeedIteratorResponse(response.result, response.result ? response.result.length : 0, response.code, response.headers, getEmptyCosmosDiagnostics());
        }
        catch (err) {
            // If any errors are encountered, throw the error.
            const errorResponse = new ErrorResponse(err.message);
            errorResponse.code = err.code;
            errorResponse.headers = err.headers;
            throw errorResponse;
        }
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @hidden
 * Class which specifies the ChangeFeedIterator to start reading changes from this moment in time.
 */
class ChangeFeedStartFromNow {
    constructor(cfResource) {
        this.cfResource = cfResource;
    }
    getCfResource() {
        return this.cfResource;
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Enum to specify the resource for which change feed is being fetched.
 */
var ChangeFeedResourceType;
(function (ChangeFeedResourceType) {
    ChangeFeedResourceType[ChangeFeedResourceType["FeedRange"] = 0] = "FeedRange";
    ChangeFeedResourceType[ChangeFeedResourceType["PartitionKey"] = 1] = "PartitionKey";
})(ChangeFeedResourceType || (ChangeFeedResourceType = {}));

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @hidden
 * Class which specifies the ChangeFeedIterator to start reading changes from a saved point.
 */
class ChangeFeedStartFromContinuation {
    constructor(continuation) {
        this.continuationToken = continuation;
    }
    getCfResource() {
        return this.continuationToken;
    }
    getCfResourceJson() {
        return JSON.parse(this.continuationToken);
    }
    getResourceType() {
        const cToken = this.getCfResourceJson();
        if (Object.prototype.hasOwnProperty.call(cToken, "partitionKey") &&
            Object.prototype.hasOwnProperty.call(cToken, "Continuation") &&
            typeof cToken.Continuation === "string") {
            return ChangeFeedResourceType.PartitionKey;
        }
        else if (Object.prototype.hasOwnProperty.call(cToken, "Continuation") &&
            Array.isArray(cToken.Continuation) &&
            cToken.Continuation.length > 0) {
            return ChangeFeedResourceType.FeedRange;
        }
        else {
            throw new ErrorResponse("Invalid continuation token.");
        }
    }
}

/**
 * Base class for where to start a ChangeFeedIterator.
 */
/* eslint-disable @typescript-eslint/no-extraneous-class */
class ChangeFeedStartFrom {
    /**
     * Returns an object that tells the ChangeFeedIterator to start from the beginning of time.
     * @param cfResource - PartitionKey or FeedRange for which changes are to be fetched. Leave blank for fetching changes for entire container.
     */
    static Beginning(cfResource) {
        return new ChangeFeedStartFromBeginning(cfResource);
    }
    /**
     *  Returns an object that tells the ChangeFeedIterator to start reading changes from this moment onward.
     * @param cfResource - PartitionKey or FeedRange for which changes are to be fetched. Leave blank for fetching changes for entire container.
     **/
    static Now(cfResource) {
        return new ChangeFeedStartFromNow(cfResource);
    }
    /**
     * Returns an object that tells the ChangeFeedIterator to start reading changes from some point in time onward.
     * @param startTime - Date object specfiying the time to start reading changes from.
     * @param cfResource - PartitionKey or FeedRange for which changes are to be fetched. Leave blank for fetching changes for entire container.
     */
    static Time(startTime, cfResource) {
        if (!startTime) {
            throw new ErrorResponse("startTime must be present");
        }
        if (startTime instanceof Date === true) {
            return new ChangeFeedStartFromTime(startTime, cfResource);
        }
        else {
            throw new ErrorResponse("startTime must be a Date object.");
        }
    }
    /**
     * Returns an object that tells the ChangeFeedIterator to start reading changes from a save point.
     * @param continuation - The continuation to resume from.
     */
    static Continuation(continuationToken) {
        if (!continuationToken) {
            throw new ErrorResponse("Argument continuation must be passed.");
        }
        if (isNullOrEmpty(continuationToken)) {
            throw new ErrorResponse("Argument continuationToken must be a non-empty string.");
        }
        return new ChangeFeedStartFromContinuation(continuationToken);
    }
}

async function buildChangeFeedIterator(cfOptions, clientContext, container, partitionKeyRangeCache) {
    const url = container.url;
    const path = getPathFromLink(url, exports.ResourceType.item);
    const id = getIdFromLink(url);
    let changeFeedStartFrom = cfOptions.changeFeedStartFrom;
    if (changeFeedStartFrom === undefined) {
        changeFeedStartFrom = ChangeFeedStartFrom.Now();
    }
    if (changeFeedStartFrom instanceof ChangeFeedStartFromContinuation) {
        const continuationToken = changeFeedStartFrom.getCfResourceJson();
        const resourceType = changeFeedStartFrom.getResourceType();
        const internalCfOptions = buildInternalChangeFeedOptions(cfOptions, changeFeedStartFrom.getCfResource());
        if (resourceType === ChangeFeedResourceType.PartitionKey &&
            isPartitionKey(continuationToken.partitionKey)) {
            return new ChangeFeedForPartitionKey(clientContext, container, id, path, continuationToken.partitionKey, internalCfOptions);
        }
        else if (resourceType === ChangeFeedResourceType.FeedRange) {
            return new ChangeFeedForEpkRange(clientContext, container, partitionKeyRangeCache, id, path, url, internalCfOptions, undefined);
        }
        else {
            throw new ErrorResponse("Invalid continuation token.");
        }
    }
    else if (changeFeedStartFrom instanceof ChangeFeedStartFromNow ||
        changeFeedStartFrom instanceof ChangeFeedStartFromTime ||
        changeFeedStartFrom instanceof ChangeFeedStartFromBeginning) {
        const startFromNow = changeFeedStartFrom instanceof ChangeFeedStartFromNow ? true : false;
        const startTime = startFromNow ? undefined : fetchStartTime(changeFeedStartFrom);
        const internalCfOptions = buildInternalChangeFeedOptions(cfOptions, undefined, startTime, startFromNow);
        const cfResource = changeFeedStartFrom.getCfResource();
        if (isPartitionKey(cfResource)) {
            const partitionKey = cfResource;
            const partitionKeyDefinition = await container.getPartitionKeyDefinition();
            if (partitionKeyDefinition !== undefined &&
                isPrefixPartitionKey(partitionKey, partitionKeyDefinition.resource)) {
                const effectiveEPKRange = await getEPKRangeForPrefixPartitionKey(partitionKey);
                return new ChangeFeedForEpkRange(clientContext, container, partitionKeyRangeCache, id, path, url, internalCfOptions, effectiveEPKRange);
            }
            return new ChangeFeedForPartitionKey(clientContext, container, id, path, cfResource, internalCfOptions);
        }
        else {
            let internalCfResource;
            if (cfResource === undefined) {
                internalCfResource = new QueryRange(Constants.EffectivePartitionKeyConstants.MinimumInclusiveEffectivePartitionKey, Constants.EffectivePartitionKeyConstants.MaximumExclusiveEffectivePartitionKey, true, false);
            }
            else if (isEpkRange(cfResource)) {
                internalCfResource = new QueryRange(cfResource.minInclusive, cfResource.maxExclusive, true, false);
            }
            else {
                throw new ErrorResponse("Invalid feed range.");
            }
            return new ChangeFeedForEpkRange(clientContext, container, partitionKeyRangeCache, id, path, url, internalCfOptions, internalCfResource);
        }
    }
    else {
        throw new ErrorResponse("Invalid change feed start location.");
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/*
 * Represents the change feed policy configuration for a container in the Azure Cosmos DB service.
 */
class ChangeFeedRetentionTimeSpan {
    /**
     * @internal
     */
    constructor(minutes) {
        if (typeof minutes !== "number") {
            throw new ErrorResponse("ChangeFeedRetentionTimeSpan must be a number.");
        }
        if (minutes < 0) {
            throw new ErrorResponse("ChangeFeedRetentionTimeSpan must be a positive number.");
        }
        if (minutes % 1 !== 0) {
            throw new ErrorResponse("Retention's granularity is minutes.");
        }
        this.retentionInMinutes = minutes;
    }
    /**
     * Specifies the retention window in minutes for which processing the change feed with allVersionsAndDeletes mode will be available.
     */
    static fromMinutes(minutes) {
        return new ChangeFeedRetentionTimeSpan(minutes);
    }
    /**
     * @internal
     */
    getRetentionInMinutes() {
        return this.retentionInMinutes;
    }
}

/**
 * Represents the change feed policy configuration for a container in the Azure Cosmos DB service.
 */
class ChangeFeedPolicy {
    constructor(retentionDuration) {
        this.retentionDuration = retentionDuration.getRetentionInMinutes();
    }
}

/**
 * @hidden
 * Provides iterator for change feed.
 *
 * Use `Items.getChangeFeedIterator()` to get an instance of the iterator.
 */
class ChangeFeedIteratorBuilder {
    /**
     * @internal
     */
    constructor(cfOptions, clientContext, container, partitionKeyRangeCache) {
        this.cfOptions = cfOptions;
        this.clientContext = clientContext;
        this.container = container;
        this.partitionKeyRangeCache = partitionKeyRangeCache;
        this.isInitialized = false;
    }
    /**
     * Change feed is an infinite feed. hasMoreResults is always true.
     */
    get hasMoreResults() {
        return true;
    }
    /**
     * Gets an async iterator which will yield change feed results.
     */
    getAsyncIterator() {
        return tslib.__asyncGenerator(this, arguments, function* getAsyncIterator_1() {
            yield tslib.__await(this.initializeIterator());
            do {
                const result = yield tslib.__await(this.iterator.readNext());
                yield yield tslib.__await(result);
            } while (this.hasMoreResults);
        });
    }
    /**
     * Returns the result of change feed from Azure Cosmos DB.
     */
    async readNext() {
        await this.initializeIterator();
        return this.iterator.readNext();
    }
    async initializeIterator() {
        if (!this.isInitialized) {
            try {
                const iterator = await buildChangeFeedIterator(this.cfOptions, this.clientContext, this.container, this.partitionKeyRangeCache);
                this.isInitialized = true;
                this.iterator = iterator;
            }
            catch (err) {
                throw new ErrorResponse(err.message);
            }
        }
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
// ----------------------------------------------------------------------------
// Utility methods
//
/** @hidden */
function javaScriptFriendlyJSONStringify(s) {
    // two line terminators (Line separator and Paragraph separator) are not needed to be escaped in JSON
    // but are needed to be escaped in JavaScript.
    return JSON.stringify(s)
        .replace(/\u2028/g, "\\u2028")
        .replace(/\u2029/g, "\\u2029");
}
/** @hidden */
function bodyFromData(data) {
    if (typeof data === "object") {
        return javaScriptFriendlyJSONStringify(data);
    }
    return data;
}
const JsonContentType = "application/json";
/**
 * @hidden
 */
async function getHeaders({ clientOptions, defaultHeaders, verb, path, resourceId, resourceType, options = {}, partitionKeyRangeId, useMultipleWriteLocations, partitionKey, }) {
    const headers = Object.assign({ [Constants.HttpHeaders.ResponseContinuationTokenLimitInKB]: 1, [Constants.HttpHeaders.EnableCrossPartitionQuery]: true }, defaultHeaders);
    // Adding SDKSupportedCapabilities header to hint that SDK supports partition merge
    headers[Constants.HttpHeaders.SDKSupportedCapabilities] = SDKSupportedCapabilities.PartitionMerge;
    if (useMultipleWriteLocations) {
        headers[Constants.HttpHeaders.ALLOW_MULTIPLE_WRITES] = true;
    }
    if (options.continuationTokenLimitInKB) {
        headers[Constants.HttpHeaders.ResponseContinuationTokenLimitInKB] =
            options.continuationTokenLimitInKB;
    }
    if (options.continuationToken) {
        headers[Constants.HttpHeaders.Continuation] = options.continuationToken;
    }
    else if (options.continuation) {
        headers[Constants.HttpHeaders.Continuation] = options.continuation;
    }
    if (options.preTriggerInclude) {
        headers[Constants.HttpHeaders.PreTriggerInclude] =
            options.preTriggerInclude.constructor === Array
                ? options.preTriggerInclude.join(",")
                : options.preTriggerInclude;
    }
    if (options.postTriggerInclude) {
        headers[Constants.HttpHeaders.PostTriggerInclude] =
            options.postTriggerInclude.constructor === Array
                ? options.postTriggerInclude.join(",")
                : options.postTriggerInclude;
    }
    if (options.offerType) {
        headers[Constants.HttpHeaders.OfferType] = options.offerType;
    }
    if (options.offerThroughput) {
        headers[Constants.HttpHeaders.OfferThroughput] = options.offerThroughput;
    }
    if (options.maxItemCount) {
        headers[Constants.HttpHeaders.PageSize] = options.maxItemCount;
    }
    if (options.accessCondition) {
        if (options.accessCondition.type === "IfMatch") {
            headers[Constants.HttpHeaders.IfMatch] = options.accessCondition.condition;
        }
        else {
            headers[Constants.HttpHeaders.IfNoneMatch] = options.accessCondition.condition;
        }
    }
    if (options.useAllVersionsAndDeletesFeed) {
        // headers required for reading feed in allVersionsAndDeletes mode
        headers[Constants.HttpHeaders.A_IM] = exports.ChangeFeedMode.AllVersionsAndDeletes;
        headers[Constants.HttpHeaders.ChangeFeedWireFormatVersion] =
            Constants.AllVersionsAndDeletesChangeFeedWireFormatVersion;
    }
    if (options.useIncrementalFeed || options.useLatestVersionFeed) {
        headers[Constants.HttpHeaders.A_IM] = exports.ChangeFeedMode.LatestVersion;
    }
    if (options.indexingDirective) {
        headers[Constants.HttpHeaders.IndexingDirective] = options.indexingDirective;
    }
    if (options.consistencyLevel) {
        headers[Constants.HttpHeaders.ConsistencyLevel] = options.consistencyLevel;
    }
    if (options.priorityLevel) {
        headers[Constants.HttpHeaders.PriorityLevel] = options.priorityLevel;
    }
    if (options.throughputBucket) {
        headers[Constants.HttpHeaders.ThroughputBucket] = options.throughputBucket;
    }
    if (options.maxIntegratedCacheStalenessInMs && resourceType === exports.ResourceType.item) {
        if (typeof options.maxIntegratedCacheStalenessInMs === "number") {
            headers[Constants.HttpHeaders.DedicatedGatewayPerRequestCacheStaleness] =
                options.maxIntegratedCacheStalenessInMs.toString();
        }
        else {
            defaultLogger.error(`RangeError: maxIntegratedCacheStalenessInMs "${options.maxIntegratedCacheStalenessInMs}" is not a valid parameter.`);
            headers[Constants.HttpHeaders.DedicatedGatewayPerRequestCacheStaleness] = "null";
        }
    }
    if (options.bypassIntegratedCache) {
        headers[Constants.HttpHeaders.DedicatedGatewayPerRequestBypassCache] =
            options.bypassIntegratedCache.toString();
    }
    if (options.resourceTokenExpirySeconds) {
        headers[Constants.HttpHeaders.ResourceTokenExpiry] = options.resourceTokenExpirySeconds;
    }
    if (options.sessionToken) {
        headers[Constants.HttpHeaders.SessionToken] = options.sessionToken;
    }
    if (options.enableScanInQuery) {
        headers[Constants.HttpHeaders.EnableScanInQuery] = options.enableScanInQuery;
    }
    if (options.populateQuotaInfo) {
        headers[Constants.HttpHeaders.PopulateQuotaInfo] = options.populateQuotaInfo;
    }
    if (options.populateQueryMetrics) {
        headers[Constants.HttpHeaders.PopulateQueryMetrics] = options.populateQueryMetrics;
    }
    if (options.maxDegreeOfParallelism !== undefined &&
        options.maxDegreeOfParallelism !== 0 &&
        options.maxDegreeOfParallelism !== 1) {
        headers[Constants.HttpHeaders.ParallelizeCrossPartitionQuery] = true;
    }
    if (options.populateQuotaInfo) {
        headers[Constants.HttpHeaders.PopulateQuotaInfo] = true;
    }
    if (partitionKey !== undefined && !headers[Constants.HttpHeaders.PartitionKey]) {
        headers[Constants.HttpHeaders.PartitionKey] = jsonStringifyAndEscapeNonASCII(partitionKey);
    }
    if (clientOptions.key || clientOptions.tokenProvider) {
        headers[Constants.HttpHeaders.XDate] = new Date().toUTCString();
    }
    if (verb === exports.HTTPMethod.post || verb === exports.HTTPMethod.put) {
        if (!headers[Constants.HttpHeaders.ContentType]) {
            headers[Constants.HttpHeaders.ContentType] = JsonContentType;
        }
    }
    if (!headers[Constants.HttpHeaders.Accept]) {
        headers[Constants.HttpHeaders.Accept] = JsonContentType;
    }
    if (partitionKeyRangeId !== undefined) {
        headers[Constants.HttpHeaders.PartitionKeyRangeID] = partitionKeyRangeId;
    }
    if (options.enableScriptLogging) {
        headers[Constants.HttpHeaders.EnableScriptLogging] = options.enableScriptLogging;
    }
    if (options.disableRUPerMinuteUsage) {
        headers[Constants.HttpHeaders.DisableRUPerMinuteUsage] = true;
    }
    if (options.populateIndexMetrics) {
        headers[Constants.HttpHeaders.PopulateIndexMetrics] = options.populateIndexMetrics;
    }
    if (clientOptions.clientEncryptionOptions) {
        headers[Constants.HttpHeaders.IsClientEncryptedHeader] = true;
        if (options.containerRid) {
            headers[Constants.HttpHeaders.IntendedCollectionHeader] = options.containerRid;
        }
    }
    if (clientOptions.key ||
        clientOptions.resourceTokens ||
        clientOptions.tokenProvider ||
        clientOptions.permissionFeed) {
        await setAuthorizationHeader(clientOptions, verb, path, resourceId, resourceType, headers);
    }
    return headers;
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
function isKeyInRange(min, max, key) {
    const isAfterMinInclusive = key.localeCompare(min) >= 0;
    const isBeforeMax = key.localeCompare(max) < 0;
    return isAfterMinInclusive && isBeforeMax;
}
const BulkOperationType = {
    Create: "Create",
    Upsert: "Upsert",
    Read: "Read",
    Delete: "Delete",
    Replace: "Replace",
    Patch: "Patch",
};
/**
 * Maps OperationInput to Operation by
 * - generating Ids if needed.
 * - choosing partitionKey which can be used to choose which batch this
 * operation should be part of. The order is -
 *   1. If the operationInput itself has partitionKey field set it is used.
 *   2. Other wise for create/replace/upsert it is extracted from resource body.
 *   3. For read/delete/patch type operations undefined partitionKey is used.
 * - Here one nuance is that, the partitionKey field inside Operation needs to
 *  be serialized as a JSON string.
 * @param operationInput - OperationInput
 * @param definition - PartitionKeyDefinition
 * @param options - RequestOptions
 * @returns
 */
function prepareOperations(operationInput, definition, options = {}) {
    populateIdsIfNeeded(operationInput, options);
    let partitionKey;
    if (Object.prototype.hasOwnProperty.call(operationInput, "partitionKey")) {
        if (operationInput.partitionKey === undefined) {
            partitionKey = definition.paths.map(() => NonePartitionKeyLiteral);
        }
        else {
            partitionKey = convertToInternalPartitionKey(operationInput.partitionKey);
        }
    }
    else {
        switch (operationInput.operationType) {
            case BulkOperationType.Create:
            case BulkOperationType.Replace:
            case BulkOperationType.Upsert:
                partitionKey = assertNotUndefined(extractPartitionKeys(operationInput.resourceBody, definition), "Unexpected undefined Partition Key Found.");
                break;
            case BulkOperationType.Read:
            case BulkOperationType.Delete:
            case BulkOperationType.Patch:
                partitionKey = undefinedPartitionKey(definition);
                break;
        }
    }
    return {
        operation: Object.assign(Object.assign({}, operationInput), { partitionKey: JSON.stringify(partitionKey) }),
        partitionKey,
    };
}
/**
 * For operations requiring Id genrate random uuids.
 * @param operationInput - OperationInput to be checked.
 * @param options - RequestOptions
 */
function populateIdsIfNeeded(operationInput, options) {
    if (operationInput.operationType === BulkOperationType.Create ||
        operationInput.operationType === BulkOperationType.Upsert) {
        if ((operationInput.resourceBody.id === undefined || operationInput.resourceBody.id === "") &&
            !options.disableAutomaticIdGeneration) {
            operationInput.resourceBody.id = coreUtil.randomUUID();
        }
    }
}
/**
 * Splits a batch into array of batches based on cumulative size of its operations by making sure
 * cumulative size of an individual batch is not larger than {@link Constants.DefaultMaxBulkRequestBodySizeInBytes}.
 * If a single operation itself is larger than {@link Constants.DefaultMaxBulkRequestBodySizeInBytes}, that
 * operation would be moved into a batch containing only that operation.
 * @param originalBatch - A batch of operations needed to be checked.
 * @returns
 * @hidden
 */
function splitBatchBasedOnBodySize(originalBatch) {
    if ((originalBatch === null || originalBatch === void 0 ? void 0 : originalBatch.operations) === undefined || originalBatch.operations.length < 1)
        return [];
    let currentBatchSize = calculateObjectSizeInBytes(originalBatch.operations[0]);
    let currentBatch = Object.assign(Object.assign({}, originalBatch), { operations: [originalBatch.operations[0]], indexes: [originalBatch.indexes[0]] });
    const processedBatches = [];
    processedBatches.push(currentBatch);
    for (let index = 1; index < originalBatch.operations.length; index++) {
        const operation = originalBatch.operations[index];
        const currentOpSize = calculateObjectSizeInBytes(operation);
        if (currentBatchSize + currentOpSize > Constants.DefaultMaxBulkRequestBodySizeInBytes) {
            currentBatch = Object.assign(Object.assign({}, originalBatch), { operations: [], indexes: [] });
            processedBatches.push(currentBatch);
            currentBatchSize = 0;
        }
        currentBatch.operations.push(operation);
        currentBatch.indexes.push(originalBatch.indexes[index]);
        currentBatchSize += currentOpSize;
    }
    return processedBatches;
}
/**
 * Calculates size of an JSON object in bytes with utf-8 encoding.
 * @hidden
 */
function calculateObjectSizeInBytes(obj) {
    return new TextEncoder().encode(bodyFromData(obj)).length;
}
function decorateBatchOperation(operation, options = {}) {
    if (operation.operationType === BulkOperationType.Create ||
        operation.operationType === BulkOperationType.Upsert) {
        if ((operation.resourceBody.id === undefined || operation.resourceBody.id === "") &&
            !options.disableAutomaticIdGeneration) {
            operation.resourceBody.id = coreUtil.randomUUID();
        }
    }
    return operation;
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
const PatchOperationType = {
    add: "add",
    replace: "replace",
    remove: "remove",
    set: "set",
    incr: "incr",
};

const logger$3 = logger$5.createClientLogger("ClientContext");
/** @hidden */
var STATES;
(function (STATES) {
    STATES["start"] = "start";
    STATES["inProgress"] = "inProgress";
    STATES["ended"] = "ended";
})(STATES || (STATES = {}));
/** @hidden */
class DefaultQueryExecutionContext {
    get continuation() {
        return this.continuationToken;
    }
    /**
     * Provides the basic Query Execution Context.
     * This wraps the internal logic query execution using provided fetch functions
     *
     * @param clientContext  - Is used to read the partitionKeyRanges for split proofing
     * @param query          - A SQL query.
     * @param options        - Represents the feed options.
     * @param fetchFunctions - A function to retrieve each page of data.
     *                          An array of functions may be used to query more than one partition.
     * @hidden
     */
    constructor(options, fetchFunctions, correlatedActivityId) {
        this.resources = [];
        this.currentIndex = 0;
        this.currentPartitionIndex = 0;
        this.fetchFunctions = Array.isArray(fetchFunctions) ? fetchFunctions : [fetchFunctions];
        this.options = options || {};
        this.continuationToken = this.options.continuationToken || this.options.continuation || null;
        this.state = DefaultQueryExecutionContext.STATES.start;
        this.correlatedActivityId = correlatedActivityId;
    }
    /**
     * Execute a provided callback on the next element in the execution context.
     */
    async nextItem(diagnosticNode) {
        ++this.currentIndex;
        const response = await this.current(diagnosticNode);
        return response;
    }
    /**
     * Retrieve the current element on the execution context.
     */
    async current(diagnosticNode) {
        if (this.currentIndex < this.resources.length) {
            return {
                result: this.resources[this.currentIndex],
                headers: getInitialHeader(),
            };
        }
        if (this._canFetchMore()) {
            const { result: resources, headers } = await this.fetchMore(diagnosticNode);
            this.resources = resources;
            if (this.resources.length === 0) {
                if (!this.continuationToken && this.currentPartitionIndex >= this.fetchFunctions.length) {
                    this.state = DefaultQueryExecutionContext.STATES.ended;
                    return { result: undefined, headers };
                }
                else {
                    return this.current(diagnosticNode);
                }
            }
            return { result: this.resources[this.currentIndex], headers };
        }
        else {
            this.state = DefaultQueryExecutionContext.STATES.ended;
            return {
                result: undefined,
                headers: getInitialHeader(),
            };
        }
    }
    /**
     * Determine if there are still remaining resources to processs based on
     * the value of the continuation token or the elements remaining on the current batch in the execution context.
     *
     * @returns true if there is other elements to process in the DefaultQueryExecutionContext.
     */
    hasMoreResults() {
        return (this.state === DefaultQueryExecutionContext.STATES.start ||
            this.continuationToken !== undefined ||
            this.currentIndex < this.resources.length - 1 ||
            this.currentPartitionIndex < this.fetchFunctions.length);
    }
    /**
     * Fetches the next batch of the feed and pass them as an array to a callback
     */
    async fetchMore(diagnosticNode) {
        return addDignosticChild(async (childDiagnosticNode) => {
            if (this.currentPartitionIndex >= this.fetchFunctions.length) {
                return {
                    headers: getInitialHeader(),
                    result: undefined,
                };
            }
            // Keep to the original continuation and to restore the value after fetchFunction call
            const originalContinuation = this.options.continuationToken || this.options.continuation;
            this.options.continuationToken = this.continuationToken;
            // Return undefined if there is no more results
            if (this.currentPartitionIndex >= this.fetchFunctions.length) {
                return {
                    headers: getInitialHeader(),
                    result: undefined,
                };
            }
            let resources;
            let responseHeaders;
            try {
                let p;
                if (this.nextFetchFunction !== undefined) {
                    logger$3.verbose("using prefetch");
                    p = this.nextFetchFunction;
                    this.nextFetchFunction = undefined;
                }
                else {
                    logger$3.verbose("using fresh fetch");
                    p = this.fetchFunctions[this.currentPartitionIndex](childDiagnosticNode, this.options, this.correlatedActivityId);
                }
                const response = await p;
                resources = response.result;
                childDiagnosticNode.recordQueryResult(resources, exports.CosmosDbDiagnosticLevel.debugUnsafe);
                responseHeaders = response.headers;
                this.continuationToken = responseHeaders[Constants.HttpHeaders.Continuation];
                if (!this.continuationToken) {
                    ++this.currentPartitionIndex;
                }
                if (this.options && this.options.bufferItems === true) {
                    const fetchFunction = this.fetchFunctions[this.currentPartitionIndex];
                    this.nextFetchFunction = fetchFunction
                        ? fetchFunction(childDiagnosticNode, Object.assign(Object.assign({}, this.options), { continuationToken: this.continuationToken }), this.correlatedActivityId)
                        : undefined;
                }
            }
            catch (err) {
                this.state = DefaultQueryExecutionContext.STATES.ended;
                // return callback(err, undefined, responseHeaders);
                // TODO: Error and data being returned is an antipattern, this might broken
                throw err;
            }
            this.state = DefaultQueryExecutionContext.STATES.inProgress;
            this.currentIndex = 0;
            this.options.continuationToken = originalContinuation;
            this.options.continuation = originalContinuation;
            // deserializing query metrics so that we aren't working with delimited strings in the rest of the code base
            if (Constants.HttpHeaders.QueryMetrics in responseHeaders) {
                const delimitedString = responseHeaders[Constants.HttpHeaders.QueryMetrics];
                let queryMetrics = QueryMetrics.createFromDelimitedString(delimitedString);
                // Add the request charge to the query metrics so that we can have per partition request charge.
                if (Constants.HttpHeaders.RequestCharge in responseHeaders) {
                    const requestCharge = Number(responseHeaders[Constants.HttpHeaders.RequestCharge]) || 0;
                    queryMetrics = new QueryMetrics(queryMetrics.retrievedDocumentCount, queryMetrics.retrievedDocumentSize, queryMetrics.outputDocumentCount, queryMetrics.outputDocumentSize, queryMetrics.indexHitDocumentCount, queryMetrics.totalQueryExecutionTime, queryMetrics.queryPreparationTimes, queryMetrics.indexLookupTime, queryMetrics.documentLoadTime, queryMetrics.vmExecutionTime, queryMetrics.runtimeExecutionTimes, queryMetrics.documentWriteTime, new ClientSideMetrics(requestCharge));
                }
                // Wraping query metrics in a object where the key is '0' just so single partition
                // and partition queries have the same response schema
                responseHeaders[Constants.HttpHeaders.QueryMetrics] = {};
                responseHeaders[Constants.HttpHeaders.QueryMetrics]["0"] = queryMetrics;
            }
            return { result: resources, headers: responseHeaders };
        }, diagnosticNode, exports.DiagnosticNodeType.DEFAULT_QUERY_NODE, {
            queryMethodIdentifier: "fetchMore",
        });
    }
    _canFetchMore() {
        const res = this.state === DefaultQueryExecutionContext.STATES.start ||
            (this.continuationToken && this.state === DefaultQueryExecutionContext.STATES.inProgress) ||
            (this.currentPartitionIndex < this.fetchFunctions.length &&
                this.state === DefaultQueryExecutionContext.STATES.inProgress);
        return res;
    }
}
DefaultQueryExecutionContext.STATES = STATES;

/** @hidden */
class AverageAggregator {
    /**
     * Add the provided item to aggregation result.
     */
    aggregate(other) {
        if (other == null || other.sum == null) {
            return;
        }
        if (this.sum == null) {
            this.sum = 0.0;
            this.count = 0;
        }
        this.sum += other.sum;
        this.count += other.count;
    }
    /**
     * Get the aggregation result.
     */
    getResult() {
        if (this.sum == null || this.count <= 0) {
            return undefined;
        }
        return this.sum / this.count;
    }
}

/** @hidden */
class CountAggregator {
    /**
     * Represents an aggregator for COUNT operator.
     * @hidden
     */
    constructor() {
        this.value = 0;
    }
    /**
     * Add the provided item to aggregation result.
     */
    aggregate(other) {
        this.value += other;
    }
    /**
     * Get the aggregation result.
     */
    getResult() {
        return this.value;
    }
}

// TODO: this smells funny
/** @hidden */
const TYPEORDCOMPARATOR$1 = Object.freeze({
    NoValue: {
        ord: 0,
    },
    undefined: {
        ord: 1,
    },
    boolean: {
        ord: 2,
        compFunc: (a, b) => {
            return a === b ? 0 : a > b ? 1 : -1;
        },
    },
    number: {
        ord: 4,
        compFunc: (a, b) => {
            return a === b ? 0 : a > b ? 1 : -1;
        },
    },
    string: {
        ord: 5,
        compFunc: (a, b) => {
            return a === b ? 0 : a > b ? 1 : -1;
        },
    },
});
/** @hidden */
class OrderByDocumentProducerComparator {
    constructor(sortOrder) {
        this.sortOrder = sortOrder;
    } // TODO: This should be an enum
    targetPartitionKeyRangeDocProdComparator(docProd1, docProd2) {
        const a = docProd1.getTargetParitionKeyRange()["minInclusive"];
        const b = docProd2.getTargetParitionKeyRange()["minInclusive"];
        return a === b ? 0 : a > b ? 1 : -1;
    }
    compare(docProd1, docProd2) {
        // Need to check for split, since we don't want to dereference "item" of undefined / exception
        if (docProd1.gotSplit()) {
            return -1;
        }
        if (docProd2.gotSplit()) {
            return 1;
        }
        const orderByItemsRes1 = this.getOrderByItems(docProd1.peekBufferedItems()[0]);
        const orderByItemsRes2 = this.getOrderByItems(docProd2.peekBufferedItems()[0]);
        // validate order by items and types
        // TODO: once V1 order by on different types is fixed this need to change
        this.validateOrderByItems(orderByItemsRes1, orderByItemsRes2);
        // no async call in the for loop
        for (let i = 0; i < orderByItemsRes1.length; i++) {
            // compares the orderby items one by one
            const compRes = this.compareOrderByItem(orderByItemsRes1[i], orderByItemsRes2[i]);
            if (compRes !== 0) {
                if (this.sortOrder[i] === "Ascending") {
                    return compRes;
                }
                else if (this.sortOrder[i] === "Descending") {
                    return -compRes;
                }
            }
        }
        return this.targetPartitionKeyRangeDocProdComparator(docProd1, docProd2);
    }
    // TODO: This smells funny
    compareValue(item1, type1, item2, type2) {
        if (type1 === "object" || type2 === "object") {
            throw new Error("Tried to compare an object type");
        }
        const type1Ord = TYPEORDCOMPARATOR$1[type1].ord;
        const type2Ord = TYPEORDCOMPARATOR$1[type2].ord;
        const typeCmp = type1Ord - type2Ord;
        if (typeCmp !== 0) {
            // if the types are different, use type ordinal
            return typeCmp;
        }
        // both are of the same type
        if (type1Ord === TYPEORDCOMPARATOR$1["undefined"].ord ||
            type1Ord === TYPEORDCOMPARATOR$1["NoValue"].ord) {
            // if both types are undefined or Null they are equal
            return 0;
        }
        const compFunc = TYPEORDCOMPARATOR$1[type1].compFunc;
        if (typeof compFunc === "undefined") {
            throw new Error("Cannot find the comparison function");
        }
        // same type and type is defined compare the items
        return compFunc(item1, item2);
    }
    compareOrderByItem(orderByItem1, orderByItem2) {
        const type1 = this.getType(orderByItem1);
        const type2 = this.getType(orderByItem2);
        return this.compareValue(orderByItem1["item"], type1, orderByItem2["item"], type2);
    }
    validateOrderByItems(res1, res2) {
        if (res1.length !== res2.length) {
            throw new Error(`Expected ${res1.length}, but got ${res2.length}.`);
        }
        if (res1.length !== this.sortOrder.length) {
            throw new Error("orderByItems cannot have a different size than sort orders.");
        }
        for (let i = 0; i < this.sortOrder.length; i++) {
            const type1 = this.getType(res1[i]);
            const type2 = this.getType(res2[i]);
            if (type1 !== type2) {
                throw new Error(`Expected ${type1}, but got ${type2}. Cannot execute cross partition order-by queries on mixed types. Consider filtering your query using IS_STRING or IS_NUMBER to get around this exception.`);
            }
        }
    }
    getType(orderByItem) {
        // TODO: any item?
        if (orderByItem === undefined || orderByItem.item === undefined) {
            return "NoValue";
        }
        const type = typeof orderByItem.item;
        if (TYPEORDCOMPARATOR$1[type] === undefined) {
            throw new Error(`unrecognizable type ${type}`);
        }
        return type;
    }
    getOrderByItems(res) {
        // TODO: any res?
        return res["orderByItems"];
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/** @hidden */
class MaxAggregator {
    /**
     * Represents an aggregator for MAX operator.
     * @hidden
     */
    constructor() {
        this.value = undefined;
        this.comparer = new OrderByDocumentProducerComparator(["Ascending"]);
    }
    /**
     * Add the provided item to aggregation result.
     */
    aggregate(other) {
        if (this.value === undefined) {
            this.value = other.max;
        }
        else if (this.comparer.compareValue(other.max, typeof other.max, this.value, typeof this.value) > 0) {
            this.value = other.max;
        }
    }
    /**
     * Get the aggregation result.
     */
    getResult() {
        return this.value;
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/** @hidden */
class MinAggregator {
    /**
     * Represents an aggregator for MIN operator.
     * @hidden
     */
    constructor() {
        this.value = undefined;
        this.comparer = new OrderByDocumentProducerComparator(["Ascending"]);
    }
    /**
     * Add the provided item to aggregation result.
     */
    aggregate(other) {
        if (this.value === undefined) {
            // || typeof this.value === "object"
            this.value = other.min;
        }
        else {
            const otherType = other.min === null ? "NoValue" : typeof other.min; // || typeof other === "object"
            const thisType = this.value === null ? "NoValue" : typeof this.value;
            if (this.comparer.compareValue(other.min, otherType, this.value, thisType) < 0) {
                this.value = other.min;
            }
        }
    }
    /**
     * Get the aggregation result.
     */
    getResult() {
        return this.value;
    }
}

/** @hidden */
class SumAggregator {
    /**
     * Add the provided item to aggregation result.
     */
    aggregate(other) {
        if (other === undefined) {
            return;
        }
        if (this.sum === undefined) {
            this.sum = other;
        }
        else {
            this.sum += other;
        }
    }
    /**
     * Get the aggregation result.
     */
    getResult() {
        return this.sum;
    }
}

/** @hidden */
class StaticValueAggregator {
    aggregate(other) {
        if (this.value === undefined) {
            this.value = other;
        }
    }
    getResult() {
        return this.value;
    }
}

/** @hidden */
class MakeListAggregator {
    constructor() {
        this.value = [];
    }
    aggregate(other) {
        if (Array.isArray(other)) {
            this.value.push(...other);
        }
    }
    getResult() {
        const result = [...this.value];
        return result;
    }
}

/** @hidden */
/**
 * Represents an aggregator that collects unique values into a set.
 */
class MakeSetAggregator {
    constructor() {
        this.value = new Set();
    }
    /**
     * Aggregates the values from another set into the current set.
     * @param other - The set to aggregate.
     */
    aggregate(other) {
        other.forEach((item) => {
            this.value.add(item);
        });
    }
    /**
     * Gets the result of the MakeSetAggregator.
     * @returns A Set containing the unique values collected by the aggregator.
     */
    getResult() {
        return Array.from(this.value);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
function createAggregator(aggregateType) {
    switch (aggregateType) {
        case "Average":
            return new AverageAggregator();
        case "Count":
            return new CountAggregator();
        case "Max":
            return new MaxAggregator();
        case "Min":
            return new MinAggregator();
        case "Sum":
            return new SumAggregator();
        case "MakeList":
            return new MakeListAggregator();
        case "MakeSet":
            return new MakeSetAggregator();
        default:
            return new StaticValueAggregator();
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/** @hidden */
var FetchResultType;
(function (FetchResultType) {
    FetchResultType[FetchResultType["Done"] = 0] = "Done";
    FetchResultType[FetchResultType["Exception"] = 1] = "Exception";
    FetchResultType[FetchResultType["Result"] = 2] = "Result";
})(FetchResultType || (FetchResultType = {}));
/** @hidden */
class FetchResult {
    /**
     * Wraps fetch results for the document producer.
     * This allows the document producer to buffer exceptions so that actual results don't get flushed during splits.
     *
     * @param feedReponse - The response the document producer got back on a successful fetch
     * @param error - The exception meant to be buffered on an unsuccessful fetch
     * @hidden
     */
    constructor(feedResponse, error, headers) {
        // TODO: feedResponse/error
        if (feedResponse !== undefined) {
            this.feedResponse = feedResponse;
            this.headers = headers;
            this.fetchResultType = FetchResultType.Result;
        }
        else {
            this.error = error;
            this.fetchResultType = FetchResultType.Exception;
        }
    }
}

/** @hidden */
class DocumentProducer {
    /**
     * Provides the Target Partition Range Query Execution Context.
     * @param clientContext  - The service endpoint to use to create the client.
     * @param collectionLink - Represents collection link
     * @param query          - A SQL query.
     * @param targetPartitionKeyRange - Query Target Partition key Range
     * @hidden
     */
    constructor(clientContext, collectionLink, query, targetPartitionKeyRange, options, correlatedActivityId, startEpk, endEpk, populateEpkRangeHeaders = false) {
        this.clientContext = clientContext;
        this.generation = 0;
        this.fetchFunction = async (diagnosticNode, options, correlatedActivityId) => {
            const path = getPathFromLink(this.collectionLink, exports.ResourceType.item);
            diagnosticNode.addData({ partitionKeyRangeId: this.targetPartitionKeyRange.id });
            const id = getIdFromLink(this.collectionLink);
            const startEpk = this.populateEpkRangeHeaders ? this.startEpk : undefined;
            const endEpk = this.populateEpkRangeHeaders ? this.endEpk : undefined;
            return this.clientContext.queryFeed({
                path,
                resourceType: exports.ResourceType.item,
                resourceId: id,
                resultFn: (result) => result.Documents,
                query: this.query,
                options,
                diagnosticNode,
                partitionKeyRangeId: this.targetPartitionKeyRange["id"],
                correlatedActivityId: correlatedActivityId,
                startEpk: startEpk,
                endEpk: endEpk,
            });
        };
        // TODO: any options
        this.collectionLink = collectionLink;
        this.query = query;
        this.targetPartitionKeyRange = targetPartitionKeyRange;
        this.fetchResults = [];
        this.allFetched = false;
        this.err = undefined;
        this.previousContinuationToken = undefined;
        this.continuationToken = undefined;
        this.respHeaders = getInitialHeader();
        this.internalExecutionContext = new DefaultQueryExecutionContext(options, this.fetchFunction, correlatedActivityId);
        this.startEpk = startEpk;
        this.endEpk = endEpk;
        this.populateEpkRangeHeaders = populateEpkRangeHeaders;
    }
    peekBufferedItems() {
        const bufferedResults = [];
        for (let i = 0, done = false; i < this.fetchResults.length && !done; i++) {
            const fetchResult = this.fetchResults[i];
            switch (fetchResult.fetchResultType) {
                case FetchResultType.Done:
                    done = true;
                    break;
                case FetchResultType.Exception:
                    done = true;
                    break;
                case FetchResultType.Result:
                    bufferedResults.push(fetchResult.feedResponse);
                    break;
            }
        }
        return bufferedResults;
    }
    hasMoreResults() {
        return this.internalExecutionContext.hasMoreResults() || this.fetchResults.length !== 0;
    }
    gotSplit() {
        if (this.fetchResults.length !== 0) {
            const fetchResult = this.fetchResults[0];
            if (fetchResult.fetchResultType === FetchResultType.Exception) {
                if (DocumentProducer._needPartitionKeyRangeCacheRefresh(fetchResult.error)) {
                    return true;
                }
            }
        }
        return false;
    }
    _getAndResetActiveResponseHeaders() {
        const ret = this.respHeaders;
        this.respHeaders = getInitialHeader();
        return ret;
    }
    _updateStates(err, allFetched) {
        if (err) {
            this.err = err;
            return;
        }
        if (allFetched) {
            this.allFetched = true;
        }
        if (this.internalExecutionContext.continuationToken === this.continuationToken) {
            // nothing changed
            return;
        }
        this.previousContinuationToken = this.continuationToken;
        this.continuationToken = this.internalExecutionContext.continuationToken;
    }
    static _needPartitionKeyRangeCacheRefresh(error) {
        // TODO: error
        return (error.code === StatusCodes.Gone &&
            "substatus" in error &&
            error["substatus"] === SubStatusCodes.PartitionKeyRangeGone);
    }
    /**
     * Fetches and bufferes the next page of results in internal buffer
     */
    async bufferMore(diagnosticNode) {
        if (this.err) {
            throw this.err;
        }
        try {
            const { result: resources, headers: headerResponse } = await this.internalExecutionContext.fetchMore(diagnosticNode);
            ++this.generation;
            this._updateStates(undefined, resources === undefined);
            if (resources !== undefined) {
                // add fetched header to the 1st element in the buffer
                let addHeaderToFetchResult = true;
                resources.forEach((element) => {
                    this.fetchResults.push(new FetchResult(element, undefined, addHeaderToFetchResult ? headerResponse : getInitialHeader()));
                    addHeaderToFetchResult = false;
                });
            }
            // need to modify the header response so that the query metrics are per partition
            if (headerResponse != null && Constants.HttpHeaders.QueryMetrics in headerResponse) {
                // "0" is the default partition before one is actually assigned.
                const queryMetrics = headerResponse[Constants.HttpHeaders.QueryMetrics]["0"];
                // Wraping query metrics in a object where the keys are the partition key range.
                headerResponse[Constants.HttpHeaders.QueryMetrics] = {};
                headerResponse[Constants.HttpHeaders.QueryMetrics][this.targetPartitionKeyRange.id] =
                    queryMetrics;
            }
            mergeHeaders(this.respHeaders, headerResponse);
        }
        catch (err) {
            if (DocumentProducer._needPartitionKeyRangeCacheRefresh(err)) {
                // Split just happend
                // Buffer the error so the execution context can still get the feedResponses in the itemBuffer
                const bufferedError = new FetchResult(undefined, err);
                this.fetchResults.push(bufferedError);
                mergeHeaders(this.respHeaders, err.headers);
            }
            else {
                this._updateStates(err, err.resources === undefined);
                throw err;
            }
        }
    }
    getTargetParitionKeyRange() {
        return this.targetPartitionKeyRange;
    }
    /**
     * Peak the next item in the buffer
     */
    peakNextItem() {
        if (this.err) {
            throw this.err;
        }
        if (this.allFetched || this.fetchResults.length === 0) {
            return undefined;
        }
        const fetchResult = this.fetchResults[0];
        switch (fetchResult.fetchResultType) {
            case FetchResultType.Done:
                return undefined;
            case FetchResultType.Exception: // do not throw this error
                return undefined;
            case FetchResultType.Result:
                return fetchResult.feedResponse;
        }
    }
    /**
     * Returns the first item in the buffered results if any, or [] otherwise.
     */
    async fetchNextItem() {
        if (this.err) {
            this._updateStates(this.err, undefined);
            throw this.err;
        }
        if (this.allFetched) {
            return { result: undefined, headers: this._getAndResetActiveResponseHeaders() };
        }
        try {
            const { result, headers } = this.current();
            this._updateStates(undefined, result === undefined);
            if (result === undefined || result.length === 0) {
                return { result: undefined, headers };
            }
            return { result, headers }; //
        }
        catch (err) {
            this._updateStates(err, err.item === undefined);
            throw err;
        }
    }
    /**
     * Fetches all the buffered results
     */
    async fetchBufferedItems() {
        if (this.err) {
            this._updateStates(this.err, undefined);
            throw this.err;
        }
        if (this.allFetched) {
            return { result: undefined, headers: this._getAndResetActiveResponseHeaders() };
        }
        const resources = [];
        const resHeaders = getInitialHeader();
        try {
            while (this.fetchResults.length > 0) {
                const { result, headers } = this.current();
                this._updateStates(undefined, result === undefined);
                mergeHeaders(resHeaders, headers);
                if (result === undefined) {
                    return { result: resources.length > 0 ? resources : undefined, headers: resHeaders };
                }
                else {
                    resources.push(result);
                }
            }
            return { result: resources, headers: resHeaders };
        }
        catch (err) {
            this._updateStates(err, err.item === undefined);
            throw err;
        }
    }
    /**
     * Retrieve the current element on the DocumentProducer.
     */
    current() {
        // If something is buffered just give that
        if (this.fetchResults.length > 0) {
            const fetchResult = this.fetchResults.shift();
            // Need to unwrap fetch results
            switch (fetchResult.fetchResultType) {
                case FetchResultType.Done:
                    return {
                        result: undefined,
                        headers: this._getAndResetActiveResponseHeaders(),
                    };
                case FetchResultType.Exception:
                    fetchResult.error.headers = this._getAndResetActiveResponseHeaders();
                    throw fetchResult.error;
                case FetchResultType.Result:
                    return {
                        result: fetchResult.feedResponse,
                        headers: this._getAndResetActiveResponseHeaders(),
                    };
            }
        }
        // If there isn't anymore items left to fetch then let the user know.
        if (this.allFetched) {
            return {
                result: undefined,
                headers: this._getAndResetActiveResponseHeaders(),
            };
        }
        // If the internal buffer is empty, return empty result
        return { result: [], headers: this._getAndResetActiveResponseHeaders() };
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/** @hidden */
const logger$2 = logger$5.createClientLogger("parallelQueryExecutionContextBase");
/** @hidden */
var ParallelQueryExecutionContextBaseStates;
(function (ParallelQueryExecutionContextBaseStates) {
    ParallelQueryExecutionContextBaseStates["started"] = "started";
    ParallelQueryExecutionContextBaseStates["inProgress"] = "inProgress";
    ParallelQueryExecutionContextBaseStates["ended"] = "ended";
})(ParallelQueryExecutionContextBaseStates || (ParallelQueryExecutionContextBaseStates = {}));
/** @hidden */
class ParallelQueryExecutionContextBase {
    /**
     * Provides the ParallelQueryExecutionContextBase.
     * This is the base class that ParallelQueryExecutionContext and OrderByQueryExecutionContext will derive from.
     *
     * When handling a parallelized query, it instantiates one instance of
     * DocumentProcuder per target partition key range and aggregates the result of each.
     *
     * @param clientContext - The service endpoint to use to create the client.
     * @param collectionLink - The Collection Link
     * @param options - Represents the feed options.
     * @param partitionedQueryExecutionInfo - PartitionedQueryExecutionInfo
     * @hidden
     */
    constructor(clientContext, collectionLink, query, options, partitionedQueryExecutionInfo, correlatedActivityId) {
        this.clientContext = clientContext;
        this.collectionLink = collectionLink;
        this.query = query;
        this.options = options;
        this.partitionedQueryExecutionInfo = partitionedQueryExecutionInfo;
        this.correlatedActivityId = correlatedActivityId;
        this.clientContext = clientContext;
        this.collectionLink = collectionLink;
        this.query = query;
        this.options = options;
        this.partitionedQueryExecutionInfo = partitionedQueryExecutionInfo;
        this.correlatedActivityId = correlatedActivityId;
        this.diagnosticNodeWrapper = {
            consumed: false,
            diagnosticNode: new DiagnosticNodeInternal(clientContext.diagnosticLevel, exports.DiagnosticNodeType.PARALLEL_QUERY_NODE, null),
        };
        this.diagnosticNodeWrapper.diagnosticNode.addData({ stateful: true });
        this.err = undefined;
        this.state = ParallelQueryExecutionContextBase.STATES.started;
        this.routingProvider = new SmartRoutingMapProvider(this.clientContext);
        this.sortOrders = this.partitionedQueryExecutionInfo.queryInfo.orderBy;
        this.buffer = [];
        this.requestContinuation = options ? options.continuationToken || options.continuation : null;
        // response headers of undergoing operation
        this.respHeaders = getInitialHeader();
        // Make priority queue for documentProducers
        this.unfilledDocumentProducersQueue = new PriorityQueue((a, b) => a.generation - b.generation);
        // The comparator is supplied by the derived class
        this.bufferedDocumentProducersQueue = new PriorityQueue((a, b) => this.documentProducerComparator(b, a));
        // Creating the documentProducers
        this.sem = semaphore(1);
        const createDocumentProducersAndFillUpPriorityQueueFunc = async () => {
            // ensure the lock is released after finishing up
            try {
                const targetPartitionRanges = await this._onTargetPartitionRanges();
                const maxDegreeOfParallelism = options.maxDegreeOfParallelism === undefined || options.maxDegreeOfParallelism < 1
                    ? targetPartitionRanges.length
                    : Math.min(options.maxDegreeOfParallelism, targetPartitionRanges.length);
                logger$2.info("Query starting against " +
                    targetPartitionRanges.length +
                    " ranges with parallelism of " +
                    maxDegreeOfParallelism);
                let filteredPartitionKeyRanges = [];
                // The document producers generated from filteredPartitionKeyRanges
                const targetPartitionQueryExecutionContextList = [];
                if (this.requestContinuation) {
                    throw new Error("Continuation tokens are not yet supported for cross partition queries");
                }
                else {
                    filteredPartitionKeyRanges = targetPartitionRanges;
                }
                // Create one documentProducer for each partitionTargetRange
                filteredPartitionKeyRanges.forEach((partitionTargetRange) => {
                    // TODO: any partitionTargetRange
                    // no async callback
                    targetPartitionQueryExecutionContextList.push(this._createTargetPartitionQueryExecutionContext(partitionTargetRange, undefined));
                });
                // Fill up our priority queue with documentProducers
                targetPartitionQueryExecutionContextList.forEach((documentProducer) => {
                    // has async callback
                    try {
                        this.unfilledDocumentProducersQueue.enq(documentProducer);
                    }
                    catch (e) {
                        this.err = e;
                    }
                });
                this.sem.leave();
            }
            catch (err) {
                this.err = err;
                // release the lock
                this.sem.leave();
                return;
            }
        };
        this.sem.take(createDocumentProducersAndFillUpPriorityQueueFunc);
    }
    _mergeWithActiveResponseHeaders(headers) {
        mergeHeaders(this.respHeaders, headers);
    }
    _getAndResetActiveResponseHeaders() {
        const ret = this.respHeaders;
        this.respHeaders = getInitialHeader();
        return ret;
    }
    getDiagnosticNode() {
        return this.diagnosticNodeWrapper.diagnosticNode;
    }
    async _onTargetPartitionRanges() {
        // invokes the callback when the target partition ranges are ready
        const parsedRanges = this.partitionedQueryExecutionInfo.queryRanges;
        const queryRanges = parsedRanges.map((item) => QueryRange.parseFromDict(item));
        return this.routingProvider.getOverlappingRanges(this.collectionLink, queryRanges, this.getDiagnosticNode());
    }
    /**
     * Gets the replacement ranges for a partitionkeyrange that has been split
     */
    async _getReplacementPartitionKeyRanges(documentProducer, diagnosticNode) {
        const partitionKeyRange = documentProducer.targetPartitionKeyRange;
        // Download the new routing map
        this.routingProvider = new SmartRoutingMapProvider(this.clientContext);
        // Get the queryRange that relates to this partitionKeyRange
        const queryRange = QueryRange.parsePartitionKeyRange(partitionKeyRange);
        return this.routingProvider.getOverlappingRanges(this.collectionLink, [queryRange], diagnosticNode);
    }
    async _enqueueReplacementDocumentProducers(error, diagnosticNode, documentProducer) {
        // Get the replacement ranges
        const replacementPartitionKeyRanges = await this._getReplacementPartitionKeyRanges(documentProducer, diagnosticNode);
        if (replacementPartitionKeyRanges.length === 0) {
            throw error;
        }
        else if (replacementPartitionKeyRanges.length === 1) {
            // Partition is gone due to Merge
            // Create the replacement documentProducer with populateEpkRangeHeaders Flag set to true to set startEpk and endEpk headers
            const replacementDocumentProducer = this._createTargetPartitionQueryExecutionContext(replacementPartitionKeyRanges[0], documentProducer.continuationToken, documentProducer.startEpk, documentProducer.endEpk, true);
            this.unfilledDocumentProducersQueue.enq(replacementDocumentProducer);
        }
        else {
            // Create the replacement documentProducers
            const replacementDocumentProducers = [];
            replacementPartitionKeyRanges.forEach((partitionKeyRange) => {
                const queryRange = QueryRange.parsePartitionKeyRange(partitionKeyRange);
                // Create replacment document producers with the parent's continuationToken
                const replacementDocumentProducer = this._createTargetPartitionQueryExecutionContext(partitionKeyRange, documentProducer.continuationToken, queryRange.min, queryRange.max, false);
                replacementDocumentProducers.push(replacementDocumentProducer);
            });
            // add document producers to the queue
            replacementDocumentProducers.forEach((replacementDocumentProducer) => {
                if (replacementDocumentProducer.hasMoreResults()) {
                    this.unfilledDocumentProducersQueue.enq(replacementDocumentProducer);
                }
            });
        }
    }
    static _needPartitionKeyRangeCacheRefresh(error) {
        // TODO: any error
        return (error.code === StatusCodes.Gone &&
            "substatus" in error &&
            error["substatus"] === SubStatusCodes.PartitionKeyRangeGone);
    }
    /**
     * Determine if there are still remaining resources to processs based on the value of the continuation
     * token or the elements remaining on the current batch in the QueryIterator.
     * @returns true if there is other elements to process in the ParallelQueryExecutionContextBase.
     */
    hasMoreResults() {
        return (!this.err &&
            (this.buffer.length > 0 || this.state !== ParallelQueryExecutionContextBase.STATES.ended));
    }
    /**
     * Creates target partition range Query Execution Context
     */
    _createTargetPartitionQueryExecutionContext(partitionKeyTargetRange, continuationToken, startEpk, endEpk, populateEpkRangeHeaders) {
        let rewrittenQuery = this.partitionedQueryExecutionInfo.queryInfo.rewrittenQuery;
        let sqlQuerySpec;
        const query = this.query;
        if (typeof query === "string") {
            sqlQuerySpec = { query };
        }
        else {
            sqlQuerySpec = query;
        }
        const formatPlaceHolder = "{documentdb-formattableorderbyquery-filter}";
        if (rewrittenQuery) {
            sqlQuerySpec = JSON.parse(JSON.stringify(sqlQuerySpec));
            // We hardcode the formattable filter to true for now
            rewrittenQuery = rewrittenQuery.replace(formatPlaceHolder, "true");
            sqlQuerySpec["query"] = rewrittenQuery;
        }
        const options = Object.assign({}, this.options);
        options.continuationToken = continuationToken;
        return new DocumentProducer(this.clientContext, this.collectionLink, sqlQuerySpec, partitionKeyTargetRange, options, this.correlatedActivityId, startEpk, endEpk, populateEpkRangeHeaders);
    }
    async drainBufferedItems() {
        return new Promise((resolve, reject) => {
            this.sem.take(() => {
                if (this.err) {
                    // if there is a prior error return error
                    this.sem.leave();
                    this.err.headers = this._getAndResetActiveResponseHeaders();
                    reject(this.err);
                    return;
                }
                // return undefined if there is no more results
                if (this.buffer.length === 0) {
                    this.sem.leave();
                    return resolve({
                        result: this.state === ParallelQueryExecutionContextBase.STATES.ended ? undefined : [],
                        headers: this._getAndResetActiveResponseHeaders(),
                    });
                }
                // draing the entire buffer object and return that in result of return object
                const bufferedResults = this.buffer;
                this.buffer = [];
                // release the lock before returning
                this.sem.leave();
                // invoke the callback on the item
                return resolve({
                    result: bufferedResults,
                    headers: this._getAndResetActiveResponseHeaders(),
                });
            });
        });
    }
    /**
     * Buffers document producers based on the maximum degree of parallelism.
     * Moves document producers from the unfilled queue to the buffered queue.
     * @param diagnosticNode - The diagnostic node for logging and tracing.
     * @returns A promise that resolves when buffering is complete.
     */
    async bufferDocumentProducers(diagnosticNode) {
        return new Promise((resolve, reject) => {
            this.sem.take(async () => {
                if (this.err) {
                    this.sem.leave();
                    reject(this.err);
                    return;
                }
                this.updateStates(this.err);
                if (this.state === ParallelQueryExecutionContextBase.STATES.ended) {
                    this.sem.leave();
                    resolve();
                    return;
                }
                if (this.unfilledDocumentProducersQueue.size() === 0) {
                    this.sem.leave();
                    resolve();
                    return;
                }
                try {
                    const maxDegreeOfParallelism = this.options.maxDegreeOfParallelism === undefined ||
                        this.options.maxDegreeOfParallelism < 1
                        ? this.unfilledDocumentProducersQueue.size()
                        : Math.min(this.options.maxDegreeOfParallelism, this.unfilledDocumentProducersQueue.size());
                    const documentProducers = [];
                    while (documentProducers.length < maxDegreeOfParallelism &&
                        this.unfilledDocumentProducersQueue.size() > 0) {
                        let documentProducer;
                        try {
                            documentProducer = this.unfilledDocumentProducersQueue.deq();
                        }
                        catch (e) {
                            this.err = e;
                            this.err.headers = this._getAndResetActiveResponseHeaders();
                            reject(this.err);
                            return;
                        }
                        documentProducers.push(documentProducer);
                    }
                    const bufferDocumentProducer = async (documentProducer) => {
                        try {
                            await documentProducer.bufferMore(diagnosticNode);
                            // if buffer of document producer is filled, add it to the buffered document producers queue
                            const nextItem = documentProducer.peakNextItem();
                            if (nextItem !== undefined) {
                                this.bufferedDocumentProducersQueue.enq(documentProducer);
                            }
                            else if (documentProducer.hasMoreResults()) {
                                this.unfilledDocumentProducersQueue.enq(documentProducer);
                            }
                        }
                        catch (err) {
                            if (ParallelQueryExecutionContextBase._needPartitionKeyRangeCacheRefresh(err)) {
                                // We want the document producer enqueued
                                // So that later parts of the code can repair the execution context
                                // refresh the partition key ranges and ctreate new document producers and add it to the queue
                                await this._enqueueReplacementDocumentProducers(err, diagnosticNode, documentProducer);
                                resolve();
                            }
                            else {
                                this.err = err;
                                this.err.headers = this._getAndResetActiveResponseHeaders();
                                reject(err);
                            }
                        }
                    };
                    try {
                        await Promise.all(documentProducers.map((producer) => bufferDocumentProducer(producer)));
                    }
                    catch (err) {
                        this.err = err;
                        this.err.headers = this._getAndResetActiveResponseHeaders();
                        reject(err);
                        return;
                    }
                    resolve();
                }
                catch (err) {
                    this.err = err;
                    this.err.headers = this._getAndResetActiveResponseHeaders();
                    reject(err);
                }
                finally {
                    this.sem.leave();
                }
            });
        });
    }
    /**
     * Drains the buffer of filled document producers and appends their items to the main buffer.
     * @param isOrderBy - Indicates if the query is an order by query.
     * @returns A promise that resolves when the buffer is filled.
     */
    async fillBufferFromBufferQueue(isOrderBy = false) {
        return new Promise((resolve, reject) => {
            this.sem.take(async () => {
                if (this.err) {
                    // if there is a prior error return error
                    this.sem.leave();
                    this.err.headers = this._getAndResetActiveResponseHeaders();
                    reject(this.err);
                    return;
                }
                if (this.state === ParallelQueryExecutionContextBase.STATES.ended ||
                    this.bufferedDocumentProducersQueue.size() === 0) {
                    this.sem.leave();
                    resolve();
                    return;
                }
                try {
                    if (isOrderBy) {
                        while (this.unfilledDocumentProducersQueue.isEmpty() &&
                            this.bufferedDocumentProducersQueue.size() > 0) {
                            const documentProducer = this.bufferedDocumentProducersQueue.deq();
                            const { result, headers } = await documentProducer.fetchNextItem();
                            this._mergeWithActiveResponseHeaders(headers);
                            if (result) {
                                this.buffer.push(result);
                            }
                            if (documentProducer.peakNextItem() !== undefined) {
                                this.bufferedDocumentProducersQueue.enq(documentProducer);
                            }
                            else if (documentProducer.hasMoreResults()) {
                                this.unfilledDocumentProducersQueue.enq(documentProducer);
                            }
                            else {
                                // no more results in document producer
                            }
                        }
                    }
                    else {
                        while (this.bufferedDocumentProducersQueue.size() > 0) {
                            const documentProducer = this.bufferedDocumentProducersQueue.deq();
                            const { result, headers } = await documentProducer.fetchBufferedItems();
                            this._mergeWithActiveResponseHeaders(headers);
                            if (result) {
                                this.buffer.push(...result);
                            }
                            if (documentProducer.hasMoreResults()) {
                                this.unfilledDocumentProducersQueue.enq(documentProducer);
                            }
                        }
                    }
                    this.updateStates(this.err);
                }
                catch (err) {
                    this.err = err;
                    this.err.headers = this._getAndResetActiveResponseHeaders();
                    reject(this.err);
                    return;
                }
                finally {
                    // release the lock before returning
                    this.sem.leave();
                }
                resolve();
                return;
            });
        });
    }
    updateStates(error) {
        if (error) {
            this.err = error;
            this.state = ParallelQueryExecutionContextBase.STATES.ended;
            return;
        }
        if (this.state === ParallelQueryExecutionContextBase.STATES.started) {
            this.state = ParallelQueryExecutionContextBase.STATES.inProgress;
        }
        const hasNoActiveProducers = this.unfilledDocumentProducersQueue.size() === 0 &&
            this.bufferedDocumentProducersQueue.size() === 0;
        if (hasNoActiveProducers) {
            this.state = ParallelQueryExecutionContextBase.STATES.ended;
        }
    }
}
ParallelQueryExecutionContextBase.STATES = ParallelQueryExecutionContextBaseStates;

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Provides the ParallelQueryExecutionContext.
 * This class is capable of handling parallelized queries and derives from ParallelQueryExecutionContextBase.
 * @hidden
 */
class ParallelQueryExecutionContext extends ParallelQueryExecutionContextBase {
    // Instance members are inherited
    // Overriding documentProducerComparator for ParallelQueryExecutionContexts
    /**
     * Provides a Comparator for document producers using the min value of the corresponding target partition.
     * @returns Comparator Function
     * @hidden
     */
    documentProducerComparator(docProd1, docProd2) {
        return docProd1.generation - docProd2.generation;
    }
    /**
     * Fetches more results from the query execution context.
     * @param diagnosticNode - Optional diagnostic node for tracing.
     * @returns A promise that resolves to the fetched results.
     * @hidden
     */
    async fetchMore(diagnosticNode) {
        try {
            // Buffer document producers and fill buffer from the queue
            await this.bufferDocumentProducers(diagnosticNode);
            await this.fillBufferFromBufferQueue();
            // Drain buffered items
            return this.drainBufferedItems();
        }
        catch (error) {
            // Handle any errors that occur during fetching
            console.error("Error fetching more documents:", error);
            throw error;
        }
    }
}

/** @hidden */
class OrderByQueryExecutionContext extends ParallelQueryExecutionContextBase {
    /**
     * Provides the OrderByQueryExecutionContext.
     * This class is capable of handling orderby queries and dervives from ParallelQueryExecutionContextBase.
     *
     * When handling a parallelized query, it instantiates one instance of
     * DocumentProcuder per target partition key range and aggregates the result of each.
     *
     * @param clientContext - The service endpoint to use to create the client.
     * @param collectionLink - The Collection Link
     * @param options - Represents the feed options.
     * @param partitionedQueryExecutionInfo - PartitionedQueryExecutionInfo
     * @hidden
     */
    constructor(clientContext, collectionLink, query, options, partitionedQueryExecutionInfo, correlatedActivityId) {
        // Calling on base class constructor
        super(clientContext, collectionLink, query, options, partitionedQueryExecutionInfo, correlatedActivityId);
        this.orderByComparator = new OrderByDocumentProducerComparator(this.sortOrders);
    }
    // Instance members are inherited
    // Overriding documentProducerComparator for OrderByQueryExecutionContexts
    /**
     * Provides a Comparator for document producers which respects orderby sort order.
     * @returns Comparator Function
     * @hidden
     */
    documentProducerComparator(docProd1, docProd2) {
        return this.orderByComparator.compare(docProd1, docProd2);
    }
    /**
     * Fetches more results from the query execution context.
     * @param diagnosticNode - Optional diagnostic node for tracing.
     * @returns A promise that resolves to the fetched results.
     * @hidden
     */
    async fetchMore(diagnosticNode) {
        try {
            await this.bufferDocumentProducers(diagnosticNode);
            await this.fillBufferFromBufferQueue(true);
            return this.drainBufferedItems();
        }
        catch (error) {
            console.error("Error fetching more results:", error);
            throw error;
        }
    }
}

/** @hidden */
class OffsetLimitEndpointComponent {
    constructor(executionContext, offset, limit) {
        this.executionContext = executionContext;
        this.offset = offset;
        this.limit = limit;
    }
    hasMoreResults() {
        return (this.offset > 0 || this.limit > 0) && this.executionContext.hasMoreResults();
    }
    async fetchMore(diagnosticNode) {
        const aggregateHeaders = getInitialHeader();
        const buffer = [];
        const response = await this.executionContext.fetchMore(diagnosticNode);
        mergeHeaders(aggregateHeaders, response.headers);
        if (response === undefined || response.result === undefined) {
            return { result: undefined, headers: response.headers };
        }
        for (const item of response.result) {
            if (this.offset > 0) {
                this.offset--;
            }
            else if (this.limit > 0) {
                buffer.push(item);
                this.limit--;
            }
        }
        return { result: buffer, headers: aggregateHeaders };
    }
}

/** @hidden */
class OrderByEndpointComponent {
    /**
     * Represents an endpoint in handling an order by query. For each processed orderby
     * result it returns 'payload' item of the result
     *
     * @param executionContext - Underlying Execution Context
     * @hidden
     */
    constructor(executionContext, emitRawOrderByPayload = false) {
        this.executionContext = executionContext;
        this.emitRawOrderByPayload = emitRawOrderByPayload;
    }
    /**
     * Determine if there are still remaining resources to processs.
     * @returns true if there is other elements to process in the OrderByEndpointComponent.
     */
    hasMoreResults() {
        return this.executionContext.hasMoreResults();
    }
    async fetchMore(diagnosticNode) {
        const buffer = [];
        const response = await this.executionContext.fetchMore(diagnosticNode);
        if (response === undefined || response.result === undefined) {
            return { result: undefined, headers: response.headers };
        }
        for (const item of response.result) {
            if (this.emitRawOrderByPayload) {
                buffer.push(item);
            }
            else {
                buffer.push(item.payload);
            }
        }
        return { result: buffer, headers: response.headers };
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
async function digest(str) {
    const hash = crypto.createHash("sha256");
    hash.update(str, "utf8");
    return hash.digest("hex");
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
async function hashObject(object) {
    const stringifiedObject = stableStringify(object);
    return digest(stringifiedObject);
}

/** @hidden */
class OrderedDistinctEndpointComponent {
    constructor(executionContext) {
        this.executionContext = executionContext;
    }
    hasMoreResults() {
        return this.executionContext.hasMoreResults();
    }
    async fetchMore(diagnosticNode) {
        const buffer = [];
        const response = await this.executionContext.fetchMore(diagnosticNode);
        if (response === undefined || response.result === undefined) {
            return { result: undefined, headers: response.headers };
        }
        for (const item of response.result) {
            if (item) {
                const hashedResult = await hashObject(item);
                if (hashedResult !== this.hashedLastResult) {
                    buffer.push(item);
                    this.hashedLastResult = hashedResult;
                }
            }
        }
        return { result: buffer, headers: response.headers };
    }
}

/** @hidden */
class UnorderedDistinctEndpointComponent {
    constructor(executionContext) {
        this.executionContext = executionContext;
        this.hashedResults = new Set();
    }
    hasMoreResults() {
        return this.executionContext.hasMoreResults();
    }
    async fetchMore(diagnosticNode) {
        const buffer = [];
        const response = await this.executionContext.fetchMore(diagnosticNode);
        if (response === undefined || response.result === undefined) {
            return { result: undefined, headers: response.headers };
        }
        for (const item of response.result) {
            if (item) {
                const hashedResult = await hashObject(item);
                if (!this.hashedResults.has(hashedResult)) {
                    buffer.push(item);
                    this.hashedResults.add(hashedResult);
                }
            }
        }
        return { result: buffer, headers: response.headers };
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
// All aggregates are effectively a group by operation
// The empty group is used for aggregates without a GROUP BY clause
const emptyGroup = "__empty__";
// Newer API versions rewrite the query to return `item2`. It fixes some legacy issues with the original `item` result
// Aggregator code should use item2 when available
const extractAggregateResult = (payload) => Object.keys(payload).length > 0 ? (payload.item2 ? payload.item2 : payload.item) : null;

/** @hidden */
class GroupByEndpointComponent {
    constructor(executionContext, queryInfo) {
        this.executionContext = executionContext;
        this.queryInfo = queryInfo;
        this.groupings = new Map();
        this.aggregateResultArray = [];
        this.completed = false;
    }
    hasMoreResults() {
        return this.executionContext.hasMoreResults();
    }
    async fetchMore(diagnosticNode) {
        if (this.completed) {
            return {
                result: undefined,
                headers: getInitialHeader(),
            };
        }
        const aggregateHeaders = getInitialHeader();
        const response = await this.executionContext.fetchMore(diagnosticNode);
        mergeHeaders(aggregateHeaders, response.headers);
        if (response === undefined || response.result === undefined) {
            // If there are any groupings, consolidate and return them
            if (this.groupings.size > 0) {
                return this.consolidateGroupResults(aggregateHeaders);
            }
            return { result: undefined, headers: aggregateHeaders };
        }
        for (const item of response.result) {
            // If it exists, process it via aggregators
            if (item) {
                const group = item.groupByItems ? await hashObject(item.groupByItems) : emptyGroup;
                const aggregators = this.groupings.get(group);
                const payload = item.payload;
                if (aggregators) {
                    // Iterator over all results in the payload
                    for (const key of Object.keys(payload)) {
                        // in case the value of a group is null make sure we create a dummy payload with item2==null
                        const effectiveGroupByValue = payload[key]
                            ? payload[key]
                            : new Map().set("item2", null);
                        const aggregateResult = extractAggregateResult(effectiveGroupByValue);
                        aggregators.get(key).aggregate(aggregateResult);
                    }
                }
                else {
                    // This is the first time we have seen a grouping. Setup the initial result without aggregate values
                    const grouping = new Map();
                    this.groupings.set(group, grouping);
                    // Iterator over all results in the payload
                    for (const key of Object.keys(payload)) {
                        const aggregateType = this.queryInfo.groupByAliasToAggregateType[key];
                        // Create a new aggregator for this specific aggregate field
                        const aggregator = createAggregator(aggregateType);
                        grouping.set(key, aggregator);
                        if (aggregateType) {
                            const aggregateResult = extractAggregateResult(payload[key]);
                            aggregator.aggregate(aggregateResult);
                        }
                        else {
                            aggregator.aggregate(payload[key]);
                        }
                    }
                }
            }
        }
        if (this.executionContext.hasMoreResults()) {
            return {
                result: [],
                headers: aggregateHeaders,
            };
        }
        else {
            return this.consolidateGroupResults(aggregateHeaders);
        }
    }
    consolidateGroupResults(aggregateHeaders) {
        for (const grouping of this.groupings.values()) {
            const groupResult = {};
            for (const [aggregateKey, aggregator] of grouping.entries()) {
                groupResult[aggregateKey] = aggregator.getResult();
            }
            this.aggregateResultArray.push(groupResult);
        }
        this.completed = true;
        return { result: this.aggregateResultArray, headers: aggregateHeaders };
    }
}

/** @hidden */
class GroupByValueEndpointComponent {
    constructor(executionContext, queryInfo) {
        this.executionContext = executionContext;
        this.queryInfo = queryInfo;
        this.aggregators = new Map();
        this.aggregateResultArray = [];
        this.completed = false;
        // VALUE queries will only every have a single grouping
        this.aggregateType = this.queryInfo.aggregates[0];
    }
    hasMoreResults() {
        return this.executionContext.hasMoreResults();
    }
    async fetchMore(diagnosticNode) {
        if (this.completed) {
            return {
                result: undefined,
                headers: getInitialHeader(),
            };
        }
        const aggregateHeaders = getInitialHeader();
        const response = await this.executionContext.fetchMore(diagnosticNode);
        mergeHeaders(aggregateHeaders, response.headers);
        if (response === undefined || response.result === undefined) {
            if (this.aggregators.size > 0) {
                return this.generateAggregateResponse(aggregateHeaders);
            }
            return { result: undefined, headers: aggregateHeaders };
        }
        for (const item of response.result) {
            if (item) {
                let grouping = emptyGroup;
                let payload = item;
                if (item.groupByItems) {
                    // If the query contains a GROUP BY clause, it will have a payload property and groupByItems
                    payload = item.payload;
                    grouping = await hashObject(item.groupByItems);
                }
                const aggregator = this.aggregators.get(grouping);
                if (!aggregator) {
                    // This is the first time we have seen a grouping so create a new aggregator
                    this.aggregators.set(grouping, createAggregator(this.aggregateType));
                }
                if (this.aggregateType) {
                    const aggregateResult = extractAggregateResult(payload[0]);
                    // if aggregate result is null, we need to short circuit aggregation and return undefined
                    if (aggregateResult === null) {
                        this.completed = true;
                    }
                    this.aggregators.get(grouping).aggregate(aggregateResult);
                }
                else {
                    // Queries with no aggregates pass the payload directly to the aggregator
                    // Example: SELECT VALUE c.team FROM c GROUP BY c.team
                    this.aggregators.get(grouping).aggregate(payload);
                }
            }
        }
        // We bail early since we got an undefined result back `[{}]`
        if (this.completed) {
            return {
                result: undefined,
                headers: aggregateHeaders,
            };
        }
        if (this.executionContext.hasMoreResults()) {
            return { result: [], headers: aggregateHeaders };
        }
        else {
            // If no results are left in the underlying execution context, convert our aggregate results to an array
            return this.generateAggregateResponse(aggregateHeaders);
        }
    }
    generateAggregateResponse(aggregateHeaders) {
        for (const aggregator of this.aggregators.values()) {
            const result = aggregator.getResult();
            if (result !== undefined) {
                this.aggregateResultArray.push(result);
            }
        }
        this.completed = true;
        return {
            result: this.aggregateResultArray,
            headers: aggregateHeaders,
        };
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
class FixedSizePriorityQueue {
    constructor(compareFn, pqMaxSize) {
        this.compareFn = compareFn;
        this.pq = new PriorityQueue(this.compareFn);
        this.pqMaxSize = pqMaxSize;
    }
    enqueue(item) {
        if (this.pq.size() < this.pqMaxSize) {
            this.pq.enq(item);
        }
        else {
            const topItem = this.pq.peek();
            if (this.compareFn(topItem, item) > 0) {
                this.pq.deq();
                this.pq.enq(item);
            }
        }
    }
    dequeue() {
        return this.pq.deq();
    }
    size() {
        return this.pq.size();
    }
    isEmpty() {
        return this.pq.isEmpty();
    }
    peek() {
        return this.pq.peek();
    }
    getTopElements() {
        const elements = [];
        while (!this.pq.isEmpty()) {
            elements.unshift(this.pq.deq());
        }
        return elements;
    }
    // Create a new instance of FixedSizePriorityQueue with a reversed compare function and the same maximum size.
    // Enqueue all elements from the current priority queue into the reverse priority queue.
    reverse() {
        const reversePQ = new FixedSizePriorityQueue((a, b) => -this.compareFn(a, b), this.pqMaxSize);
        while (!this.pq.isEmpty()) {
            reversePQ.enqueue(this.pq.deq());
        }
        return reversePQ;
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Stores the most favourable distinct result from a set of nonStreamingOrderBy results.
 */
class NonStreamingOrderByMap {
    constructor(compareFn) {
        this.compareFn = compareFn;
        this.map = new Map();
    }
    set(key, value) {
        if (!this.map.has(key)) {
            // If the key is not present in the map, add it.
            this.map.set(key, value);
        }
        else {
            // If the key is present in the map, compare the similarity score of the new value with the old value. Keep the more favourable one.
            const oldValue = this.map.get(key);
            if (this.replaceResults(oldValue, value)) {
                this.map.set(key, value);
            }
        }
    }
    get(key) {
        if (!this.map.has(key))
            return undefined;
        return this.map.get(key);
    }
    /**
     * Returns all the values in the map and resets the map.
     */
    getAllValuesAndReset() {
        const res = [];
        for (const [key, value] of this.map) {
            res.push(value);
            this.map.delete(key);
        }
        return res;
    }
    replaceResults(res1, res2) {
        const res = this.compareFn(res1, res2);
        if (res < 0)
            return true;
        return false;
    }
    size() {
        return this.map.size;
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 *  @hidden
 * ord is used to compare different types. Eg. in ascending order, for cross type comparison, boolean will come first, then number and, then string.
 * compFunc is used to compare the same type comparison.
 */
const TYPEORDCOMPARATOR = Object.freeze({
    NoValue: {
        ord: 0,
    },
    undefined: {
        ord: 1,
    },
    boolean: {
        ord: 2,
        compFunc: (a, b) => {
            return a === b ? 0 : a > b ? 1 : -1;
        },
    },
    number: {
        ord: 4,
        compFunc: (a, b) => {
            return a === b ? 0 : a > b ? 1 : -1;
        },
    },
    string: {
        ord: 5,
        compFunc: (a, b) => {
            return a === b ? 0 : a > b ? 1 : -1;
        },
    },
});
/** @hidden */
class OrderByComparator {
    constructor(sortOrder) {
        this.sortOrder = sortOrder;
    }
    compareItems(item1, item2) {
        const orderByItemsRes1 = this.getOrderByItems(item1);
        const orderByItemsRes2 = this.getOrderByItems(item2);
        for (let i = 0; i < orderByItemsRes1.length; i++) {
            // compares the orderby items one by one
            const compRes = this.compareOrderByItem(orderByItemsRes1[i], orderByItemsRes2[i]);
            if (compRes !== 0) {
                if (this.sortOrder[i] === "Descending") {
                    return compRes;
                }
                else if (this.sortOrder[i] === "Ascending") {
                    return -compRes;
                }
            }
        }
    }
    getOrderByItems(res) {
        return res["orderByItems"];
    }
    compareOrderByItem(orderByItem1, orderByItem2) {
        const type1 = this.getType(orderByItem1);
        const type2 = this.getType(orderByItem2);
        return this.compareValue(orderByItem1["item"], type1, orderByItem2["item"], type2);
    }
    getType(orderByItem) {
        // TODO: any item?
        if (orderByItem === undefined || orderByItem.item === undefined) {
            return "NoValue";
        }
        const type = typeof orderByItem.item;
        if (TYPEORDCOMPARATOR[type] === undefined) {
            throw new Error(`unrecognizable type ${type}`);
        }
        return type;
    }
    compareValue(item1, type1, item2, type2) {
        // TODO: https://github.com/Azure/azure-sdk-for-js/issues/30122
        // currently we do not support same type and cross type comparision for object and arrays.
        if (type1 === "object" || type2 === "object") {
            throw new Error("Tried to compare an object type");
        }
        const type1Ord = TYPEORDCOMPARATOR[type1].ord;
        const type2Ord = TYPEORDCOMPARATOR[type2].ord;
        // Validate if the two item are of same type or not based on the type ordinal.
        const typeCmp = type1Ord - type2Ord;
        // if not same type, compare based on the type ordinal. Lower ordinal takes precedence over higher ordinal.
        if (typeCmp !== 0) {
            return typeCmp;
        }
        // both are of the same type
        if (type1Ord === TYPEORDCOMPARATOR["undefined"].ord ||
            type1Ord === TYPEORDCOMPARATOR["NoValue"].ord) {
            // if both types are undefined or Null they are equal
            return 0;
        }
        const compFunc = TYPEORDCOMPARATOR[type1].compFunc;
        if (typeof compFunc === "undefined") {
            throw new Error("Cannot find the comparison function");
        }
        // same type and type is defined compare the items
        return compFunc(item1, item2);
    }
}

/**
 * @hidden
 * Represents an endpoint in handling an non-streaming order by distinct query.
 */
class NonStreamingOrderByDistinctEndpointComponent {
    constructor(executionContext, queryInfo, priorityQueueBufferSize, emitRawOrderByPayload = false) {
        this.executionContext = executionContext;
        this.queryInfo = queryInfo;
        this.priorityQueueBufferSize = priorityQueueBufferSize;
        this.emitRawOrderByPayload = emitRawOrderByPayload;
        /**
         * Flag to determine if all results are fetched from backend and results can be returned.
         */
        this.isCompleted = false;
        this.sortOrders = this.queryInfo.orderBy;
        const comparator = new OrderByComparator(this.sortOrders);
        this.aggregateMap = new NonStreamingOrderByMap((a, b) => {
            return comparator.compareItems(a, b);
        });
        this.nonStreamingOrderByPQ = new FixedSizePriorityQueue((a, b) => {
            return comparator.compareItems(b, a);
        }, this.priorityQueueBufferSize);
    }
    /**
     * Build final sorted result array from which responses will be served.
     */
    async buildFinalResultArray() {
        var _a;
        // Fetch all distinct values from the map and store in priority queue.
        const allValues = this.aggregateMap.getAllValuesAndReset();
        for (const value of allValues) {
            this.nonStreamingOrderByPQ.enqueue(value);
        }
        // Compute the final result array size based on offset and limit.
        const offSet = this.queryInfo.offset ? this.queryInfo.offset : 0;
        const queueSize = this.nonStreamingOrderByPQ.size();
        const finalArraySize = queueSize - offSet;
        if (finalArraySize <= 0) {
            this.finalResultArray = [];
        }
        else {
            this.finalResultArray = new Array(finalArraySize);
            // Only keep the final result array size number of items in the final result array and discard the rest.
            for (let count = finalArraySize - 1; count >= 0; count--) {
                if (this.emitRawOrderByPayload) {
                    this.finalResultArray[count] = this.nonStreamingOrderByPQ.dequeue();
                }
                else {
                    this.finalResultArray[count] = (_a = this.nonStreamingOrderByPQ.dequeue()) === null || _a === void 0 ? void 0 : _a.payload;
                }
            }
        }
    }
    hasMoreResults() {
        if (this.priorityQueueBufferSize === 0)
            return false;
        return this.executionContext.hasMoreResults();
    }
    async fetchMore(diagnosticNode) {
        if (this.isCompleted) {
            return {
                result: undefined,
                headers: getInitialHeader(),
            };
        }
        let resHeaders = getInitialHeader();
        // if size is 0, just return undefined to signal to more results. Valid if query is TOP 0 or LIMIT 0
        if (this.priorityQueueBufferSize <= 0) {
            return {
                result: undefined,
                headers: resHeaders,
            };
        }
        // If there are more results in backend, keep filling map.
        if (this.executionContext.hasMoreResults()) {
            // Grab the next result
            const response = await this.executionContext.fetchMore(diagnosticNode);
            if (response === undefined || response.result === undefined) {
                this.isCompleted = true;
                if (this.aggregateMap.size() > 0) {
                    await this.buildFinalResultArray();
                    return {
                        result: this.finalResultArray,
                        headers: response.headers,
                    };
                }
                return { result: undefined, headers: response.headers };
            }
            resHeaders = response.headers;
            for (const item of response.result) {
                if (item) {
                    const key = await hashObject(item === null || item === void 0 ? void 0 : item.payload);
                    this.aggregateMap.set(key, item);
                }
            }
            // return [] to signal that there are more results to fetch.
            if (this.executionContext.hasMoreResults()) {
                return {
                    result: [],
                    headers: resHeaders,
                };
            }
        }
        // If all results are fetched from backend, prepare final results
        if (!this.executionContext.hasMoreResults() && !this.isCompleted) {
            this.isCompleted = true;
            await this.buildFinalResultArray();
            return {
                result: this.finalResultArray,
                headers: resHeaders,
            };
        }
        // Signal that there are no more results.
        return {
            result: undefined,
            headers: resHeaders,
        };
    }
}

/**
 * @hidden
 * Represents an endpoint in handling an non-streaming order by query.
 */
class NonStreamingOrderByEndpointComponent {
    /**
     * Represents an endpoint in handling an non-streaming order by query. For each processed orderby
     * result it returns 'payload' item of the result
     *
     * @param executionContext - Underlying Execution Context
     * @hidden
     */
    constructor(executionContext, sortOrders, priorityQueueBufferSize, offset = 0, emitRawOrderByPayload = false) {
        this.executionContext = executionContext;
        this.sortOrders = sortOrders;
        this.priorityQueueBufferSize = priorityQueueBufferSize;
        this.offset = offset;
        this.emitRawOrderByPayload = emitRawOrderByPayload;
        /**
         * Flag to determine if all results are fetched from backend and results can be returned from priority queue.
         */
        this.isCompleted = false;
        const comparator = new OrderByComparator(this.sortOrders);
        this.nonStreamingOrderByPQ = new FixedSizePriorityQueue((a, b) => {
            return comparator.compareItems(b, a);
        }, this.priorityQueueBufferSize);
    }
    /**
     * Determine if there are still remaining resources to processs.
     * @returns true if there is other elements to process in the NonStreamingOrderByEndpointComponent.
     */
    hasMoreResults() {
        return this.priorityQueueBufferSize > 0 && this.executionContext.hasMoreResults();
    }
    /**
     * Fetches the next batch of the result from the target container.
     * @param diagnosticNode - The diagnostic information for the request.
     */
    async fetchMore(diagnosticNode) {
        if (this.isCompleted) {
            return {
                result: undefined,
                headers: getInitialHeader(),
            };
        }
        let resHeaders = getInitialHeader();
        // if size is 0, just return undefined to signal to more results. Valid if query is TOP 0 or LIMIT 0
        if (this.priorityQueueBufferSize <= 0) {
            return {
                result: undefined,
                headers: resHeaders,
            };
        }
        // If there are more results in backend, keep filling pq.
        if (this.executionContext.hasMoreResults()) {
            const response = await this.executionContext.fetchMore(diagnosticNode);
            resHeaders = response.headers;
            if (response === undefined || response.result === undefined) {
                this.isCompleted = true;
                if (!this.nonStreamingOrderByPQ.isEmpty()) {
                    return this.buildFinalResultArray(resHeaders);
                }
                return { result: undefined, headers: resHeaders };
            }
            for (const item of response.result) {
                if (item !== undefined) {
                    this.nonStreamingOrderByPQ.enqueue(item);
                }
            }
        }
        // If the backend has more results to fetch, return [] to signal that there are more results to fetch.
        if (this.executionContext.hasMoreResults()) {
            return {
                result: [],
                headers: resHeaders,
            };
        }
        // If all results are fetched from backend, prepare final results
        if (!this.executionContext.hasMoreResults() && !this.isCompleted) {
            this.isCompleted = true;
            return this.buildFinalResultArray(resHeaders);
        }
        // If pq is empty, return undefined to signal that there are no more results.
        return {
            result: undefined,
            headers: resHeaders,
        };
    }
    async buildFinalResultArray(resHeaders) {
        var _a;
        // Set isCompleted to true.
        this.isCompleted = true;
        // Reverse the priority queue to get the results in the correct order
        this.nonStreamingOrderByPQ = this.nonStreamingOrderByPQ.reverse();
        // For offset limit case we set the size of priority queue to offset + limit
        // and we drain offset number of items from the priority queue
        while (this.offset < this.priorityQueueBufferSize &&
            this.offset > 0 &&
            !this.nonStreamingOrderByPQ.isEmpty()) {
            this.nonStreamingOrderByPQ.dequeue();
            this.offset--;
        }
        // If pq is not empty, return the result from pq.
        if (!this.nonStreamingOrderByPQ.isEmpty()) {
            const buffer = [];
            if (this.emitRawOrderByPayload) {
                while (!this.nonStreamingOrderByPQ.isEmpty()) {
                    buffer.push(this.nonStreamingOrderByPQ.dequeue());
                }
            }
            else {
                while (!this.nonStreamingOrderByPQ.isEmpty()) {
                    buffer.push((_a = this.nonStreamingOrderByPQ.dequeue()) === null || _a === void 0 ? void 0 : _a.payload);
                }
            }
            return {
                result: buffer,
                headers: resHeaders,
            };
        }
    }
}

/** @hidden */
class PipelinedQueryExecutionContext {
    constructor(clientContext, collectionLink, query, options, partitionedQueryExecutionInfo, correlatedActivityId, emitRawOrderByPayload = false) {
        this.clientContext = clientContext;
        this.collectionLink = collectionLink;
        this.query = query;
        this.options = options;
        this.partitionedQueryExecutionInfo = partitionedQueryExecutionInfo;
        this.emitRawOrderByPayload = emitRawOrderByPayload;
        this.vectorSearchBufferSize = 0;
        this.nonStreamingOrderBy = false;
        this.endpoint = null;
        this.pageSize = options["maxItemCount"];
        if (this.pageSize === undefined) {
            this.pageSize = PipelinedQueryExecutionContext.DEFAULT_PAGE_SIZE;
        }
        // Pick between Nonstreaming and streaming endpoints
        this.nonStreamingOrderBy = partitionedQueryExecutionInfo.queryInfo.hasNonStreamingOrderBy;
        // Pick between parallel vs order by execution context
        const sortOrders = partitionedQueryExecutionInfo.queryInfo.orderBy;
        // TODO: Currently we don't get any field from backend to determine streaming queries
        if (this.nonStreamingOrderBy) {
            if (!options.allowUnboundedNonStreamingQueries) {
                this.checkQueryConstraints(partitionedQueryExecutionInfo.queryInfo);
            }
            this.vectorSearchBufferSize = this.calculateVectorSearchBufferSize(partitionedQueryExecutionInfo.queryInfo, options);
            const maxBufferSize = options["vectorSearchBufferSize"]
                ? options["vectorSearchBufferSize"]
                : PipelinedQueryExecutionContext.DEFAULT_MAX_VECTOR_SEARCH_BUFFER_SIZE;
            if (this.vectorSearchBufferSize > maxBufferSize) {
                throw new ErrorResponse(`Executing a vector search query with TOP or OFFSET + LIMIT value ${this.vectorSearchBufferSize} larger than the vectorSearchBufferSize ${maxBufferSize} ` +
                    `is not allowed`);
            }
            const distinctType = partitionedQueryExecutionInfo.queryInfo.distinctType;
            const context = new ParallelQueryExecutionContext(this.clientContext, this.collectionLink, this.query, this.options, this.partitionedQueryExecutionInfo, correlatedActivityId);
            if (distinctType === "None") {
                this.endpoint = new NonStreamingOrderByEndpointComponent(context, sortOrders, this.vectorSearchBufferSize, partitionedQueryExecutionInfo.queryInfo.offset, this.emitRawOrderByPayload);
            }
            else {
                this.endpoint = new NonStreamingOrderByDistinctEndpointComponent(context, partitionedQueryExecutionInfo.queryInfo, this.vectorSearchBufferSize, this.emitRawOrderByPayload);
            }
        }
        else {
            if (Array.isArray(sortOrders) && sortOrders.length > 0) {
                // Need to wrap orderby execution context in endpoint component, since the data is nested as a \
                //      "payload" property.
                this.endpoint = new OrderByEndpointComponent(new OrderByQueryExecutionContext(this.clientContext, this.collectionLink, this.query, this.options, this.partitionedQueryExecutionInfo, correlatedActivityId), this.emitRawOrderByPayload);
            }
            else {
                this.endpoint = new ParallelQueryExecutionContext(this.clientContext, this.collectionLink, this.query, this.options, this.partitionedQueryExecutionInfo, correlatedActivityId);
            }
            if (Object.keys(partitionedQueryExecutionInfo.queryInfo.groupByAliasToAggregateType).length >
                0 ||
                partitionedQueryExecutionInfo.queryInfo.aggregates.length > 0 ||
                partitionedQueryExecutionInfo.queryInfo.groupByExpressions.length > 0) {
                if (partitionedQueryExecutionInfo.queryInfo.hasSelectValue) {
                    this.endpoint = new GroupByValueEndpointComponent(this.endpoint, partitionedQueryExecutionInfo.queryInfo);
                }
                else {
                    this.endpoint = new GroupByEndpointComponent(this.endpoint, partitionedQueryExecutionInfo.queryInfo);
                }
            }
            // If distinct then add that to the pipeline
            const distinctType = partitionedQueryExecutionInfo.queryInfo.distinctType;
            if (distinctType === "Ordered") {
                this.endpoint = new OrderedDistinctEndpointComponent(this.endpoint);
            }
            if (distinctType === "Unordered") {
                this.endpoint = new UnorderedDistinctEndpointComponent(this.endpoint);
            }
            // If top then add that to the pipeline. TOP N is effectively OFFSET 0 LIMIT N
            const top = partitionedQueryExecutionInfo.queryInfo.top;
            if (typeof top === "number") {
                this.endpoint = new OffsetLimitEndpointComponent(this.endpoint, 0, top);
            }
            // If offset+limit then add that to the pipeline
            const limit = partitionedQueryExecutionInfo.queryInfo.limit;
            const offset = partitionedQueryExecutionInfo.queryInfo.offset;
            if (typeof limit === "number" && typeof offset === "number") {
                this.endpoint = new OffsetLimitEndpointComponent(this.endpoint, offset, limit);
            }
        }
        this.fetchBuffer = [];
    }
    hasMoreResults() {
        return this.fetchBuffer.length !== 0 || this.endpoint.hasMoreResults();
    }
    async fetchMore(diagnosticNode) {
        this.fetchMoreRespHeaders = getInitialHeader();
        return this._fetchMoreImplementation(diagnosticNode);
    }
    async _fetchMoreImplementation(diagnosticNode) {
        try {
            if (this.fetchBuffer.length >= this.pageSize) {
                const temp = this.fetchBuffer.slice(0, this.pageSize);
                this.fetchBuffer = this.fetchBuffer.slice(this.pageSize);
                return { result: temp, headers: this.fetchMoreRespHeaders };
            }
            else {
                const response = await this.endpoint.fetchMore(diagnosticNode);
                mergeHeaders(this.fetchMoreRespHeaders, response.headers);
                if (response === undefined || response.result === undefined) {
                    if (this.fetchBuffer.length > 0) {
                        const temp = this.fetchBuffer;
                        this.fetchBuffer = [];
                        return { result: temp, headers: this.fetchMoreRespHeaders };
                    }
                    else {
                        return { result: undefined, headers: this.fetchMoreRespHeaders };
                    }
                }
                this.fetchBuffer.push(...response.result);
                if (this.options.enableQueryControl) {
                    if (this.fetchBuffer.length >= this.pageSize) {
                        const temp = this.fetchBuffer.slice(0, this.pageSize);
                        this.fetchBuffer = this.fetchBuffer.slice(this.pageSize);
                        return { result: temp, headers: this.fetchMoreRespHeaders };
                    }
                    else {
                        const temp = this.fetchBuffer;
                        this.fetchBuffer = [];
                        return { result: temp, headers: this.fetchMoreRespHeaders };
                    }
                }
                // Recursively fetch more results to ensure the pageSize number of results are returned
                // to maintain compatibility with the previous implementation
                return this._fetchMoreImplementation(diagnosticNode);
            }
        }
        catch (err) {
            mergeHeaders(this.fetchMoreRespHeaders, err.headers);
            err.headers = this.fetchMoreRespHeaders;
            if (err) {
                throw err;
            }
        }
    }
    calculateVectorSearchBufferSize(queryInfo, options) {
        if (queryInfo.top === 0 || queryInfo.limit === 0)
            return 0;
        return queryInfo.top
            ? queryInfo.top
            : queryInfo.limit
                ? queryInfo.offset + queryInfo.limit
                : options["vectorSearchBufferSize"] && options["vectorSearchBufferSize"] > 0
                    ? options["vectorSearchBufferSize"]
                    : PipelinedQueryExecutionContext.DEFAULT_MAX_VECTOR_SEARCH_BUFFER_SIZE;
    }
    checkQueryConstraints(queryInfo) {
        const hasTop = queryInfo.top || queryInfo.top === 0;
        const hasLimit = queryInfo.limit || queryInfo.limit === 0;
        if (!hasTop && !hasLimit) {
            throw new ErrorResponse("Executing a non-streaming search query without TOP or LIMIT can consume a large number of RUs " +
                "very fast and have long runtimes. Please ensure you are using one of the above two filters " +
                "with your vector search query.");
        }
        return;
    }
}
PipelinedQueryExecutionContext.DEFAULT_PAGE_SIZE = 10;
PipelinedQueryExecutionContext.DEFAULT_MAX_VECTOR_SEARCH_BUFFER_SIZE = 50000;

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
const FieldNames = {
    Rid: "_rid",
    Payload: "payload",
    ComponentScores: "componentScores",
};
class HybridSearchQueryResult {
    constructor(rid, componentScores, data) {
        this.rid = rid;
        this.componentScores = componentScores;
        this.data = data;
    }
    static create(document) {
        const rid = document[FieldNames.Rid];
        if (!rid) {
            throw new Error(`${FieldNames.Rid} must exist.`);
        }
        const outerPayload = document[FieldNames.Payload];
        if (!outerPayload || typeof outerPayload !== "object") {
            throw new Error(`${FieldNames.Payload} must exist.`);
        }
        const innerPayload = outerPayload[FieldNames.Payload];
        if (!innerPayload || typeof innerPayload !== "object") {
            throw new Error(`${FieldNames.Payload} must exist nested within the outer payload field.`);
        }
        const componentScores = outerPayload[FieldNames.ComponentScores];
        if (!Array.isArray(componentScores)) {
            throw new Error(`${FieldNames.ComponentScores} must exist.`);
        }
        return new HybridSearchQueryResult(rid, componentScores, innerPayload);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
class GlobalStatisticsAggregator {
    constructor() {
        this.globalStatistics = {
            documentCount: 0,
            fullTextStatistics: [],
        };
    }
    aggregate(other) {
        if (!other) {
            return;
        }
        // Aggregate document count
        this.globalStatistics.documentCount += other.documentCount;
        // Ensure `fullTextStatistics` is initialized
        if (!other.fullTextStatistics || other.fullTextStatistics.length === 0) {
            return;
        }
        // Initialize `this.globalStatistics.fullTextStatistics` if it's empty
        if (this.globalStatistics.fullTextStatistics.length === 0) {
            this.globalStatistics.fullTextStatistics = other.fullTextStatistics.map((stat) => ({
                totalWordCount: stat.totalWordCount,
                hitCounts: [...stat.hitCounts],
            }));
        }
        else {
            // Loop through `other.fullTextStatistics` to add values to `this.globalStatistics.fullTextStatistics`
            for (let i = 0; i < other.fullTextStatistics.length; i++) {
                const otherStat = other.fullTextStatistics[i];
                // Ensure the index `i` is initialized
                if (!this.globalStatistics.fullTextStatistics[i]) {
                    this.globalStatistics.fullTextStatistics[i] = {
                        totalWordCount: 0,
                        hitCounts: [],
                    };
                }
                // Add totalWordCount
                this.globalStatistics.fullTextStatistics[i].totalWordCount += otherStat.totalWordCount;
                // Aggregate `hitCounts`
                for (let j = 0; j < otherStat.hitCounts.length; j++) {
                    // Initialize hit count if necessary
                    if (this.globalStatistics.fullTextStatistics[i].hitCounts.length <= j) {
                        this.globalStatistics.fullTextStatistics[i].hitCounts.push(0);
                    }
                    this.globalStatistics.fullTextStatistics[i].hitCounts[j] += otherStat.hitCounts[j];
                }
            }
        }
    }
    getResult() {
        return this.globalStatistics;
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/** @hidden */
var HybridQueryExecutionContextBaseStates;
(function (HybridQueryExecutionContextBaseStates) {
    HybridQueryExecutionContextBaseStates["uninitialized"] = "uninitialized";
    HybridQueryExecutionContextBaseStates["initialized"] = "initialized";
    HybridQueryExecutionContextBaseStates["draining"] = "draining";
    HybridQueryExecutionContextBaseStates["done"] = "done";
})(HybridQueryExecutionContextBaseStates || (HybridQueryExecutionContextBaseStates = {}));
class HybridQueryExecutionContext {
    constructor(clientContext, collectionLink, options, partitionedQueryExecutionInfo, correlatedActivityId, allPartitionsRanges) {
        this.clientContext = clientContext;
        this.collectionLink = collectionLink;
        this.options = options;
        this.partitionedQueryExecutionInfo = partitionedQueryExecutionInfo;
        this.correlatedActivityId = correlatedActivityId;
        this.allPartitionsRanges = allPartitionsRanges;
        this.componentsExecutionContext = [];
        this.emitRawOrderByPayload = true;
        this.buffer = [];
        this.DEFAULT_PAGE_SIZE = 10;
        this.TOTAL_WORD_COUNT_PLACEHOLDER = "documentdb-formattablehybridsearchquery-totalwordcount";
        this.HIT_COUNTS_ARRAY_PLACEHOLDER = "documentdb-formattablehybridsearchquery-hitcountsarray";
        this.TOTAL_DOCUMENT_COUNT_PLACEHOLDER = "documentdb-formattablehybridsearchquery-totaldocumentcount";
        this.RRF_CONSTANT = 60; // Constant for RRF score calculation
        this.logger = logger$5.createClientLogger("HybridQueryExecutionContext");
        this.hybridSearchResult = [];
        this.uniqueItems = new Map();
        this.isSingleComponent = false;
        this.state = HybridQueryExecutionContextBaseStates.uninitialized;
        this.pageSize = this.options.maxItemCount;
        if (this.pageSize === undefined) {
            this.pageSize = this.DEFAULT_PAGE_SIZE;
        }
        if (partitionedQueryExecutionInfo.hybridSearchQueryInfo.requiresGlobalStatistics) {
            const globalStaticsQueryOptions = { maxItemCount: this.pageSize };
            this.globalStatisticsAggregator = new GlobalStatisticsAggregator();
            const globalStatisticsQuery = this.partitionedQueryExecutionInfo.hybridSearchQueryInfo.globalStatisticsQuery;
            const globalStatisticsQueryExecutionInfo = {
                partitionedQueryExecutionInfoVersion: 1,
                queryInfo: {
                    distinctType: "None",
                    hasSelectValue: false,
                    groupByAliasToAggregateType: {},
                    rewrittenQuery: globalStatisticsQuery,
                    hasNonStreamingOrderBy: false,
                },
                queryRanges: this.allPartitionsRanges,
            };
            this.globalStatisticsExecutionContext = new ParallelQueryExecutionContext(this.clientContext, this.collectionLink, globalStatisticsQuery, globalStaticsQueryOptions, globalStatisticsQueryExecutionInfo, this.correlatedActivityId);
        }
        else {
            this.createComponentExecutionContexts();
            this.state = HybridQueryExecutionContextBaseStates.initialized;
        }
    }
    async nextItem(diagnosticNode) {
        const nextItemRespHeaders = getInitialHeader();
        while ((this.state === HybridQueryExecutionContextBaseStates.uninitialized ||
            this.state === HybridQueryExecutionContextBaseStates.initialized) &&
            this.buffer.length === 0) {
            await this.fetchMoreInternal(diagnosticNode, nextItemRespHeaders);
        }
        if (this.state === HybridQueryExecutionContextBaseStates.draining && this.buffer.length > 0) {
            return this.drainOne(nextItemRespHeaders);
        }
        else {
            return this.done(nextItemRespHeaders);
        }
    }
    hasMoreResults() {
        switch (this.state) {
            case HybridQueryExecutionContextBaseStates.uninitialized:
                return true;
            case HybridQueryExecutionContextBaseStates.initialized:
                return true;
            case HybridQueryExecutionContextBaseStates.draining:
                return this.buffer.length > 0;
            case HybridQueryExecutionContextBaseStates.done:
                return false;
            default:
                return false;
        }
    }
    async fetchMore(diagnosticNode) {
        const fetchMoreRespHeaders = getInitialHeader();
        return this.fetchMoreInternal(diagnosticNode, fetchMoreRespHeaders);
    }
    async fetchMoreInternal(diagnosticNode, headers) {
        switch (this.state) {
            case HybridQueryExecutionContextBaseStates.uninitialized:
                await this.initialize(diagnosticNode, headers);
                return {
                    result: [],
                    headers: headers,
                };
            case HybridQueryExecutionContextBaseStates.initialized:
                await this.executeComponentQueries(diagnosticNode, headers);
                return {
                    result: [],
                    headers: headers,
                };
            case HybridQueryExecutionContextBaseStates.draining:
                return this.drain(headers);
            case HybridQueryExecutionContextBaseStates.done:
                return this.done(headers);
            default:
                throw new Error(`Invalid state: ${this.state}`);
        }
    }
    async initialize(diagnosticNode, fetchMoreRespHeaders) {
        try {
            while (this.globalStatisticsExecutionContext.hasMoreResults()) {
                const result = await this.globalStatisticsExecutionContext.fetchMore(diagnosticNode);
                mergeHeaders(fetchMoreRespHeaders, result.headers);
                if (result && result.result) {
                    for (const item of result.result) {
                        const globalStatistics = item;
                        if (globalStatistics) {
                            // iterate over the components update placeholders from globalStatistics
                            this.globalStatisticsAggregator.aggregate(globalStatistics);
                        }
                    }
                }
            }
        }
        catch (error) {
            this.state = HybridQueryExecutionContextBaseStates.done;
            throw error;
        }
        // create component execution contexts for each component query
        this.createComponentExecutionContexts();
        this.state = HybridQueryExecutionContextBaseStates.initialized;
    }
    async executeComponentQueries(diagnosticNode, fetchMoreRespHeaders) {
        if (this.isSingleComponent) {
            await this.drainSingleComponent(diagnosticNode, fetchMoreRespHeaders);
            return;
        }
        try {
            if (this.options.enableQueryControl) {
                // track componentExecutionContexts with remaining results and call them in LIFO order
                if (this.componentsExecutionContext.length > 0) {
                    const componentExecutionContext = this.componentsExecutionContext.pop();
                    if (componentExecutionContext.hasMoreResults()) {
                        const result = await componentExecutionContext.fetchMore(diagnosticNode);
                        const response = result.result;
                        mergeHeaders(fetchMoreRespHeaders, result.headers);
                        if (response) {
                            response.forEach((item) => {
                                const hybridItem = HybridSearchQueryResult.create(item);
                                if (!this.uniqueItems.has(hybridItem.rid)) {
                                    this.uniqueItems.set(hybridItem.rid, hybridItem);
                                }
                            });
                        }
                        if (componentExecutionContext.hasMoreResults()) {
                            this.componentsExecutionContext.push(componentExecutionContext);
                        }
                    }
                }
                if (this.componentsExecutionContext.length === 0) {
                    this.processUniqueItems();
                }
            }
            else {
                for (const componentExecutionContext of this.componentsExecutionContext) {
                    while (componentExecutionContext.hasMoreResults()) {
                        const result = await componentExecutionContext.fetchMore(diagnosticNode);
                        const response = result.result;
                        mergeHeaders(fetchMoreRespHeaders, result.headers);
                        if (response) {
                            response.forEach((item) => {
                                const hybridItem = HybridSearchQueryResult.create(item);
                                if (!this.uniqueItems.has(hybridItem.rid)) {
                                    this.uniqueItems.set(hybridItem.rid, hybridItem);
                                }
                            });
                        }
                    }
                }
                this.processUniqueItems();
            }
        }
        catch (error) {
            this.state = HybridQueryExecutionContextBaseStates.done;
            throw error;
        }
    }
    processUniqueItems() {
        this.uniqueItems.forEach((item) => this.hybridSearchResult.push(item));
        if (this.hybridSearchResult.length === 0 || this.hybridSearchResult.length === 1) {
            // return the result as no or one element is present
            this.hybridSearchResult.forEach((item) => this.buffer.push(item.data));
            this.state = HybridQueryExecutionContextBaseStates.draining;
            return;
        }
        // Initialize an array to hold ranks for each document
        const sortedHybridSearchResult = this.sortHybridSearchResultByRRFScore(this.hybridSearchResult);
        // store the result to buffer
        // add only data from the sortedHybridSearchResult in the buffer
        sortedHybridSearchResult.forEach((item) => this.buffer.push(item.data));
        this.applySkipAndTakeToBuffer();
        this.state = HybridQueryExecutionContextBaseStates.draining;
    }
    applySkipAndTakeToBuffer() {
        const { skip, take } = this.partitionedQueryExecutionInfo.hybridSearchQueryInfo;
        if (skip) {
            this.buffer = skip >= this.buffer.length ? [] : this.buffer.slice(skip);
        }
        if (take) {
            this.buffer = take <= 0 ? [] : this.buffer.slice(0, take);
        }
    }
    async drain(fetchMoreRespHeaders) {
        try {
            if (this.buffer.length === 0) {
                this.state = HybridQueryExecutionContextBaseStates.done;
                return this.done(fetchMoreRespHeaders);
            }
            const result = this.buffer.slice(0, this.pageSize);
            this.buffer = this.buffer.slice(this.pageSize);
            if (this.buffer.length === 0) {
                this.state = HybridQueryExecutionContextBaseStates.done;
            }
            return {
                result: result,
                headers: fetchMoreRespHeaders,
            };
        }
        catch (error) {
            this.state = HybridQueryExecutionContextBaseStates.done;
            throw error;
        }
    }
    async drainOne(nextItemRespHeaders) {
        try {
            if (this.buffer.length === 0) {
                this.state = HybridQueryExecutionContextBaseStates.done;
                return this.done(nextItemRespHeaders);
            }
            const result = this.buffer.shift();
            if (this.buffer.length === 0) {
                this.state = HybridQueryExecutionContextBaseStates.done;
            }
            return {
                result: result,
                headers: nextItemRespHeaders,
            };
        }
        catch (error) {
            this.state = HybridQueryExecutionContextBaseStates.done;
            throw error;
        }
    }
    done(fetchMoreRespHeaders) {
        return {
            result: undefined,
            headers: fetchMoreRespHeaders,
        };
    }
    sortHybridSearchResultByRRFScore(hybridSearchResult) {
        if (hybridSearchResult.length === 0) {
            return [];
        }
        const ranksArray = hybridSearchResult.map((item) => ({
            rid: item.rid,
            ranks: new Array(item.componentScores.length).fill(0),
        }));
        // Compute ranks for each component score
        for (let i = 0; i < hybridSearchResult[0].componentScores.length; i++) {
            // Sort based on the i-th component score
            hybridSearchResult.sort((a, b) => b.componentScores[i] - a.componentScores[i]);
            // Assign ranks
            let rank = 1;
            for (let j = 0; j < hybridSearchResult.length; j++) {
                if (j > 0 &&
                    hybridSearchResult[j].componentScores[i] !== hybridSearchResult[j - 1].componentScores[i]) {
                    rank = j + 1;
                }
                const rankIndex = ranksArray.findIndex((rankItem) => rankItem.rid === hybridSearchResult[j].rid);
                ranksArray[rankIndex].ranks[i] = rank; // 1-based rank
            }
        }
        // Function to compute RRF score
        const computeRRFScore = (ranks, k) => {
            return ranks.reduce((acc, rank) => acc + 1 / (k + rank), 0);
        };
        // Compute RRF scores and sort based on them
        const rrfScores = ranksArray.map((item) => ({
            rid: item.rid,
            rrfScore: computeRRFScore(item.ranks, this.RRF_CONSTANT),
        }));
        // Sort based on RRF scores
        rrfScores.sort((a, b) => b.rrfScore - a.rrfScore);
        // Map sorted RRF scores back to hybridSearchResult
        const sortedHybridSearchResult = rrfScores.map((scoreItem) => hybridSearchResult.find((item) => item.rid === scoreItem.rid));
        return sortedHybridSearchResult;
    }
    async drainSingleComponent(diagNode, fetchMoreRespHeaders) {
        if (this.componentsExecutionContext && this.componentsExecutionContext.length !== 1) {
            this.logger.error("drainSingleComponent called on multiple components");
            return;
        }
        try {
            if (this.options.enableQueryControl) {
                const componentExecutionContext = this.componentsExecutionContext[0];
                if (componentExecutionContext.hasMoreResults()) {
                    const result = await componentExecutionContext.fetchMore(diagNode);
                    const response = result.result;
                    mergeHeaders(fetchMoreRespHeaders, result.headers);
                    if (response) {
                        response.forEach((item) => {
                            this.hybridSearchResult.push(HybridSearchQueryResult.create(item));
                        });
                    }
                }
                if (!componentExecutionContext.hasMoreResults()) {
                    this.state = HybridQueryExecutionContextBaseStates.draining;
                    this.hybridSearchResult.forEach((item) => this.buffer.push(item.data));
                    this.applySkipAndTakeToBuffer();
                    this.state = HybridQueryExecutionContextBaseStates.draining;
                }
                return;
            }
            else {
                const componentExecutionContext = this.componentsExecutionContext[0];
                const hybridSearchResult = [];
                // add check for enable query control
                while (componentExecutionContext.hasMoreResults()) {
                    const result = await componentExecutionContext.fetchMore(diagNode);
                    const response = result.result;
                    mergeHeaders(fetchMoreRespHeaders, result.headers);
                    if (response) {
                        response.forEach((item) => {
                            hybridSearchResult.push(HybridSearchQueryResult.create(item));
                        });
                    }
                }
                hybridSearchResult.forEach((item) => this.buffer.push(item.data));
                this.applySkipAndTakeToBuffer();
                this.state = HybridQueryExecutionContextBaseStates.draining;
            }
        }
        catch (error) {
            this.state = HybridQueryExecutionContextBaseStates.done;
            throw error;
        }
    }
    createComponentExecutionContexts() {
        // rewrite queries based on global statistics
        let queryInfos = this.partitionedQueryExecutionInfo.hybridSearchQueryInfo.componentQueryInfos;
        if (this.partitionedQueryExecutionInfo.hybridSearchQueryInfo.requiresGlobalStatistics) {
            queryInfos = this.processComponentQueries(this.partitionedQueryExecutionInfo.hybridSearchQueryInfo.componentQueryInfos, this.globalStatisticsAggregator.getResult());
        }
        // create component execution contexts
        for (const componentQueryInfo of queryInfos) {
            const componentPartitionExecutionInfo = {
                partitionedQueryExecutionInfoVersion: 1,
                queryInfo: componentQueryInfo,
                queryRanges: this.partitionedQueryExecutionInfo.queryRanges,
            };
            const executionContext = new PipelinedQueryExecutionContext(this.clientContext, this.collectionLink, componentQueryInfo.rewrittenQuery, this.options, componentPartitionExecutionInfo, this.correlatedActivityId, this.emitRawOrderByPayload);
            this.componentsExecutionContext.push(executionContext);
        }
        this.isSingleComponent = this.componentsExecutionContext.length === 1;
    }
    processComponentQueries(componentQueryInfos, globalStats) {
        return componentQueryInfos.map((queryInfo) => {
            if (!queryInfo.hasNonStreamingOrderBy) {
                throw new Error("The component query must have a non-streaming order by clause.");
            }
            return Object.assign(Object.assign({}, queryInfo), { rewrittenQuery: this.replacePlaceholdersWorkaroud(queryInfo.rewrittenQuery, globalStats, componentQueryInfos.length), orderByExpressions: queryInfo.orderByExpressions.map((expr) => this.replacePlaceholdersWorkaroud(expr, globalStats, componentQueryInfos.length)) });
        });
    }
    // This method is commented currently, but we will switch back to using this
    // once the gateway has been redeployed with the fix for placeholder indexes
    // private replacePlaceholders(query: string, globalStats: GlobalStatistics): string {
    //   // Replace total document count
    //   query = query.replace(
    //     new RegExp(`{${this.TOTAL_DOCUMENT_COUNT_PLACEHOLDER}}`, "g"),
    //     globalStats.documentCount.toString(),
    //   );
    //   // Replace total word counts and hit counts from fullTextStatistics
    //   globalStats.fullTextStatistics.forEach((stats, index) => {
    //     // Replace total word counts
    //     query = query.replace(
    //       new RegExp(`{${this.TOTAL_WORD_COUNT_PLACEHOLDER}-${index}}`, "g"),
    //       stats.totalWordCount.toString(),
    //     );
    //     // Replace hit counts
    //     query = query.replace(
    //       new RegExp(`{${this.HIT_COUNTS_ARRAY_PLACEHOLDER}-${index}}`, "g"),
    //       `[${stats.hitCounts.join(",")}]`,
    //     );
    //   });
    //   return query;
    // }
    replacePlaceholdersWorkaroud(query, globalStats, componentCount) {
        if (!globalStats ||
            !globalStats.documentCount ||
            !Array.isArray(globalStats.fullTextStatistics)) {
            throw new Error("GlobalStats validation failed");
        }
        // Replace total document count
        query = query.replace(new RegExp(`{${this.TOTAL_DOCUMENT_COUNT_PLACEHOLDER}}`, "g"), globalStats.documentCount.toString());
        let statisticsIndex = 0;
        for (let i = 0; i < componentCount; i++) {
            // Replace total word counts and hit counts from fullTextStatistics
            const wordCountPlaceholder = `{${this.TOTAL_WORD_COUNT_PLACEHOLDER}-${i}}`;
            const hitCountPlaceholder = `{${this.HIT_COUNTS_ARRAY_PLACEHOLDER}-${i}}`;
            if (!query.includes(wordCountPlaceholder)) {
                continue;
            }
            const stats = globalStats.fullTextStatistics[statisticsIndex];
            // Replace total word counts
            query = query.replace(new RegExp(wordCountPlaceholder, "g"), stats.totalWordCount.toString());
            // Replace hit counts
            query = query.replace(new RegExp(hitCountPlaceholder, "g"), `[${stats.hitCounts.join(",")}]`);
            statisticsIndex++;
        }
        return query;
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Represents a QueryIterator Object, an implementation of feed or query response that enables
 * traversal and iterating over the response
 * in the Azure Cosmos DB database service.
 */
class QueryIterator {
    /**
     * @hidden
     */
    constructor(clientContext, query, options, fetchFunctions, resourceLink, resourceType) {
        this.clientContext = clientContext;
        this.query = query;
        this.options = options;
        this.fetchFunctions = fetchFunctions;
        this.resourceLink = resourceLink;
        this.resourceType = resourceType;
        this.query = query;
        this.fetchFunctions = fetchFunctions;
        this.options = options || {};
        this.resourceLink = resourceLink;
        this.fetchAllLastResHeaders = getInitialHeader();
        this.reset();
        this.isInitialized = false;
        this.partitionKeyRangeCache = new PartitionKeyRangeCache(this.clientContext);
    }
    /**
     * Gets an async iterator that will yield results until completion.
     *
     * NOTE: AsyncIterators are a very new feature and you might need to
     * use polyfils/etc. in order to use them in your code.
     *
     * If you're using TypeScript, you can use the following polyfill as long
     * as you target ES6 or higher and are running on Node 6 or higher.
     *
     * ```typescript
     * if (!Symbol || !Symbol.asyncIterator) {
     *   (Symbol as any).asyncIterator = Symbol.for("Symbol.asyncIterator");
     * }
     * ```
     *
     * @example Iterate over all databases
     * ```typescript
     * for await(const { resources: db } of client.databases.readAll().getAsyncIterator()) {
     *   console.log(`Got ${db} from AsyncIterator`);
     * }
     * ```
     */
    getAsyncIterator() {
        return tslib.__asyncGenerator(this, arguments, function* getAsyncIterator_1() {
            const diagnosticNode = new DiagnosticNodeInternal(this.clientContext.diagnosticLevel, exports.DiagnosticNodeType.CLIENT_REQUEST_NODE, null);
            yield tslib.__await(yield* tslib.__asyncDelegator(tslib.__asyncValues(this.getAsyncIteratorInternal(diagnosticNode))));
        });
    }
    /**
     * @internal
     */
    getAsyncIteratorInternal(diagnosticNode) {
        return tslib.__asyncGenerator(this, arguments, function* getAsyncIteratorInternal_1() {
            this.reset();
            this.queryPlanPromise = this.fetchQueryPlan(diagnosticNode);
            while (this.queryExecutionContext.hasMoreResults()) {
                let response;
                try {
                    response = yield tslib.__await(this.queryExecutionContext.fetchMore(diagnosticNode));
                }
                catch (error) {
                    if (this.needsQueryPlan(error)) {
                        yield tslib.__await(this.createExecutionContext(diagnosticNode));
                        try {
                            response = yield tslib.__await(this.queryExecutionContext.fetchMore(diagnosticNode));
                        }
                        catch (queryError) {
                            this.handleSplitError(queryError);
                        }
                    }
                    else {
                        throw error;
                    }
                }
                const feedResponse = new FeedResponse(response.result, response.headers, this.queryExecutionContext.hasMoreResults(), diagnosticNode.toDiagnostic(this.clientContext.getClientConfig()));
                diagnosticNode = new DiagnosticNodeInternal(this.clientContext.diagnosticLevel, exports.DiagnosticNodeType.CLIENT_REQUEST_NODE, null);
                if (response.result !== undefined) {
                    yield yield tslib.__await(feedResponse);
                }
            }
        });
    }
    /**
     * Determine if there are still remaining resources to process based on the value of the continuation token or the
     * elements remaining on the current batch in the QueryIterator.
     * @returns true if there is other elements to process in the QueryIterator.
     */
    hasMoreResults() {
        return this.queryExecutionContext.hasMoreResults();
    }
    /**
     * Fetch all pages for the query and return a single FeedResponse.
     */
    async fetchAll() {
        return withDiagnostics(async (diagnosticNode) => {
            return this.fetchAllInternal(diagnosticNode);
        }, this.clientContext);
    }
    /**
     * @hidden
     */
    async fetchAllInternal(diagnosticNode) {
        this.reset();
        let response;
        try {
            response = await this.toArrayImplementation(diagnosticNode);
        }
        catch (error) {
            this.handleSplitError(error);
        }
        return response;
    }
    /**
     * Retrieve the next batch from the feed.
     *
     * This may or may not fetch more pages from the backend depending on your settings
     * and the type of query. Aggregate queries will generally fetch all backend pages
     * before returning the first batch of responses.
     */
    async fetchNext() {
        return withDiagnostics(async (diagnosticNode) => {
            return this.fetchNextInternal(diagnosticNode);
        }, this.clientContext);
    }
    /**
     * @internal
     */
    async fetchNextInternal(diagnosticNode) {
        this.queryPlanPromise = withMetadataDiagnostics(async (metadataNode) => {
            return this.fetchQueryPlan(metadataNode);
        }, diagnosticNode, exports.MetadataLookUpType.QueryPlanLookUp);
        if (!this.isInitialized) {
            await this.init(diagnosticNode);
        }
        let response;
        try {
            response = await this.queryExecutionContext.fetchMore(diagnosticNode);
        }
        catch (error) {
            if (this.needsQueryPlan(error)) {
                await this.createExecutionContext(diagnosticNode);
                try {
                    response = await this.queryExecutionContext.fetchMore(diagnosticNode);
                }
                catch (queryError) {
                    this.handleSplitError(queryError);
                }
            }
            else {
                throw error;
            }
        }
        return new FeedResponse(response.result, response.headers, this.queryExecutionContext.hasMoreResults(), getEmptyCosmosDiagnostics());
    }
    /**
     * Reset the QueryIterator to the beginning and clear all the resources inside it
     */
    reset() {
        this.correlatedActivityId = coreUtil.randomUUID();
        this.queryPlanPromise = undefined;
        this.fetchAllLastResHeaders = getInitialHeader();
        this.fetchAllTempResources = [];
        this.queryExecutionContext = new DefaultQueryExecutionContext(this.options, this.fetchFunctions, this.correlatedActivityId);
    }
    async toArrayImplementation(diagnosticNode) {
        this.queryPlanPromise = withMetadataDiagnostics(async (metadataNode) => {
            return this.fetchQueryPlan(metadataNode);
        }, diagnosticNode, exports.MetadataLookUpType.QueryPlanLookUp);
        // this.queryPlanPromise = this.fetchQueryPlan(diagnosticNode);
        if (!this.isInitialized) {
            await this.init(diagnosticNode);
        }
        while (this.queryExecutionContext.hasMoreResults()) {
            let response;
            try {
                response = await this.queryExecutionContext.fetchMore(diagnosticNode);
            }
            catch (error) {
                if (this.needsQueryPlan(error)) {
                    await this.createExecutionContext(diagnosticNode);
                    response = await this.queryExecutionContext.fetchMore(diagnosticNode);
                }
                else {
                    throw error;
                }
            }
            const { result, headers } = response;
            // concatenate the results and fetch more
            mergeHeaders(this.fetchAllLastResHeaders, headers);
            if (result) {
                this.fetchAllTempResources.push(...result);
            }
        }
        return new FeedResponse(this.fetchAllTempResources, this.fetchAllLastResHeaders, this.queryExecutionContext.hasMoreResults(), getEmptyCosmosDiagnostics());
    }
    async createExecutionContext(diagnosticNode) {
        const queryPlanResponse = await this.queryPlanPromise;
        // We always coerce queryPlanPromise to resolved. So if it errored, we need to manually inspect the resolved value
        if (queryPlanResponse instanceof Error) {
            throw queryPlanResponse;
        }
        const queryPlan = queryPlanResponse.result;
        if (queryPlan.hybridSearchQueryInfo && queryPlan.hybridSearchQueryInfo !== null) {
            await this.createHybridQueryExecutionContext(queryPlan, diagnosticNode);
        }
        else {
            await this.createPipelinedExecutionContext(queryPlan);
        }
    }
    async createHybridQueryExecutionContext(queryPlan, diagnosticNode) {
        const allPartitionKeyRanges = (await this.partitionKeyRangeCache.onCollectionRoutingMap(this.resourceLink, diagnosticNode)).getOrderedParitionKeyRanges();
        // convert allPartitionKeyRanges to QueryRanges
        const queryRanges = allPartitionKeyRanges.map((partitionKeyRange) => {
            return {
                min: partitionKeyRange.minInclusive,
                max: partitionKeyRange.maxExclusive,
                isMinInclusive: true,
                isMaxInclusive: false,
            };
        });
        this.queryExecutionContext = new HybridQueryExecutionContext(this.clientContext, this.resourceLink, this.options, queryPlan, this.correlatedActivityId, queryRanges);
    }
    async createPipelinedExecutionContext(queryPlan) {
        const queryInfo = queryPlan.queryInfo;
        if (queryInfo.aggregates.length > 0 && queryInfo.hasSelectValue === false) {
            throw new Error("Aggregate queries must use the VALUE keyword");
        }
        this.queryExecutionContext = new PipelinedQueryExecutionContext(this.clientContext, this.resourceLink, this.query, this.options, queryPlan, this.correlatedActivityId);
    }
    async fetchQueryPlan(diagnosticNode) {
        if (!this.queryPlanPromise && this.resourceType === exports.ResourceType.item) {
            return this.clientContext
                .getQueryPlan(getPathFromLink(this.resourceLink) + "/docs", exports.ResourceType.item, this.resourceLink, this.query, this.options, diagnosticNode, this.correlatedActivityId)
                .catch((error) => error); // Without this catch, node reports an unhandled rejection. So we stash the promise as resolved even if it errored.
        }
        return this.queryPlanPromise;
    }
    needsQueryPlan(error) {
        var _a;
        if (((_a = error.body) === null || _a === void 0 ? void 0 : _a.additionalErrorInfo) ||
            error.message.includes("Cross partition query only supports")) {
            return error.code === StatusCodes.BadRequest && this.resourceType === exports.ResourceType.item;
        }
        else {
            throw error;
        }
    }
    /**
     * @internal
     */
    async init(diagnosticNode) {
        if (this.isInitialized === true) {
            return;
        }
        if (this.initPromise === undefined) {
            this.initPromise = this._init(diagnosticNode);
        }
        return this.initPromise;
    }
    async _init(diagnosticNode) {
        if (this.options.forceQueryPlan === true && this.resourceType === exports.ResourceType.item) {
            await this.createExecutionContext(diagnosticNode);
        }
        this.isInitialized = true;
    }
    handleSplitError(err) {
        if (err.code === 410) {
            const error = new Error("Encountered partition split and could not recover. This request is retryable");
            error.code = 503;
            error.originalError = err;
            throw error;
        }
        else {
            throw err;
        }
    }
}

class ConflictResponse extends ResourceResponse {
    constructor(resource, headers, statusCode, conflict, diagnostics) {
        super(resource, headers, statusCode, diagnostics);
        this.conflict = conflict;
    }
}

/**
 * Use to read or delete a given {@link Conflict} by id.
 *
 * @see {@link Conflicts} to query or read all conflicts.
 */
class Conflict {
    /**
     * Returns a reference URL to the resource. Used for linking in Permissions.
     */
    get url() {
        return `/${this.container.url}/${Constants.Path.ConflictsPathSegment}/${this.id}`;
    }
    /**
     * @hidden
     * @param container - The parent {@link Container}.
     * @param id - The id of the given {@link Conflict}.
     */
    constructor(container, id, clientContext, partitionKey) {
        this.container = container;
        this.id = id;
        this.clientContext = clientContext;
        this.partitionKey = partitionKey;
        this.partitionKey = partitionKey;
    }
    /**
     * Read the {@link ConflictDefinition} for the given {@link Conflict}.
     */
    async read(options) {
        return withDiagnostics(async (diagnosticNode) => {
            const path = getPathFromLink(this.url, exports.ResourceType.conflicts);
            const id = getIdFromLink(this.url);
            const response = await this.clientContext.read({
                path,
                resourceType: exports.ResourceType.user,
                resourceId: id,
                options,
                diagnosticNode,
            });
            return new ConflictResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * Delete the given {@link ConflictDefinition}.
     */
    async delete(options) {
        return withDiagnostics(async (diagnosticNode) => {
            if (this.partitionKey === undefined) {
                const partitionKeyDefinition = await readPartitionKeyDefinition(diagnosticNode, this.container);
                this.partitionKey = undefinedPartitionKey(partitionKeyDefinition);
            }
            const path = getPathFromLink(this.url);
            const id = getIdFromLink(this.url);
            const response = await this.clientContext.delete({
                path,
                resourceType: exports.ResourceType.conflicts,
                resourceId: id,
                options,
                partitionKey: this.partitionKey,
                diagnosticNode,
            });
            return new ConflictResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
}

/**
 * Use to query or read all conflicts.
 *
 * @see {@link Conflict} to read or delete a given {@link Conflict} by id.
 */
class Conflicts {
    constructor(container, clientContext) {
        this.container = container;
        this.clientContext = clientContext;
    }
    query(query, options) {
        const path = getPathFromLink(this.container.url, exports.ResourceType.conflicts);
        const id = getIdFromLink(this.container.url);
        return new QueryIterator(this.clientContext, query, options, (diagNode, innerOptions) => {
            return this.clientContext.queryFeed({
                path,
                resourceType: exports.ResourceType.conflicts,
                resourceId: id,
                resultFn: (result) => result.Conflicts,
                query,
                options: innerOptions,
                diagnosticNode: diagNode,
            });
        });
    }
    /**
     * Reads all conflicts
     * @param options - Use to set options like response page size, continuation tokens, etc.
     */
    readAll(options) {
        return this.query(undefined, options);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
exports.ConflictResolutionMode = void 0;
(function (ConflictResolutionMode) {
    ConflictResolutionMode["Custom"] = "Custom";
    ConflictResolutionMode["LastWriterWins"] = "LastWriterWins";
})(exports.ConflictResolutionMode || (exports.ConflictResolutionMode = {}));

class ItemResponse extends ResourceResponse {
    constructor(resource, headers, statusCode, subsstatusCode, item, diagnostics) {
        super(resource, headers, statusCode, diagnostics, subsstatusCode);
        this.item = item;
    }
}

/**
 * Used to perform operations on a specific item.
 *
 * @see {@link Items} for operations on all items; see `container.items`.
 */
class Item {
    /**
     * Returns a reference URL to the resource. Used for linking in Permissions.
     */
    get url() {
        return createDocumentUri(this.container.database.id, this.container.id, this.id);
    }
    /**
     * @hidden
     * @param container - The parent {@link Container}.
     * @param id - The id of the given {@link Item}.
     * @param partitionKey - The primary key of the given {@link Item} (only for partitioned containers).
     */
    constructor(container, id, clientContext, partitionKey) {
        this.container = container;
        this.id = id;
        this.clientContext = clientContext;
        this.partitionKey =
            partitionKey === undefined ? undefined : convertToInternalPartitionKey(partitionKey);
    }
    /**
     * Read the item's definition.
     *
     * Any provided type, T, is not necessarily enforced by the SDK.
     * You may get more or less properties and it's up to your logic to enforce it.
     * If the type, T, is a class, it won't pass `typeof` comparisons, because it won't have a match prototype.
     * It's recommended to only use interfaces.
     *
     * There is no set schema for JSON items. They may contain any number of custom properties.
     *
     * @param options - Additional options for the request
     *
     * @example Using custom type for response
     * ```typescript
     * interface TodoItem {
     *   title: string;
     *   done: bool;
     *   id: string;
     * }
     *
     * let item: TodoItem;
     * ({body: item} = await item.read<TodoItem>());
     * ```
     */
    async read(options = {}) {
        return withDiagnostics(async (diagnosticNode) => {
            this.partitionKey = await setPartitionKeyIfUndefined(diagnosticNode, this.container, this.partitionKey);
            let url = this.url;
            let partitionKey = this.partitionKey;
            let response;
            try {
                if (this.clientContext.enableEncryption) {
                    await this.container.checkAndInitializeEncryption();
                    options.containerRid = this.container._rid;
                    let count = 0;
                    diagnosticNode.beginEncryptionDiagnostics(Constants.Encryption.DiagnosticsEncryptOperation);
                    const { partitionKeyList: encryptedPartitionKey, encryptedCount } = await this.container.encryptionProcessor.getEncryptedPartitionKeyValue(this.partitionKey);
                    partitionKey = encryptedPartitionKey;
                    count += encryptedCount;
                    if (await this.container.encryptionProcessor.isPathEncrypted("/id")) {
                        url = await this.container.encryptionProcessor.getEncryptedUrl(this.url);
                        count++;
                    }
                    diagnosticNode.endEncryptionDiagnostics(Constants.Encryption.DiagnosticsEncryptOperation, count);
                }
                const path = getPathFromLink(url);
                const id = getIdFromLink(url);
                response = await this.clientContext.read({
                    path,
                    resourceType: exports.ResourceType.item,
                    resourceId: id,
                    options,
                    partitionKey: partitionKey,
                    diagnosticNode,
                });
            }
            catch (error) {
                if (this.clientContext.enableEncryption) {
                    await this.container.throwIfRequestNeedsARetryPostPolicyRefresh(error);
                }
                if (error.code !== StatusCodes.NotFound) {
                    throw error;
                }
                response = error;
            }
            if (this.clientContext.enableEncryption) {
                diagnosticNode.beginEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation);
                const { body, propertiesDecryptedCount } = await this.container.encryptionProcessor.decrypt(response.result);
                diagnosticNode.endEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation, propertiesDecryptedCount);
                response.result = body;
            }
            return new ItemResponse(response.result, response.headers, response.code, response.substatus, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    async replace(body, options = {}) {
        return withDiagnostics(async (diagnosticNode) => {
            this.partitionKey = await setPartitionKeyIfUndefined(diagnosticNode, this.container, this.partitionKey);
            let partitionKey = this.partitionKey;
            const err = {};
            if (!isItemResourceValid(body, err)) {
                throw err;
            }
            let url = this.url;
            let response;
            try {
                if (this.clientContext.enableEncryption) {
                    // returns copy to avoid encryption of original body passed
                    body = copyObject(body);
                    options = options || {};
                    await this.container.checkAndInitializeEncryption();
                    options.containerRid = this.container._rid;
                    let count = 0;
                    diagnosticNode.beginEncryptionDiagnostics(Constants.Encryption.DiagnosticsEncryptOperation);
                    const { body: encryptedBody, propertiesEncryptedCount } = await this.container.encryptionProcessor.encrypt(body);
                    body = encryptedBody;
                    count += propertiesEncryptedCount;
                    const { partitionKeyList: encryptedPartitionKeyList, encryptedCount } = await this.container.encryptionProcessor.getEncryptedPartitionKeyValue(this.partitionKey);
                    partitionKey = encryptedPartitionKeyList;
                    count += encryptedCount;
                    if (await this.container.encryptionProcessor.isPathEncrypted("/id")) {
                        url = await this.container.encryptionProcessor.getEncryptedUrl(this.url);
                        count++;
                    }
                    diagnosticNode.endEncryptionDiagnostics(Constants.Encryption.DiagnosticsEncryptOperation, count);
                }
                const path = getPathFromLink(url);
                const id = getIdFromLink(url);
                response = await this.clientContext.replace({
                    body,
                    path,
                    resourceType: exports.ResourceType.item,
                    resourceId: id,
                    options,
                    partitionKey: partitionKey,
                    diagnosticNode,
                });
            }
            catch (error) {
                if (this.clientContext.enableEncryption) {
                    await this.container.throwIfRequestNeedsARetryPostPolicyRefresh(error);
                }
                throw error;
            }
            if (this.clientContext.enableEncryption) {
                try {
                    // try block for decrypting response. This is done so that we can throw special error message in case of decryption failure
                    diagnosticNode.beginEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation);
                    const { body: result, propertiesDecryptedCount } = await this.container.encryptionProcessor.decrypt(response.result);
                    response.result = result;
                    diagnosticNode.endEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation, propertiesDecryptedCount);
                }
                catch (error) {
                    const decryptionError = new ErrorResponse(`Item replace operation was successful but response decryption failed: + ${error.message}`);
                    decryptionError.code = StatusCodes.ServiceUnavailable;
                    throw decryptionError;
                }
            }
            return new ItemResponse(response.result, response.headers, response.code, response.substatus, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * Delete the item.
     *
     * Any provided type, T, is not necessarily enforced by the SDK.
     * You may get more or less properties and it's up to your logic to enforce it.
     *
     * @param options - Additional options for the request
     */
    async delete(options = {}) {
        return withDiagnostics(async (diagnosticNode) => {
            this.partitionKey = await setPartitionKeyIfUndefined(diagnosticNode, this.container, this.partitionKey);
            let partitionKey = this.partitionKey;
            let url = this.url;
            let response;
            try {
                if (this.clientContext.enableEncryption) {
                    await this.container.checkAndInitializeEncryption();
                    options.containerRid = this.container._rid;
                    let count = 0;
                    diagnosticNode.beginEncryptionDiagnostics(Constants.Encryption.DiagnosticsEncryptOperation);
                    const { partitionKeyList, encryptedCount } = await this.container.encryptionProcessor.getEncryptedPartitionKeyValue(this.partitionKey);
                    partitionKey = partitionKeyList;
                    count += encryptedCount;
                    if (await this.container.encryptionProcessor.isPathEncrypted("/id")) {
                        url = await this.container.encryptionProcessor.getEncryptedUrl(this.url);
                        count++;
                    }
                    diagnosticNode.endEncryptionDiagnostics(Constants.Encryption.DiagnosticsEncryptOperation, count);
                }
                const path = getPathFromLink(url);
                const id = getIdFromLink(url);
                response = await this.clientContext.delete({
                    path,
                    resourceType: exports.ResourceType.item,
                    resourceId: id,
                    options,
                    partitionKey: partitionKey,
                    diagnosticNode,
                });
            }
            catch (error) {
                if (this.clientContext.enableEncryption) {
                    await this.container.throwIfRequestNeedsARetryPostPolicyRefresh(error);
                }
                throw error;
            }
            return new ItemResponse(response.result, response.headers, response.code, response.substatus, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * Perform a JSONPatch on the item.
     *
     * Any provided type, T, is not necessarily enforced by the SDK.
     * You may get more or less properties and it's up to your logic to enforce it.
     *
     * @param options - Additional options for the request
     */
    async patch(body, options = {}) {
        return withDiagnostics(async (diagnosticNode) => {
            this.partitionKey = await setPartitionKeyIfUndefined(diagnosticNode, this.container, this.partitionKey);
            let url = this.url;
            let partitionKey = this.partitionKey;
            let response;
            try {
                if (this.clientContext.enableEncryption) {
                    await this.container.checkAndInitializeEncryption();
                    options.containerRid = this.container._rid;
                    // returns copy to avoid encryption of original body passed
                    body = copyObject(body);
                    const operations = Array.isArray(body) ? body : body.operations;
                    diagnosticNode.beginEncryptionDiagnostics(Constants.Encryption.DiagnosticsEncryptOperation);
                    let propertiesEncryptedCount = 0;
                    for (const operation of operations) {
                        if (operation.op === PatchOperationType.remove) {
                            continue;
                        }
                        const isPathEncrypted = await this.container.encryptionProcessor.isPathEncrypted(operation.path);
                        if (!isPathEncrypted) {
                            continue;
                        }
                        if (operation.op === PatchOperationType.incr) {
                            throw new ErrorResponse(`Increment patch operation is not allowed for encrypted path '${operation.path}'`);
                        }
                        if ("value" in operation) {
                            operation.value = await this.container.encryptionProcessor.encryptProperty(operation.path, operation.value);
                        }
                        propertiesEncryptedCount++;
                    }
                    const { partitionKeyList, encryptedCount } = await this.container.encryptionProcessor.getEncryptedPartitionKeyValue(partitionKey);
                    partitionKey = partitionKeyList;
                    propertiesEncryptedCount += encryptedCount;
                    if (await this.container.encryptionProcessor.isPathEncrypted("/id")) {
                        url = await this.container.encryptionProcessor.getEncryptedUrl(this.url);
                        propertiesEncryptedCount++;
                    }
                    diagnosticNode.endEncryptionDiagnostics(Constants.Encryption.DiagnosticsEncryptOperation, propertiesEncryptedCount);
                }
                const path = getPathFromLink(url);
                const id = getIdFromLink(url);
                response = await this.clientContext.patch({
                    body,
                    path,
                    resourceType: exports.ResourceType.item,
                    resourceId: id,
                    options,
                    partitionKey: partitionKey,
                    diagnosticNode,
                });
            }
            catch (error) {
                if (this.clientContext.enableEncryption) {
                    await this.container.throwIfRequestNeedsARetryPostPolicyRefresh(error);
                }
                throw error;
            }
            if (this.clientContext.enableEncryption) {
                try {
                    diagnosticNode.beginEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation);
                    const { body: result, propertiesDecryptedCount } = await this.container.encryptionProcessor.decrypt(response.result);
                    response.result = result;
                    diagnosticNode.endEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation, propertiesDecryptedCount);
                }
                catch (error) {
                    const decryptionError = new ErrorResponse(`Item patch operation was successful but response decryption failed: + ${error.message}`);
                    decryptionError.code = StatusCodes.ServiceUnavailable;
                    throw decryptionError;
                }
            }
            return new ItemResponse(response.result, response.headers, response.code, response.substatus, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
}

/**
 * A single response page from the Azure Cosmos DB Change Feed
 */
class ChangeFeedResponse {
    /**
     * @internal
     */
    constructor(
    /**
     * Gets the items returned in the response from Azure Cosmos DB
     */
    result, 
    /**
     * Gets the number of items returned in the response from Azure Cosmos DB
     */
    count, 
    /**
     * Gets the status code of the response from Azure Cosmos DB
     */
    statusCode, headers, diagnostics) {
        this.result = result;
        this.count = count;
        this.statusCode = statusCode;
        this.diagnostics = diagnostics;
        this.headers = Object.freeze(headers);
    }
    /**
     * Gets the request charge for this request from the Azure Cosmos DB service.
     */
    get requestCharge() {
        const rus = this.headers[Constants.HttpHeaders.RequestCharge];
        return rus ? parseInt(rus, 10) : null;
    }
    /**
     * Gets the activity ID for the request from the Azure Cosmos DB service.
     */
    get activityId() {
        return this.headers[Constants.HttpHeaders.ActivityId];
    }
    /**
     * Gets the continuation token to be used for continuing enumeration of the Azure Cosmos DB service.
     *
     * This is equivalent to the `etag` property.
     */
    get continuation() {
        return this.etag;
    }
    /**
     * Gets the session token for use in session consistency reads from the Azure Cosmos DB service.
     */
    get sessionToken() {
        return this.headers[Constants.HttpHeaders.SessionToken];
    }
    /**
     * Gets the entity tag associated with last transaction in the Azure Cosmos DB service,
     * which can be used as If-Non-Match Access condition for ReadFeed REST request or
     * `continuation` property of `ChangeFeedOptions` parameter for
     * `Items.changeFeed()`
     * to get feed changes since the transaction specified by this entity tag.
     *
     * This is equivalent to the `continuation` property.
     */
    get etag() {
        return this.headers[Constants.HttpHeaders.ETag];
    }
}

/**
 * Provides iterator for change feed.
 *
 * Use `Items.changeFeed()` to get an instance of the iterator.
 */
class ChangeFeedIterator {
    /**
     * @internal
     */
    constructor(clientContext, resourceId, resourceLink, partitionKey, changeFeedOptions) {
        this.clientContext = clientContext;
        this.resourceId = resourceId;
        this.resourceLink = resourceLink;
        this.partitionKey = partitionKey;
        this.changeFeedOptions = changeFeedOptions;
        // partition key XOR partition key range id
        const partitionKeyValid = partitionKey !== undefined;
        this.isPartitionSpecified = partitionKeyValid;
        let canUseStartFromBeginning = true;
        if (changeFeedOptions.continuation) {
            this.nextIfNoneMatch = changeFeedOptions.continuation;
            canUseStartFromBeginning = false;
        }
        if (changeFeedOptions.startTime) {
            // .toUTCString() is platform specific, but most platforms use RFC 1123.
            // In ECMAScript 2018, this was standardized to RFC 1123.
            // See for more info: https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Date/toUTCString
            this.ifModifiedSince = changeFeedOptions.startTime.toUTCString();
            canUseStartFromBeginning = false;
        }
        if (canUseStartFromBeginning && !changeFeedOptions.startFromBeginning) {
            this.nextIfNoneMatch = ChangeFeedIterator.IfNoneMatchAllHeaderValue;
        }
    }
    /**
     * Gets a value indicating whether there are potentially additional results that can be retrieved.
     *
     * Initially returns true. This value is set based on whether the last execution returned a continuation token.
     *
     * @returns Boolean value representing if whether there are potentially additional results that can be retrieved.
     */
    get hasMoreResults() {
        return this.lastStatusCode !== StatusCodes.NotModified;
    }
    /**
     * Gets an async iterator which will yield pages of results from Azure Cosmos DB.
     */
    getAsyncIterator() {
        return tslib.__asyncGenerator(this, arguments, function* getAsyncIterator_1() {
            do {
                const result = yield tslib.__await(this.fetchNext());
                if (result.count > 0) {
                    yield yield tslib.__await(result);
                }
            } while (this.hasMoreResults);
        });
    }
    /**
     * Read feed and retrieves the next page of results in Azure Cosmos DB.
     */
    async fetchNext() {
        return withDiagnostics(async (diagnosticNode) => {
            const response = await this.getFeedResponse(diagnosticNode);
            this.lastStatusCode = response.statusCode;
            this.nextIfNoneMatch = response.headers[Constants.HttpHeaders.ETag];
            return response;
        }, this.clientContext);
    }
    async getFeedResponse(diagnosticNode) {
        if (!this.isPartitionSpecified) {
            throw new Error("Container is partitioned, but no partition key or partition key range id was specified.");
        }
        const feedOptions = { initialHeaders: {}, useIncrementalFeed: true };
        if (typeof this.changeFeedOptions.maxItemCount === "number") {
            feedOptions.maxItemCount = this.changeFeedOptions.maxItemCount;
        }
        if (this.changeFeedOptions.sessionToken) {
            feedOptions.sessionToken = this.changeFeedOptions.sessionToken;
        }
        if (this.nextIfNoneMatch) {
            feedOptions.accessCondition = {
                type: Constants.HttpHeaders.IfNoneMatch,
                condition: this.nextIfNoneMatch,
            };
        }
        if (this.ifModifiedSince) {
            feedOptions.initialHeaders[Constants.HttpHeaders.IfModifiedSince] = this.ifModifiedSince;
        }
        const response = await this.clientContext.queryFeed({
            path: this.resourceLink,
            resourceType: exports.ResourceType.item,
            resourceId: this.resourceId,
            resultFn: (result) => (result ? result.Documents : []),
            query: undefined,
            options: feedOptions,
            partitionKey: this.partitionKey,
            diagnosticNode: diagnosticNode,
        }); // TODO: some funky issues with query feed. Probably need to change it up.
        return new ChangeFeedResponse(response.result, response.result ? response.result.length : 0, response.code, response.headers, getEmptyCosmosDiagnostics());
    }
}
ChangeFeedIterator.IfNoneMatchAllHeaderValue = "*";

/**
 * Generate Hash for a `Multi Hash` type partition.
 * @param partitionKey - to be hashed.
 * @returns
 */
function hashMultiHashPartitionKey(partitionKey) {
    return partitionKey.map((keys) => hashV2PartitionKey([keys])).join("");
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
function writeStringForBinaryEncoding(payload) {
    let outputStream = Buffer.from(BytePrefix.String, "hex");
    const MAX_STRING_BYTES_TO_APPEND = 100;
    const byteArray = [...Buffer.from(payload)];
    const isShortString = payload.length <= MAX_STRING_BYTES_TO_APPEND;
    for (let index = 0; index < (isShortString ? byteArray.length : MAX_STRING_BYTES_TO_APPEND + 1); index++) {
        let charByte = byteArray[index];
        if (charByte < 0xff) {
            charByte++;
        }
        outputStream = Buffer.concat([outputStream, Buffer.from(charByte.toString(16), "hex")]);
    }
    if (isShortString) {
        outputStream = Buffer.concat([outputStream, Buffer.from(BytePrefix.Undefined, "hex")]);
    }
    return outputStream;
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
const MAX_STRING_CHARS = 100;
function hashV1PartitionKey(partitionKey) {
    const key = partitionKey[0];
    const toHash = prefixKeyByType(key);
    const hash = MurmurHash.x86.hash32(toHash);
    const encodedJSBI = writeNumberForBinaryEncodingJSBI(hash);
    const encodedValue = encodeByType(key);
    const finalHash = Buffer.concat([encodedJSBI, encodedValue]).toString("hex").toUpperCase();
    return finalHash;
}
function prefixKeyByType(key) {
    let bytes;
    switch (typeof key) {
        case "string": {
            const truncated = key.substr(0, MAX_STRING_CHARS);
            bytes = Buffer.concat([
                Buffer.from(BytePrefix.String, "hex"),
                Buffer.from(truncated),
                Buffer.from(BytePrefix.Undefined, "hex"),
            ]);
            return bytes;
        }
        case "number": {
            const numberBytes = doubleToByteArrayJSBI(key);
            bytes = Buffer.concat([Buffer.from(BytePrefix.Number, "hex"), numberBytes]);
            return bytes;
        }
        case "boolean": {
            const prefix = key ? BytePrefix.True : BytePrefix.False;
            return Buffer.from(prefix, "hex");
        }
        case "object": {
            if (key === null) {
                return Buffer.from(BytePrefix.Null, "hex");
            }
            return Buffer.from(BytePrefix.Undefined, "hex");
        }
        case "undefined": {
            return Buffer.from(BytePrefix.Undefined, "hex");
        }
        default:
            throw new Error(`Unexpected type: ${typeof key}`);
    }
}
function encodeByType(key) {
    switch (typeof key) {
        case "string": {
            const truncated = key.substr(0, MAX_STRING_CHARS);
            return writeStringForBinaryEncoding(truncated);
        }
        case "number": {
            const encodedJSBI = writeNumberForBinaryEncodingJSBI(key);
            return encodedJSBI;
        }
        case "boolean": {
            const prefix = key ? BytePrefix.True : BytePrefix.False;
            return Buffer.from(prefix, "hex");
        }
        case "object":
            if (key === null) {
                return Buffer.from(BytePrefix.Null, "hex");
            }
            return Buffer.from(BytePrefix.Undefined, "hex");
        case "undefined":
            return Buffer.from(BytePrefix.Undefined, "hex");
        default:
            throw new Error(`Unexpected type: ${typeof key}`);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Generate hash of a PartitonKey based on it PartitionKeyDefinition.
 * @param partitionKey - to be hashed.
 * @param partitionDefinition - container's partitionKey definition
 * @returns
 */
function hashPartitionKey(partitionKey, partitionDefinition) {
    const kind = (partitionDefinition === null || partitionDefinition === void 0 ? void 0 : partitionDefinition.kind) || exports.PartitionKeyKind.Hash; // Default value.
    const isV2 = partitionDefinition &&
        partitionDefinition.version &&
        partitionDefinition.version === exports.PartitionKeyDefinitionVersion.V2;
    switch (kind) {
        case exports.PartitionKeyKind.Hash:
            return isV2 ? hashV2PartitionKey(partitionKey) : hashV1PartitionKey(partitionKey);
        case exports.PartitionKeyKind.MultiHash:
            return hashMultiHashPartitionKey(partitionKey);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @internal
 * Provides the iterator for handling encrypted items in the Azure Cosmos DB database service.
 * extends @see {@link QueryIterator}
 */
class EncryptionItemQueryIterator extends QueryIterator {
    constructor(clientContext, query, options, fetchFunctions, container) {
        super(clientContext, query, options, fetchFunctions, container.url, exports.ResourceType.item);
        this.container = container;
        this.encryptionClientContext = clientContext;
        this.encryptionOptions = options;
    }
    /**
     * Gets an async iterator that will yield results until completion.
     */
    getAsyncIterator() {
        return tslib.__asyncGenerator(this, arguments, function* getAsyncIterator_1() {
            var _a;
            let response;
            const diagnosticNode = new DiagnosticNodeInternal(this.encryptionClientContext.diagnosticLevel, exports.DiagnosticNodeType.CLIENT_REQUEST_NODE, null);
            try {
                response = yield tslib.__await(yield* tslib.__asyncDelegator(tslib.__asyncValues(QueryIterator.prototype.getAsyncIteratorInternal.call(this, diagnosticNode))));
            }
            catch (error) {
                yield tslib.__await(this.container.throwIfRequestNeedsARetryPostPolicyRefresh(error));
            }
            if (((_a = response === null || response === void 0 ? void 0 : response.resources) === null || _a === void 0 ? void 0 : _a.length) > 0) {
                let count = 0;
                diagnosticNode.beginEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation);
                for (let resource of response.resources) {
                    const { body, propertiesDecryptedCount } = yield tslib.__await(this.container.encryptionProcessor.decrypt(resource));
                    resource = body;
                    count += propertiesDecryptedCount;
                }
                diagnosticNode.endEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation, count);
            }
            yield yield tslib.__await(response);
        });
    }
    /**
     * Fetch all pages for the query and return a single FeedResponse.
     */
    async fetchAll() {
        return withDiagnostics(async (diagnosticNode) => {
            var _a;
            let response;
            try {
                response = await QueryIterator.prototype.fetchAllInternal.call(this, diagnosticNode);
            }
            catch (error) {
                await this.container.throwIfRequestNeedsARetryPostPolicyRefresh(error);
            }
            if (((_a = response === null || response === void 0 ? void 0 : response.resources) === null || _a === void 0 ? void 0 : _a.length) > 0) {
                let count = 0;
                diagnosticNode.beginEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation);
                for (let resource of response.resources) {
                    const { body, propertiesDecryptedCount } = await this.container.encryptionProcessor.decrypt(resource);
                    resource = body;
                    count += propertiesDecryptedCount;
                }
                diagnosticNode.endEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation, count);
            }
            return response;
        }, this.encryptionClientContext);
    }
    /**
     * Retrieve the next batch from the feed.
     */
    async fetchNext() {
        return withDiagnostics(async (diagnosticNode) => {
            var _a;
            let response;
            try {
                response = await QueryIterator.prototype.fetchNextInternal.call(this, diagnosticNode);
            }
            catch (error) {
                await this.container.throwIfRequestNeedsARetryPostPolicyRefresh(error);
            }
            if (((_a = response === null || response === void 0 ? void 0 : response.resources) === null || _a === void 0 ? void 0 : _a.length) > 0) {
                let count = 0;
                diagnosticNode.beginEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation);
                for (let resource of response.resources) {
                    const { body, propertiesDecryptedCount } = await this.container.encryptionProcessor.decrypt(resource);
                    resource = body;
                    count += propertiesDecryptedCount;
                }
                diagnosticNode.endEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation, count);
            }
            return response;
        }, this.encryptionClientContext);
    }
    /**
     * @internal
     */
    async init(diagnosticNode) {
        // Ensure encryption is initialized and set rid in options
        await this.container.checkAndInitializeEncryption();
        this.encryptionOptions.containerRid = this.container._rid;
        await QueryIterator.prototype.init.call(this, diagnosticNode);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @hidden
 */
function isChangeFeedOptions(options) {
    return options && !(isPrimitivePartitionKeyValue(options) || Array.isArray(options));
}
/**
 * Operations for creating new items, and reading/querying all items
 *
 * @see {@link Item} for reading, replacing, or deleting an existing container; use `.item(id)`.
 */
class Items {
    /**
     * Create an instance of {@link Items} linked to the parent {@link Container}.
     * @param container - The parent container.
     * @hidden
     */
    constructor(container, clientContext) {
        this.container = container;
        this.clientContext = clientContext;
        this.partitionKeyRangeCache = new PartitionKeyRangeCache(this.clientContext);
    }
    query(query, options = {}) {
        const path = getPathFromLink(this.container.url, exports.ResourceType.item);
        const id = getIdFromLink(this.container.url);
        const fetchFunction = async (diagnosticNode, innerOptions, correlatedActivityId) => {
            const response = await this.clientContext.queryFeed({
                path,
                resourceType: exports.ResourceType.item,
                resourceId: id,
                resultFn: (result) => (result ? result.Documents : []),
                query,
                options: innerOptions,
                partitionKey: options.partitionKey,
                diagnosticNode,
                correlatedActivityId: correlatedActivityId,
            });
            return response;
        };
        let iterator;
        if (this.clientContext.enableEncryption) {
            iterator = new EncryptionItemQueryIterator(this.clientContext, query, options, fetchFunction, this.container);
        }
        else {
            iterator = new QueryIterator(this.clientContext, query, options, fetchFunction, this.container.url, exports.ResourceType.item);
        }
        return iterator;
    }
    /**
     * Queries all items in an encrypted container.
     * @param queryBuilder - Query configuration for the operation. See {@link SqlQuerySpec} for more info on how to build a query on encrypted properties.
     * @param options - Used for modifying the request (for instance, specifying the partition key).
     * @example Read all items to array.
     * ```typescript
     * const queryBuilder = new EncryptionQueryBuilder("SELECT firstname FROM Families f WHERE f.lastName = @lastName");
     * queryBuilder.addStringParameter("@lastName", "Hendricks", "/lastname");
     * const queryIterator = await items.getEncryptionQueryIterator<{firstName: string}>(queryBuilder);
     * const {result: items} = await queryIterator.fetchAll();
     * ```
     */
    async getEncryptionQueryIterator(queryBuilder, options = {}) {
        const encryptionSqlQuerySpec = queryBuilder.toEncryptionSqlQuerySpec();
        const sqlQuerySpec = await this.buildSqlQuerySpec(encryptionSqlQuerySpec);
        const iterator = this.query(sqlQuerySpec, options);
        return iterator;
    }
    async buildSqlQuerySpec(encryptionSqlQuerySpec) {
        let encryptionParameters = encryptionSqlQuerySpec.parameters;
        const sqlQuerySpec = {
            query: encryptionSqlQuerySpec.query,
            parameters: [],
        };
        // returns copy to avoid encryption of original parameters passed
        encryptionParameters = copyObject(encryptionParameters);
        for (const parameter of encryptionParameters) {
            let value;
            if (parameter.type !== undefined || parameter.type !== TypeMarker.Null) {
                value = await this.container.encryptionProcessor.encryptQueryParameter(parameter.path, parameter.value, parameter.path === "/id", parameter.type);
            }
            sqlQuerySpec.parameters.push({ name: parameter.name, value: value });
        }
        return sqlQuerySpec;
    }
    readChangeFeed(partitionKeyOrChangeFeedOptions, changeFeedOptions) {
        if (isChangeFeedOptions(partitionKeyOrChangeFeedOptions)) {
            return this.changeFeed(partitionKeyOrChangeFeedOptions);
        }
        else {
            return this.changeFeed(partitionKeyOrChangeFeedOptions, changeFeedOptions);
        }
    }
    changeFeed(partitionKeyOrChangeFeedOptions, changeFeedOptions) {
        let partitionKey;
        if (!changeFeedOptions && isChangeFeedOptions(partitionKeyOrChangeFeedOptions)) {
            partitionKey = undefined;
            changeFeedOptions = partitionKeyOrChangeFeedOptions;
        }
        else if (partitionKeyOrChangeFeedOptions !== undefined &&
            !isChangeFeedOptions(partitionKeyOrChangeFeedOptions)) {
            partitionKey = partitionKeyOrChangeFeedOptions;
        }
        if (!changeFeedOptions) {
            changeFeedOptions = {};
        }
        const path = getPathFromLink(this.container.url, exports.ResourceType.item);
        const id = getIdFromLink(this.container.url);
        return new ChangeFeedIterator(this.clientContext, id, path, partitionKey, changeFeedOptions);
    }
    /**
     * Returns an iterator to iterate over pages of changes. The iterator returned can be used to fetch changes for a single partition key, feed range or an entire container.
     */
    getChangeFeedIterator(changeFeedIteratorOptions) {
        const cfOptions = changeFeedIteratorOptions !== undefined ? changeFeedIteratorOptions : {};
        validateChangeFeedIteratorOptions(cfOptions);
        const iterator = new ChangeFeedIteratorBuilder(cfOptions, this.clientContext, this.container, this.partitionKeyRangeCache);
        return iterator;
    }
    readAll(options) {
        return this.query("SELECT * from c", options);
    }
    /**
     * Create an item.
     *
     * Any provided type, T, is not necessarily enforced by the SDK.
     * You may get more or less properties and it's up to your logic to enforce it.
     *
     * There is no set schema for JSON items. They may contain any number of custom properties.
     *
     * @param body - Represents the body of the item. Can contain any number of user defined properties.
     * @param options - Used for modifying the request (for instance, specifying the partition key).
     */
    async create(body, options = {}) {
        // Generate random document id if the id is missing in the payload and
        // options.disableAutomaticIdGeneration != true
        return withDiagnostics(async (diagnosticNode) => {
            if ((body.id === undefined || body.id === "") && !options.disableAutomaticIdGeneration) {
                body.id = coreUtil.randomUUID();
            }
            const partitionKeyDefinition = await readPartitionKeyDefinition(diagnosticNode, this.container);
            let partitionKey = extractPartitionKeys(body, partitionKeyDefinition);
            let response;
            try {
                if (this.clientContext.enableEncryption) {
                    await this.container.checkAndInitializeEncryption();
                    options.containerRid = this.container._rid;
                    // returns copy to avoid encryption of original body passed
                    body = copyObject(body);
                    diagnosticNode.beginEncryptionDiagnostics(Constants.Encryption.DiagnosticsEncryptOperation);
                    const { body: encryptedBody, propertiesEncryptedCount } = await this.container.encryptionProcessor.encrypt(body);
                    body = encryptedBody;
                    diagnosticNode.endEncryptionDiagnostics(Constants.Encryption.DiagnosticsEncryptOperation, propertiesEncryptedCount);
                    partitionKey = extractPartitionKeys(body, partitionKeyDefinition);
                }
                const err = {};
                if (!isItemResourceValid(body, err)) {
                    throw err;
                }
                const path = getPathFromLink(this.container.url, exports.ResourceType.item);
                const id = getIdFromLink(this.container.url);
                response = await this.clientContext.create({
                    body,
                    path,
                    resourceType: exports.ResourceType.item,
                    resourceId: id,
                    diagnosticNode,
                    options,
                    partitionKey,
                });
            }
            catch (error) {
                if (this.clientContext.enableEncryption) {
                    // Todo: internally retry post policy refresh
                    await this.container.throwIfRequestNeedsARetryPostPolicyRefresh(error);
                }
                throw error;
            }
            if (this.clientContext.enableEncryption) {
                // try block for decrypting response. This is done so that we can throw special error message in case of decryption failure
                try {
                    diagnosticNode.beginEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation);
                    const { body: decryptedResult, propertiesDecryptedCount } = await this.container.encryptionProcessor.decrypt(response.result);
                    diagnosticNode.endEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation, propertiesDecryptedCount);
                    response.result = decryptedResult;
                    partitionKey = extractPartitionKeys(response.result, partitionKeyDefinition);
                }
                catch (error) {
                    const decryptionError = new ErrorResponse(`Item creation was successful but response decryption failed: + ${error.message}`);
                    decryptionError.code = StatusCodes.ServiceUnavailable;
                    throw decryptionError;
                }
            }
            const ref = new Item(this.container, response.result.id, this.clientContext, partitionKey);
            return new ItemResponse(response.result, response.headers, response.code, response.substatus, ref, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    async upsert(body, options = {}) {
        return withDiagnostics(async (diagnosticNode) => {
            // Generate random document id if the id is missing in the payload and
            // options.disableAutomaticIdGeneration != true
            if ((body.id === undefined || body.id === "") && !options.disableAutomaticIdGeneration) {
                body.id = coreUtil.randomUUID();
            }
            const partitionKeyDefinition = await readPartitionKeyDefinition(diagnosticNode, this.container);
            let partitionKey = extractPartitionKeys(body, partitionKeyDefinition);
            let response;
            try {
                if (this.clientContext.enableEncryption) {
                    // returns copy to avoid encryption of original body passed
                    body = copyObject(body);
                    options = options || {};
                    await this.container.checkAndInitializeEncryption();
                    options.containerRid = this.container._rid;
                    diagnosticNode.beginEncryptionDiagnostics(Constants.Encryption.DiagnosticsEncryptOperation);
                    const { body: encryptedBody, propertiesEncryptedCount } = await this.container.encryptionProcessor.encrypt(body);
                    body = encryptedBody;
                    diagnosticNode.endEncryptionDiagnostics(Constants.Encryption.DiagnosticsEncryptOperation, propertiesEncryptedCount);
                    partitionKey = extractPartitionKeys(body, partitionKeyDefinition);
                }
                const err = {};
                if (!isItemResourceValid(body, err)) {
                    throw err;
                }
                const path = getPathFromLink(this.container.url, exports.ResourceType.item);
                const id = getIdFromLink(this.container.url);
                response = await this.clientContext.upsert({
                    body,
                    path,
                    resourceType: exports.ResourceType.item,
                    resourceId: id,
                    options,
                    partitionKey,
                    diagnosticNode,
                });
            }
            catch (error) {
                if (this.clientContext.enableEncryption) {
                    await this.container.throwIfRequestNeedsARetryPostPolicyRefresh(error);
                }
                throw error;
            }
            if (this.clientContext.enableEncryption) {
                try {
                    // try block for decrypting response. This is done so that we can throw special error message in case of decryption failure
                    diagnosticNode.beginEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation);
                    const { body: decryptedResult, propertiesDecryptedCount } = await this.container.encryptionProcessor.decrypt(response.result);
                    diagnosticNode.endEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation, propertiesDecryptedCount);
                    response.result = decryptedResult;
                    partitionKey = extractPartitionKeys(response.result, partitionKeyDefinition);
                }
                catch (error) {
                    const decryptionError = new ErrorResponse(`Item upsert was successful but response decryption failed: + ${error.message}`);
                    decryptionError.code = StatusCodes.ServiceUnavailable;
                    throw decryptionError;
                }
            }
            const ref = new Item(this.container, response.result.id, this.clientContext, partitionKey);
            return new ItemResponse(response.result, response.headers, response.code, response.substatus, ref, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * Execute bulk operations on items.
     *
     * Bulk takes an array of Operations which are typed based on what the operation does.
     * The choices are: Create, Upsert, Read, Replace, and Delete
     *
     * Usage example:
     * ```typescript
     * // partitionKey is optional at the top level if present in the resourceBody
     * const operations: OperationInput[] = [
     *    {
     *       operationType: "Create",
     *       resourceBody: { id: "doc1", name: "sample", key: "A" }
     *    },
     *    {
     *       operationType: "Upsert",
     *       partitionKey: 'A',
     *       resourceBody: { id: "doc2", name: "other", key: "A" }
     *    }
     * ]
     *
     * await database.container.items.bulk(operations)
     * ```
     *
     * @param operations - List of operations. Limit 100
     * @param bulkOptions - Optional options object to modify bulk behavior. Pass \{ continueOnError: false \} to stop executing operations when one fails. (Defaults to true)
     * @param options - Used for modifying the request.
     */
    async bulk(operations, bulkOptions, options) {
        return withDiagnostics(async (diagnosticNode) => {
            const partitionKeyRanges = (await this.partitionKeyRangeCache.onCollectionRoutingMap(this.container.url, diagnosticNode)).getOrderedParitionKeyRanges();
            const partitionKeyDefinition = await readPartitionKeyDefinition(diagnosticNode, this.container);
            if (this.clientContext.enableEncryption) {
                // returns copy to avoid encryption of original operations body passed
                operations = copyObject(operations);
                options = options || {};
                await this.container.checkAndInitializeEncryption();
                options.containerRid = this.container._rid;
                diagnosticNode.beginEncryptionDiagnostics(Constants.Encryption.DiagnosticsEncryptOperation);
                const { operations: encryptedOperations, totalPropertiesEncryptedCount } = await this.bulkBatchEncryptionHelper(operations);
                operations = encryptedOperations;
                diagnosticNode.endEncryptionDiagnostics(Constants.Encryption.DiagnosticsEncryptOperation, totalPropertiesEncryptedCount);
            }
            const batches = partitionKeyRanges.map((keyRange) => {
                return {
                    min: keyRange.minInclusive,
                    max: keyRange.maxExclusive,
                    rangeId: keyRange.id,
                    indexes: [],
                    operations: [],
                };
            });
            this.groupOperationsBasedOnPartitionKey(operations, partitionKeyDefinition, options, batches);
            const path = getPathFromLink(this.container.url, exports.ResourceType.item);
            const orderedResponses = [];
            // split batches based on cumulative size of operations
            const batchMap = batches
                .filter((batch) => batch.operations.length)
                .flatMap((batch) => splitBatchBasedOnBodySize(batch));
            await Promise.all(this.executeBatchOperations(batchMap, path, bulkOptions, options, diagnosticNode, orderedResponses, partitionKeyDefinition));
            const response = orderedResponses;
            response.diagnostics = diagnosticNode.toDiagnostic(this.clientContext.getClientConfig());
            return response;
        }, this.clientContext);
    }
    executeBatchOperations(batchMap, path, bulkOptions, options, diagnosticNode, orderedResponses, partitionKeyDefinition) {
        return batchMap.map(async (batch) => {
            if (batch.operations.length > 100) {
                throw new Error("Cannot run bulk request with more than 100 operations per partition");
            }
            let response;
            try {
                response = await addDignosticChild(async (childNode) => this.clientContext.bulk({
                    body: batch.operations,
                    partitionKeyRangeId: batch.rangeId,
                    path,
                    resourceId: this.container.url,
                    bulkOptions,
                    options,
                    diagnosticNode: childNode,
                }), diagnosticNode, exports.DiagnosticNodeType.BATCH_REQUEST);
                response.result.forEach((operationResponse, index) => {
                    orderedResponses[batch.indexes[index]] = operationResponse;
                });
            }
            catch (err) {
                if (this.clientContext.enableEncryption) {
                    await this.container.throwIfRequestNeedsARetryPostPolicyRefresh(err);
                }
                // In the case of 410 errors, we need to recompute the partition key ranges
                // and redo the batch request, however, 410 errors occur for unsupported
                // partition key types as well since we don't support them, so for now we throw
                if (err.code === StatusCodes.Gone) {
                    const isPartitionSplit = err.substatus === SubStatusCodes.PartitionKeyRangeGone ||
                        err.substatus === SubStatusCodes.CompletingSplit;
                    if (isPartitionSplit) {
                        const queryRange = new QueryRange(batch.min, batch.max, true, false);
                        const overlappingRanges = await this.partitionKeyRangeCache.getOverlappingRanges(this.container.url, queryRange, diagnosticNode, true);
                        if (overlappingRanges.length < 1) {
                            throw new Error("Partition split/merge detected but no overlapping ranges found.");
                        }
                        // Handles both merge (overlappingRanges.length === 1) and split (overlappingRanges.length > 1) cases.
                        if (overlappingRanges.length >= 1) {
                            // const splitBatches: Batch[] = [];
                            const newBatches = this.createNewBatches(overlappingRanges, batch, partitionKeyDefinition);
                            await Promise.all(this.executeBatchOperations(newBatches, path, bulkOptions, options, diagnosticNode, orderedResponses, partitionKeyDefinition));
                        }
                    }
                    else {
                        throw new Error("Partition key error. An operation has an unsupported partitionKey type" +
                            err.message);
                    }
                }
                else {
                    throw new Error(`Bulk request errored with: ${err.message}`);
                }
            }
            if (response) {
                try {
                    if (this.clientContext.enableEncryption) {
                        diagnosticNode.beginEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation);
                        let count = 0;
                        for (const result of response.result) {
                            if (result.resourceBody) {
                                const { body, propertiesDecryptedCount } = await this.container.encryptionProcessor.decrypt(result.resourceBody);
                                result.resourceBody = body;
                                count += propertiesDecryptedCount;
                            }
                        }
                        diagnosticNode.endEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation, count);
                    }
                }
                catch (error) {
                    const decryptionError = new ErrorResponse(`Batch response was received but response decryption failed: + ${error.message}`);
                    decryptionError.code = StatusCodes.ServiceUnavailable;
                    throw decryptionError;
                }
                response.result.forEach((operationResponse, index) => {
                    orderedResponses[batch.indexes[index]] = operationResponse;
                });
            }
        });
    }
    /**
     * Function to create new batches based of partition key Ranges.
     *
     * @param overlappingRanges - Overlapping partition key ranges.
     * @param batch - Batch to be split.
     * @param partitionKeyDefinition - PartitionKey definition of container.
     * @returns Array of new batches.
     */
    createNewBatches(overlappingRanges, batch, partitionKeyDefinition) {
        const newBatches = overlappingRanges.map((keyRange) => {
            return {
                min: keyRange.minInclusive,
                max: keyRange.maxExclusive,
                rangeId: keyRange.id,
                indexes: [],
                operations: [],
            };
        });
        let indexValue = 0;
        batch.operations.forEach((operation) => {
            const partitionKey = JSON.parse(operation.partitionKey);
            const hashed = hashPartitionKey(assertNotUndefined(partitionKey, "undefined value for PartitionKey is not expected during grouping of bulk operations."), partitionKeyDefinition);
            const batchForKey = assertNotUndefined(newBatches.find((newBatch) => {
                return isKeyInRange(newBatch.min, newBatch.max, hashed);
            }), "No suitable Batch found.");
            batchForKey.operations.push(operation);
            batchForKey.indexes.push(batch.indexes[indexValue]);
            indexValue++;
        });
        return newBatches;
    }
    /**
     * Function to create batches based of partition key Ranges.
     * @param operations - operations to group
     * @param partitionDefinition - PartitionKey definition of container.
     * @param options - Request options for bulk request.
     * @param batches - Groups to be filled with operations.
     */
    groupOperationsBasedOnPartitionKey(operations, partitionDefinition, options, batches) {
        operations.forEach((operationInput, index) => {
            const { operation, partitionKey } = prepareOperations(operationInput, partitionDefinition, options);
            const hashed = hashPartitionKey(assertNotUndefined(partitionKey, "undefined value for PartitionKey is not expected during grouping of bulk operations."), partitionDefinition);
            const batchForKey = assertNotUndefined(batches.find((batch) => {
                return isKeyInRange(batch.min, batch.max, hashed);
            }), "No suitable Batch found.");
            batchForKey.operations.push(operation);
            batchForKey.indexes.push(index);
        });
    }
    /**
     * Execute transactional batch operations on items.
     *
     * Batch takes an array of Operations which are typed based on what the operation does. Batch is transactional and will rollback all operations if one fails.
     * The choices are: Create, Upsert, Read, Replace, and Delete
     *
     * Usage example:
     * ```typescript
     * // The partitionKey is a required second argument. If its undefined, it defaults to the expected partition key format.
     * const operations: OperationInput[] = [
     *    {
     *       operationType: "Create",
     *       resourceBody: { id: "doc1", name: "sample", key: "A" }
     *    },
     *    {
     *       operationType: "Upsert",
     *       resourceBody: { id: "doc2", name: "other", key: "A" }
     *    }
     * ]
     *
     * await database.container.items.batch(operations, "A")
     * ```
     *
     * @param operations - List of operations. Limit 100
     * @param options - Used for modifying the request
     */
    async batch(operations, partitionKey, options) {
        return withDiagnostics(async (diagnosticNode) => {
            operations.map((operation) => decorateBatchOperation(operation, options));
            partitionKey = await setPartitionKeyIfUndefined(diagnosticNode, this.container, partitionKey);
            const path = getPathFromLink(this.container.url, exports.ResourceType.item);
            if (operations.length > 100) {
                throw new Error("Cannot run batch request with more than 100 operations per partition");
            }
            let response;
            try {
                if (this.clientContext.enableEncryption) {
                    // returns copy to avoid encryption of original operations body passed
                    operations = copyObject(operations);
                    options = options || {};
                    await this.container.checkAndInitializeEncryption();
                    options.containerRid = this.container._rid;
                    let count = 0;
                    diagnosticNode.beginEncryptionDiagnostics(Constants.Encryption.DiagnosticsEncryptOperation);
                    if (partitionKey) {
                        const partitionKeyInternal = convertToInternalPartitionKey(partitionKey);
                        const { partitionKeyList, encryptedCount } = await this.container.encryptionProcessor.getEncryptedPartitionKeyValue(partitionKeyInternal);
                        partitionKey = partitionKeyList;
                        count += encryptedCount;
                    }
                    const { operations: encryptedOperations, totalPropertiesEncryptedCount } = await this.bulkBatchEncryptionHelper(operations);
                    operations = encryptedOperations;
                    count += totalPropertiesEncryptedCount;
                    diagnosticNode.endEncryptionDiagnostics(Constants.Encryption.DiagnosticsEncryptOperation, count);
                }
                response = await this.clientContext.batch({
                    body: operations,
                    partitionKey,
                    path,
                    resourceId: this.container.url,
                    options,
                    diagnosticNode,
                });
            }
            catch (err) {
                if (this.clientContext.enableEncryption) {
                    await this.container.throwIfRequestNeedsARetryPostPolicyRefresh(err);
                }
                throw new Error(`Batch request error: ${err.message}`);
            }
            if (this.clientContext.enableEncryption) {
                try {
                    diagnosticNode.beginEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation);
                    let count = 0;
                    for (const result of response.result) {
                        if (result.resourceBody) {
                            const { body, propertiesDecryptedCount } = await this.container.encryptionProcessor.decrypt(result.resourceBody);
                            result.resourceBody = body;
                            count += propertiesDecryptedCount;
                        }
                    }
                    diagnosticNode.endEncryptionDiagnostics(Constants.Encryption.DiagnosticsDecryptOperation, count);
                }
                catch (error) {
                    const decryptionError = new ErrorResponse(`Batch response was received but response decryption failed: + ${error.message}`);
                    decryptionError.code = StatusCodes.ServiceUnavailable;
                    throw decryptionError;
                }
            }
            return response;
        }, this.clientContext);
    }
    async bulkBatchEncryptionHelper(operations) {
        let totalPropertiesEncryptedCount = 0;
        for (const operation of operations) {
            if (Object.prototype.hasOwnProperty.call(operation, "partitionKey")) {
                const partitionKeyInternal = convertToInternalPartitionKey(operation.partitionKey);
                const { partitionKeyList, encryptedCount } = await this.container.encryptionProcessor.getEncryptedPartitionKeyValue(partitionKeyInternal);
                operation.partitionKey = partitionKeyList;
                totalPropertiesEncryptedCount += encryptedCount;
            }
            switch (operation.operationType) {
                case BulkOperationType.Create:
                case BulkOperationType.Upsert: {
                    const { body, propertiesEncryptedCount } = await this.container.encryptionProcessor.encrypt(operation.resourceBody);
                    operation.resourceBody = body;
                    totalPropertiesEncryptedCount += propertiesEncryptedCount;
                    break;
                }
                case BulkOperationType.Read:
                case BulkOperationType.Delete:
                    if (await this.container.encryptionProcessor.isPathEncrypted("/id")) {
                        operation.id = await this.container.encryptionProcessor.getEncryptedId(operation.id);
                        totalPropertiesEncryptedCount++;
                    }
                    break;
                case BulkOperationType.Replace: {
                    if (await this.container.encryptionProcessor.isPathEncrypted("/id")) {
                        operation.id = await this.container.encryptionProcessor.getEncryptedId(operation.id);
                        totalPropertiesEncryptedCount++;
                    }
                    const { body, propertiesEncryptedCount } = await this.container.encryptionProcessor.encrypt(operation.resourceBody);
                    operation.resourceBody = body;
                    totalPropertiesEncryptedCount += propertiesEncryptedCount;
                    break;
                }
                case BulkOperationType.Patch: {
                    if (await this.container.encryptionProcessor.isPathEncrypted("/id")) {
                        operation.id = await this.container.encryptionProcessor.getEncryptedId(operation.id);
                        totalPropertiesEncryptedCount++;
                    }
                    const body = operation.resourceBody;
                    const patchRequestBody = Array.isArray(body) ? body : body.operations;
                    for (const patchOperation of patchRequestBody) {
                        if ("value" in patchOperation) {
                            if (this.container.encryptionProcessor.isPathEncrypted(patchOperation.path)) {
                                patchOperation.value = await this.container.encryptionProcessor.encryptProperty(patchOperation.path, patchOperation.value);
                                totalPropertiesEncryptedCount++;
                            }
                        }
                    }
                    break;
                }
            }
        }
        return { operations, totalPropertiesEncryptedCount };
    }
}

class StoredProcedureResponse extends ResourceResponse {
    constructor(resource, headers, statusCode, storedProcedure, diagnostics) {
        super(resource, headers, statusCode, diagnostics);
        this.storedProcedure = storedProcedure;
    }
    /**
     * Alias for storedProcedure.
     *
     * A reference to the {@link StoredProcedure} which the {@link StoredProcedureDefinition} corresponds to.
     */
    get sproc() {
        return this.storedProcedure;
    }
}

/**
 * Operations for reading, replacing, deleting, or executing a specific, existing stored procedure by id.
 *
 * For operations to create, read all, or query Stored Procedures,
 */
class StoredProcedure {
    /**
     * Returns a reference URL to the resource. Used for linking in Permissions.
     */
    get url() {
        return createStoredProcedureUri(this.container.database.id, this.container.id, this.id);
    }
    /**
     * Creates a new instance of {@link StoredProcedure} linked to the parent {@link Container}.
     * @param container - The parent {@link Container}.
     * @param id - The id of the given {@link StoredProcedure}.
     * @hidden
     */
    constructor(container, id, clientContext) {
        this.container = container;
        this.id = id;
        this.clientContext = clientContext;
    }
    /**
     * Read the {@link StoredProcedureDefinition} for the given {@link StoredProcedure}.
     */
    async read(options) {
        return withDiagnostics(async (diagnosticNode) => {
            const path = getPathFromLink(this.url);
            const id = getIdFromLink(this.url);
            const response = await this.clientContext.read({
                path,
                resourceType: exports.ResourceType.sproc,
                resourceId: id,
                options,
                diagnosticNode,
            });
            return new StoredProcedureResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * Replace the given {@link StoredProcedure} with the specified {@link StoredProcedureDefinition}.
     * @param body - The specified {@link StoredProcedureDefinition} to replace the existing definition.
     */
    async replace(body, options) {
        return withDiagnostics(async (diagnosticNode) => {
            if (body.body) {
                body.body = body.body.toString();
            }
            const err = {};
            if (!isResourceValid(body, err)) {
                throw err;
            }
            const path = getPathFromLink(this.url);
            const id = getIdFromLink(this.url);
            const response = await this.clientContext.replace({
                body,
                path,
                resourceType: exports.ResourceType.sproc,
                resourceId: id,
                options,
                diagnosticNode,
            });
            return new StoredProcedureResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * Delete the given {@link StoredProcedure}.
     */
    async delete(options) {
        return withDiagnostics(async (diagnosticNode) => {
            const path = getPathFromLink(this.url);
            const id = getIdFromLink(this.url);
            const response = await this.clientContext.delete({
                path,
                resourceType: exports.ResourceType.sproc,
                resourceId: id,
                options,
                diagnosticNode,
            });
            return new StoredProcedureResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * Execute the given {@link StoredProcedure}.
     *
     * The specified type, T, is not enforced by the client.
     * Be sure to validate the response from the stored procedure matches the type, T, you provide.
     *
     * @param partitionKey - The partition key to use when executing the stored procedure
     * @param params - Array of parameters to pass as arguments to the given {@link StoredProcedure}.
     * @param options - Additional options, such as the partition key to invoke the {@link StoredProcedure} on.
     */
    async execute(partitionKey, params, options) {
        return withDiagnostics(async (diagnosticNode) => {
            if (partitionKey === undefined) {
                const partitionKeyResponse = await readPartitionKeyDefinition(diagnosticNode, this.container);
                partitionKey = undefinedPartitionKey(partitionKeyResponse);
            }
            const response = await this.clientContext.execute({
                sprocLink: this.url,
                params,
                options,
                partitionKey,
                diagnosticNode,
            });
            return new ResourceResponse(response.result, response.headers, response.code, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
}

/**
 * Operations for creating, upserting, or reading/querying all Stored Procedures.
 *
 * For operations to read, replace, delete, or execute a specific, existing stored procedure by id, see `container.storedProcedure()`.
 */
class StoredProcedures {
    /**
     * @param container - The parent {@link Container}.
     * @hidden
     */
    constructor(container, clientContext) {
        this.container = container;
        this.clientContext = clientContext;
    }
    query(query, options) {
        const path = getPathFromLink(this.container.url, exports.ResourceType.sproc);
        const id = getIdFromLink(this.container.url);
        return new QueryIterator(this.clientContext, query, options, (diagNode, innerOptions) => {
            return this.clientContext.queryFeed({
                path,
                resourceType: exports.ResourceType.sproc,
                resourceId: id,
                resultFn: (result) => result.StoredProcedures,
                query,
                options: innerOptions,
                diagnosticNode: diagNode,
            });
        });
    }
    /**
     * Read all stored procedures.
     * @example Read all stored procedures to array.
     * ```typescript
     * const {body: sprocList} = await containers.storedProcedures.readAll().fetchAll();
     * ```
     */
    readAll(options) {
        return this.query(undefined, options);
    }
    /**
     * Create a StoredProcedure.
     *
     * Azure Cosmos DB allows stored procedures to be executed in the storage tier,
     * directly against an item container. The script
     * gets executed under ACID transactions on the primary storage partition of the
     * specified container. For additional details,
     * refer to the server-side JavaScript API documentation.
     */
    async create(body, options) {
        return withDiagnostics(async (diagnosticNode) => {
            if (body.body) {
                body.body = body.body.toString();
            }
            const err = {};
            if (!isResourceValid(body, err)) {
                throw err;
            }
            const path = getPathFromLink(this.container.url, exports.ResourceType.sproc);
            const id = getIdFromLink(this.container.url);
            const response = await this.clientContext.create({
                body,
                path,
                resourceType: exports.ResourceType.sproc,
                resourceId: id,
                options,
                diagnosticNode,
            });
            const ref = new StoredProcedure(this.container, response.result.id, this.clientContext);
            return new StoredProcedureResponse(response.result, response.headers, response.code, ref, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
}

class TriggerResponse extends ResourceResponse {
    constructor(resource, headers, statusCode, trigger, diagnostics) {
        super(resource, headers, statusCode, diagnostics);
        this.trigger = trigger;
    }
}

/**
 * Operations to read, replace, or delete a {@link Trigger}.
 *
 * Use `container.triggers` to create, upsert, query, or read all.
 */
class Trigger {
    /**
     * Returns a reference URL to the resource. Used for linking in Permissions.
     */
    get url() {
        return createTriggerUri(this.container.database.id, this.container.id, this.id);
    }
    /**
     * @hidden
     * @param container - The parent {@link Container}.
     * @param id - The id of the given {@link Trigger}.
     */
    constructor(container, id, clientContext) {
        this.container = container;
        this.id = id;
        this.clientContext = clientContext;
    }
    /**
     * Read the {@link TriggerDefinition} for the given {@link Trigger}.
     */
    async read(options) {
        return withDiagnostics(async (diagnosticNode) => {
            const path = getPathFromLink(this.url);
            const id = getIdFromLink(this.url);
            const response = await this.clientContext.read({
                path,
                resourceType: exports.ResourceType.trigger,
                resourceId: id,
                options,
                diagnosticNode,
            });
            return new TriggerResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * Replace the given {@link Trigger} with the specified {@link TriggerDefinition}.
     * @param body - The specified {@link TriggerDefinition} to replace the existing definition with.
     */
    async replace(body, options) {
        return withDiagnostics(async (diagnosticNode) => {
            if (body.body) {
                body.body = body.body.toString();
            }
            const err = {};
            if (!isResourceValid(body, err)) {
                throw err;
            }
            const path = getPathFromLink(this.url);
            const id = getIdFromLink(this.url);
            const response = await this.clientContext.replace({
                body,
                path,
                resourceType: exports.ResourceType.trigger,
                resourceId: id,
                options,
                diagnosticNode,
            });
            return new TriggerResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * Delete the given {@link Trigger}.
     */
    async delete(options) {
        return withDiagnostics(async (diagnosticNode) => {
            const path = getPathFromLink(this.url);
            const id = getIdFromLink(this.url);
            const response = await this.clientContext.delete({
                path,
                resourceType: exports.ResourceType.trigger,
                resourceId: id,
                options,
                diagnosticNode,
            });
            return new TriggerResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
}

/**
 * Operations to create, upsert, query, and read all triggers.
 *
 * Use `container.triggers` to read, replace, or delete a {@link Trigger}.
 */
class Triggers {
    /**
     * @hidden
     * @param container - The parent {@link Container}.
     */
    constructor(container, clientContext) {
        this.container = container;
        this.clientContext = clientContext;
    }
    query(query, options) {
        const path = getPathFromLink(this.container.url, exports.ResourceType.trigger);
        const id = getIdFromLink(this.container.url);
        return new QueryIterator(this.clientContext, query, options, (diagnosticNode, innerOptions) => {
            return this.clientContext.queryFeed({
                path,
                resourceType: exports.ResourceType.trigger,
                resourceId: id,
                resultFn: (result) => result.Triggers,
                query,
                options: innerOptions,
                diagnosticNode,
            });
        });
    }
    /**
     * Read all Triggers.
     * @example Read all trigger to array.
     * ```typescript
     * const {body: triggerList} = await container.triggers.readAll().fetchAll();
     * ```
     */
    readAll(options) {
        return this.query(undefined, options);
    }
    /**
     * Create a trigger.
     *
     * Azure Cosmos DB supports pre and post triggers defined in JavaScript to be executed
     * on creates, updates and deletes.
     *
     * For additional details, refer to the server-side JavaScript API documentation.
     */
    async create(body, options) {
        return withDiagnostics(async (diagnosticNode) => {
            if (body.body) {
                body.body = body.body.toString();
            }
            const err = {};
            if (!isResourceValid(body, err)) {
                throw err;
            }
            const path = getPathFromLink(this.container.url, exports.ResourceType.trigger);
            const id = getIdFromLink(this.container.url);
            const response = await this.clientContext.create({
                body,
                path,
                resourceType: exports.ResourceType.trigger,
                resourceId: id,
                options,
                diagnosticNode,
            });
            const ref = new Trigger(this.container, response.result.id, this.clientContext);
            return new TriggerResponse(response.result, response.headers, response.code, ref, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
}

class UserDefinedFunctionResponse extends ResourceResponse {
    constructor(resource, headers, statusCode, udf, diagnostics) {
        super(resource, headers, statusCode, diagnostics);
        this.userDefinedFunction = udf;
    }
    /**
     * Alias for `userDefinedFunction(id)`.
     *
     * A reference to the {@link UserDefinedFunction} corresponding to the returned {@link UserDefinedFunctionDefinition}.
     */
    get udf() {
        return this.userDefinedFunction;
    }
}

/**
 * Used to read, replace, or delete a specified User Definied Function by id.
 *
 * @see {@link UserDefinedFunction} to create, upsert, query, read all User Defined Functions.
 */
class UserDefinedFunction {
    /**
     * Returns a reference URL to the resource. Used for linking in Permissions.
     */
    get url() {
        return createUserDefinedFunctionUri(this.container.database.id, this.container.id, this.id);
    }
    /**
     * @hidden
     * @param container - The parent {@link Container}.
     * @param id - The id of the given {@link UserDefinedFunction}.
     */
    constructor(container, id, clientContext) {
        this.container = container;
        this.id = id;
        this.clientContext = clientContext;
    }
    /**
     * Read the {@link UserDefinedFunctionDefinition} for the given {@link UserDefinedFunction}.
     */
    async read(options) {
        return withDiagnostics(async (diagnosticNode) => {
            const path = getPathFromLink(this.url);
            const id = getIdFromLink(this.url);
            const response = await this.clientContext.read({
                path,
                resourceType: exports.ResourceType.udf,
                resourceId: id,
                options,
                diagnosticNode,
            });
            return new UserDefinedFunctionResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * Replace the given {@link UserDefinedFunction} with the specified {@link UserDefinedFunctionDefinition}.
     * @param options -
     */
    async replace(body, options) {
        return withDiagnostics(async (diagnosticNode) => {
            if (body.body) {
                body.body = body.body.toString();
            }
            const err = {};
            if (!isResourceValid(body, err)) {
                throw err;
            }
            const path = getPathFromLink(this.url);
            const id = getIdFromLink(this.url);
            const response = await this.clientContext.replace({
                body,
                path,
                resourceType: exports.ResourceType.udf,
                resourceId: id,
                options,
                diagnosticNode,
            });
            return new UserDefinedFunctionResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * Delete the given {@link UserDefined}.
     */
    async delete(options) {
        return withDiagnostics(async (diagnosticNode) => {
            const path = getPathFromLink(this.url);
            const id = getIdFromLink(this.url);
            const response = await this.clientContext.delete({
                path,
                resourceType: exports.ResourceType.udf,
                resourceId: id,
                options,
                diagnosticNode,
            });
            return new UserDefinedFunctionResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
}

/**
 * Used to create, upsert, query, or read all User Defined Functions.
 *
 * @see {@link UserDefinedFunction} to read, replace, or delete a given User Defined Function by id.
 */
class UserDefinedFunctions {
    /**
     * @hidden
     * @param container - The parent {@link Container}.
     */
    constructor(container, clientContext) {
        this.container = container;
        this.clientContext = clientContext;
    }
    query(query, options) {
        const path = getPathFromLink(this.container.url, exports.ResourceType.udf);
        const id = getIdFromLink(this.container.url);
        return new QueryIterator(this.clientContext, query, options, (diagnosticNode, innerOptions) => {
            return this.clientContext.queryFeed({
                path,
                resourceType: exports.ResourceType.udf,
                resourceId: id,
                resultFn: (result) => result.UserDefinedFunctions,
                query,
                options: innerOptions,
                diagnosticNode,
            });
        });
    }
    /**
     * Read all User Defined Functions.
     * @example Read all User Defined Functions to array.
     * ```typescript
     * const {body: udfList} = await container.userDefinedFunctions.readAll().fetchAll();
     * ```
     */
    readAll(options) {
        return this.query(undefined, options);
    }
    /**
     * Create a UserDefinedFunction.
     *
     * Azure Cosmos DB supports JavaScript UDFs which can be used inside queries, stored procedures and triggers.
     *
     * For additional details, refer to the server-side JavaScript API documentation.
     *
     */
    async create(body, options) {
        return withDiagnostics(async (diagnosticNode) => {
            if (body.body) {
                body.body = body.body.toString();
            }
            const err = {};
            if (!isResourceValid(body, err)) {
                throw err;
            }
            const path = getPathFromLink(this.container.url, exports.ResourceType.udf);
            const id = getIdFromLink(this.container.url);
            const response = await this.clientContext.create({
                body,
                path,
                resourceType: exports.ResourceType.udf,
                resourceId: id,
                options,
                diagnosticNode,
            });
            const ref = new UserDefinedFunction(this.container, response.result.id, this.clientContext);
            return new UserDefinedFunctionResponse(response.result, response.headers, response.code, ref, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
class Scripts {
    /**
     * @param container - The parent {@link Container}.
     * @hidden
     */
    constructor(container, clientContext) {
        this.container = container;
        this.clientContext = clientContext;
    }
    /**
     * Used to read, replace, or delete a specific, existing {@link StoredProcedure} by id.
     *
     * Use `.storedProcedures` for creating new stored procedures, or querying/reading all stored procedures.
     * @param id - The id of the {@link StoredProcedure}.
     */
    storedProcedure(id) {
        return new StoredProcedure(this.container, id, this.clientContext);
    }
    /**
     * Used to read, replace, or delete a specific, existing {@link Trigger} by id.
     *
     * Use `.triggers` for creating new triggers, or querying/reading all triggers.
     * @param id - The id of the {@link Trigger}.
     */
    trigger(id) {
        return new Trigger(this.container, id, this.clientContext);
    }
    /**
     * Used to read, replace, or delete a specific, existing {@link UserDefinedFunction} by id.
     *
     * Use `.userDefinedFunctions` for creating new user defined functions, or querying/reading all user defined functions.
     * @param id - The id of the {@link UserDefinedFunction}.
     */
    userDefinedFunction(id) {
        return new UserDefinedFunction(this.container, id, this.clientContext);
    }
    /**
     * Operations for creating new stored procedures, and reading/querying all stored procedures.
     *
     * For reading, replacing, or deleting an existing stored procedure, use `.storedProcedure(id)`.
     */
    get storedProcedures() {
        if (!this.$sprocs) {
            this.$sprocs = new StoredProcedures(this.container, this.clientContext);
        }
        return this.$sprocs;
    }
    /**
     * Operations for creating new triggers, and reading/querying all triggers.
     *
     * For reading, replacing, or deleting an existing trigger, use `.trigger(id)`.
     */
    get triggers() {
        if (!this.$triggers) {
            this.$triggers = new Triggers(this.container, this.clientContext);
        }
        return this.$triggers;
    }
    /**
     * Operations for creating new user defined functions, and reading/querying all user defined functions.
     *
     * For reading, replacing, or deleting an existing user defined function, use `.userDefinedFunction(id)`.
     */
    get userDefinedFunctions() {
        if (!this.$udfs) {
            this.$udfs = new UserDefinedFunctions(this.container, this.clientContext);
        }
        return this.$udfs;
    }
}

/** Response object for Container operations */
class ContainerResponse extends ResourceResponse {
    constructor(resource, headers, statusCode, container, diagnostics) {
        super(resource, headers, statusCode, diagnostics);
        this.container = container;
    }
}

class OfferResponse extends ResourceResponse {
    constructor(resource, headers, statusCode, diagnostics, offer) {
        super(resource, headers, statusCode, diagnostics);
        this.offer = offer;
    }
}

/**
 * Use to read or replace an existing {@link Offer} by id.
 *
 * @see {@link Offers} to query or read all offers.
 */
class Offer {
    /**
     * Returns a reference URL to the resource. Used for linking in Permissions.
     */
    get url() {
        return `/${Constants.Path.OffersPathSegment}/${this.id}`;
    }
    /**
     * @hidden
     * @param client - The parent {@link CosmosClient} for the Database Account.
     * @param id - The id of the given {@link Offer}.
     */
    constructor(client, id, clientContext) {
        this.client = client;
        this.id = id;
        this.clientContext = clientContext;
    }
    /**
     * Read the {@link OfferDefinition} for the given {@link Offer}.
     */
    async read(options) {
        return withDiagnostics(async (diagnosticNode) => {
            const response = await this.clientContext.read({
                path: this.url,
                resourceType: exports.ResourceType.offer,
                resourceId: this.id,
                options,
                diagnosticNode,
            });
            return new OfferResponse(response.result, response.headers, response.code, getEmptyCosmosDiagnostics(), this);
        }, this.clientContext);
    }
    /**
     * Replace the given {@link Offer} with the specified {@link OfferDefinition}.
     * @param body - The specified {@link OfferDefinition}
     */
    async replace(body, options) {
        return withDiagnostics(async (diagnosticNode) => {
            const err = {};
            if (!isResourceValid(body, err)) {
                throw err;
            }
            const response = await this.clientContext.replace({
                body,
                path: this.url,
                resourceType: exports.ResourceType.offer,
                resourceId: this.id,
                options,
                diagnosticNode,
            });
            return new OfferResponse(response.result, response.headers, response.code, getEmptyCosmosDiagnostics(), this);
        }, this.clientContext);
    }
}

/**
 * Use to query or read all Offers.
 *
 * @see {@link Offer} to read or replace an existing {@link Offer} by id.
 */
class Offers {
    /**
     * @hidden
     * @param client - The parent {@link CosmosClient} for the offers.
     */
    constructor(client, clientContext) {
        this.client = client;
        this.clientContext = clientContext;
    }
    query(query, options) {
        return new QueryIterator(this.clientContext, query, options, (diagnosticNode, innerOptions) => {
            return this.clientContext.queryFeed({
                path: "/offers",
                resourceType: exports.ResourceType.offer,
                resourceId: "",
                resultFn: (result) => result.Offers,
                query,
                options: innerOptions,
                diagnosticNode,
            });
        });
    }
    /**
     * Read all offers.
     * @example Read all offers to array.
     * ```typescript
     * const {body: offerList} = await client.offers.readAll().fetchAll();
     * ```
     */
    readAll(options) {
        return this.query(undefined, options);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/** Response object for ClientEncryptionKey operations */
class ClientEncryptionKeyResponse extends ResourceResponse {
    constructor(resource, headers, statusCode, clientEncryptionKeyProperties, diagnostics) {
        super(resource, headers, statusCode, diagnostics);
        this.clientEncryptionKeyProperties = clientEncryptionKeyProperties;
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/** Encryption Algorithms supported for data encryption */
exports.EncryptionAlgorithm = void 0;
(function (EncryptionAlgorithm) {
    /**  Represents the authenticated encryption algorithm with associated data as described in
          http://tools.ietf.org/html/draft-mcgrew-aead-aes-cbc-hmac-sha2-05. */
    EncryptionAlgorithm["AEAD_AES_256_CBC_HMAC_SHA256"] = "AEAD_AES_256_CBC_HMAC_SHA256";
})(exports.EncryptionAlgorithm || (exports.EncryptionAlgorithm = {}));

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/** Names of implementations of @see {@link EncryptionKeyResolver} */
exports.EncryptionKeyResolverName = void 0;
(function (EncryptionKeyResolverName) {
    /** Name of @see {@link AzureKeyVaultEncryptionKeyResolver} implementation for key encryption keys in Azure Key vault*/
    EncryptionKeyResolverName["AzureKeyVault"] = "AZURE_KEY_VAULT";
})(exports.EncryptionKeyResolverName || (exports.EncryptionKeyResolverName = {}));

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/** The algorithms used to wrap/unwrap data encryption key with key encryption key.  */
exports.KeyEncryptionAlgorithm = void 0;
(function (KeyEncryptionAlgorithm) {
    /** name of supported algo */
    KeyEncryptionAlgorithm["RSA_OAEP"] = "RSA-OAEP";
})(exports.KeyEncryptionAlgorithm || (exports.KeyEncryptionAlgorithm = {}));

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Implementation of EncryptionKeyResolver that uses Azure Key Vault for customer managed keys.
 */
class AzureKeyVaultEncryptionKeyResolver {
    constructor(credentials) {
        /**
         * Name of the resolver to use for client side encryption.
         * Currently only AzureKeyVault implementation is supported.
         */
        this.encryptionKeyResolverName = exports.EncryptionKeyResolverName.AzureKeyVault;
        this.credentials = credentials;
    }
    /**
     * wraps the given key using the specified key encryption key path and algorithm.
     * @param encryptionKeyId - path to the customer managed key to be used for wrapping. For Azure Key Vault, this is url of the key in the vault.
     * @param algorithm - algorithm to be used for wrapping.
     * @param unwrappedKey - dek to be wrapped.
     * @returns wrapped DEK.
     */
    async wrapKey(encryptionKeyId, algorithm, unwrappedKey) {
        try {
            const origin = this.getOrigin(encryptionKeyId);
            const keyClient = new keyvaultKeys.KeyClient(origin, this.credentials);
            const [keyName, keyVersion] = this.getKeyDetails(encryptionKeyId);
            const cryptographyClient = keyClient.getCryptographyClient(keyName, {
                keyVersion: keyVersion,
            });
            const res = await cryptographyClient.wrapKey(algorithm, unwrappedKey);
            if (!res || !res.result) {
                throw new ErrorResponse(`Failed to wrap key: ${res}`);
            }
            return res.result;
        }
        catch (e) {
            throw new ErrorResponse(`Failed to wrap key: ${e.message}`);
        }
    }
    /**
     * Unwraps the given wrapped key using the specified key encryption key path and algorithm.
     * @param encryptionKeyId - path to the customer managed key to be used for unwrapping. For Azure Key Vault, this is url of the key in the vault.
     * @param algorithm - algorithm to be used for unwrapping.
     * @param wrappedKey - wrapped DEK.
     * @returns unwrapped DEK.
     */
    async unwrapKey(encryptionKeyId, algorithm, wrappedKey) {
        try {
            const origin = this.getOrigin(encryptionKeyId);
            const keyClient = new keyvaultKeys.KeyClient(origin, this.credentials);
            const [keyName, keyVersion] = this.getKeyDetails(encryptionKeyId);
            const cryptographyClient = keyClient.getCryptographyClient(keyName, {
                keyVersion: keyVersion,
            });
            const res = await cryptographyClient.unwrapKey(algorithm, wrappedKey);
            if (!res || !res.result) {
                throw new ErrorResponse(`Failed to wrap key: ${res}`);
            }
            return res.result;
        }
        catch (e) {
            throw new ErrorResponse(`Failed to unwrap key: ${e.message}`);
        }
    }
    // TODO: improve this method to extract key name and version from the url
    getKeyDetails(encryptionKeyId) {
        let url;
        try {
            url = new URL(encryptionKeyId);
            const parts = url.pathname.split("/");
            if (parts.length < 4 || parts.length > 5) {
                throw new ErrorResponse(`Invalid key url: ${encryptionKeyId}. Key url must be in the format https://<vault>.vault.azure.net/keys/<key-name>/<key-version>`);
            }
            if (parts.length === 4 || parts.length === 5) {
                return [parts[2], parts[3]];
            }
        }
        catch (e) {
            throw new ErrorResponse(`Invalid key url: ${encryptionKeyId}. Key url must be in the format https://<vault>.vault.azure.net/keys/<key-name>/<key-version>. Error: ${e.message}`);
        }
    }
    getOrigin(encryptionKeyId) {
        try {
            const url = new URL(encryptionKeyId);
            return url.origin;
        }
        catch (e) {
            throw new ErrorResponse(`Invalid key url: ${encryptionKeyId}. Key url must be in the format https://<vault>.vault.azure.net/keys/<key-name>/<key-version>. Error: ${e.message}`);
        }
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Class to store encryption keys in unwrapped form and provide an interface for wrapping and unwrapping the keys.
 */
class EncryptionKeyStoreProvider {
    constructor(keyEncryptionKeyResolver, cacheTimeToLive) {
        this.keyEncryptionKeyResolver = keyEncryptionKeyResolver;
        this.cacheTimeToLive = cacheTimeToLive;
        this.RsaOaepEncryptionAlgorithm = "RSA-OAEP";
        this.keyEncryptionKeyResolver = keyEncryptionKeyResolver;
        this.providerName = keyEncryptionKeyResolver.encryptionKeyResolverName;
        this.unwrappedEncryptionKeyCache = {};
        this.cacheTimeToLive = cacheTimeToLive;
        this.clearCacheOnTtlExpiry();
    }
    async wrapKey(encryptionKeyId, algorithm, key) {
        const uInt8ArrayKey = new Uint8Array(key);
        const wrappedEncryptionKey = await this.keyEncryptionKeyResolver.wrapKey(encryptionKeyId, algorithm, uInt8ArrayKey);
        return Buffer.from(wrappedEncryptionKey);
    }
    async unwrapKey(encryptionKeyId, algorithm, wrappedKey) {
        if (this.cacheTimeToLive === 0) {
            const res = await this.keyEncryptionKeyResolver.unwrapKey(encryptionKeyId, algorithm, wrappedKey);
            return Buffer.from(res);
        }
        if (!this.unwrappedEncryptionKeyCache[encryptionKeyId]) {
            const wrappedKeyUint8Array = new Uint8Array(wrappedKey);
            const plainEncryptionKey = await this.keyEncryptionKeyResolver.unwrapKey(encryptionKeyId, algorithm, wrappedKeyUint8Array);
            const plainEncryptionKeyBuffer = Buffer.from(plainEncryptionKey);
            this.unwrappedEncryptionKeyCache[encryptionKeyId] = [new Date(), plainEncryptionKeyBuffer];
        }
        return this.unwrappedEncryptionKeyCache[encryptionKeyId][1];
    }
    async clearCacheOnTtlExpiry() {
        this.cacheRefresher = setInterval(() => {
            const now = new Date();
            for (const key in this.unwrappedEncryptionKeyCache) {
                if (now.getTime() - this.unwrappedEncryptionKeyCache[key][0].getTime() >
                    this.cacheTimeToLive) {
                    delete this.unwrappedEncryptionKeyCache[key];
                }
            }
        }, Constants.EncryptionCacheRefreshIntervalInMs);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * stores partitionKeyPaths, all the pathsToEncrypt, and encryption settings (cekId, encryption type, and algorithm) for each property.
 * see {@link EncryptionSettingForProperty}
 * @hidden
 */
class EncryptionSettings {
    // getContainerRid
    constructor(id, containerRid, partitionKeyPaths) {
        this.pathsToEncrypt = [];
        // key is property path
        this.encryptionSettingForProperties = {};
        this.id = id;
        this.containerRid = containerRid;
        this.partitionKeyPaths = partitionKeyPaths;
    }
    setEncryptionSettingForProperty(key, encryptionSettingForProperty) {
        this.encryptionSettingForProperties[key] = encryptionSettingForProperty;
    }
    getEncryptionSettingForProperty(propertyName) {
        return this.encryptionSettingForProperties[propertyName];
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * A wrapper class containing the info about the key-protecting key stored in an external key provider
 * and provides interface to wrap and unwrap the key.
 */
class KeyEncryptionKey {
    constructor(name, path, keyStoreProvider) {
        this.name = name;
        this.path = path;
        this.keyStoreProvider = keyStoreProvider;
        this.encryptionAlgorithm = exports.KeyEncryptionAlgorithm.RSA_OAEP;
    }
    async wrapEncryptionKey(plainTextEncryptionKey) {
        return this.keyStoreProvider.wrapKey(this.path, this.encryptionAlgorithm, plainTextEncryptionKey);
    }
    async unwrapEncryptionKey(wrappedEncryptionKey) {
        return this.keyStoreProvider.unwrapKey(this.path, this.encryptionAlgorithm, wrappedEncryptionKey);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
class AeadAes256CbcHmacSha256Algorithm {
    constructor(dataEncryptionKey, encryptionType) {
        this.algoVersion = 0x1;
        this.blockSizeInBytes = 16;
        this.dataEncryptionKey = dataEncryptionKey;
        this.encryptionType = encryptionType;
        this.version = Buffer.from([this.algoVersion]);
        this.versionSize = Buffer.from([1]);
        this.keySizeInBytes = 32;
        this.minimumCipherTextLength = 1 + 2 * this.blockSizeInBytes + this.keySizeInBytes;
    }
    encrypt(plainTextBuffer) {
        let iv;
        // create initialization vector
        if (this.encryptionType === exports.EncryptionType.RANDOMIZED) {
            iv = crypto.randomBytes(16);
        }
        else {
            const ivHmac = crypto.createHmac("sha256", this.dataEncryptionKey.ivKeyBuffer);
            ivHmac.update(plainTextBuffer);
            iv = ivHmac.digest().slice(0, this.blockSizeInBytes);
        }
        // create cipher text
        const cipher = crypto.createCipheriv("aes-256-cbc", this.dataEncryptionKey.encryptionKeyBuffer, iv);
        const cipherTextBuffer = Buffer.concat([cipher.update(plainTextBuffer), cipher.final()]);
        const authTagBuffer = this.generateAuthenticationTag(iv, cipherTextBuffer);
        return Buffer.concat([Buffer.from([this.algoVersion]), authTagBuffer, iv, cipherTextBuffer]);
    }
    decrypt(cipherTextBuffer) {
        if (cipherTextBuffer.length < this.minimumCipherTextLength) {
            throw new Error("Invalid cipher text length");
        }
        if (cipherTextBuffer[0] !== this.algoVersion) {
            throw new Error("Invalid cipher text version");
        }
        const authTagStartIndex = 1;
        const authTagLength = this.keySizeInBytes;
        const ivStartIndex = authTagStartIndex + authTagLength;
        const ivLength = this.blockSizeInBytes;
        const cipherTextStartIndex = ivStartIndex + ivLength;
        const cipherTextLength = cipherTextBuffer.length - cipherTextStartIndex;
        const authenticationTag = cipherTextBuffer.slice(authTagStartIndex, authTagStartIndex + authTagLength);
        const iv = cipherTextBuffer.slice(ivStartIndex, ivStartIndex + ivLength);
        const cipherText = cipherTextBuffer.slice(cipherTextStartIndex, cipherTextStartIndex + cipherTextLength);
        this.validateAuthenticationTag(authenticationTag, iv, cipherText);
        const decipher = crypto.createDecipheriv("aes-256-cbc", this.dataEncryptionKey.encryptionKeyBuffer, iv);
        const decrypted = decipher.update(cipherText);
        const result = Buffer.concat([decrypted, decipher.final()]);
        return result;
    }
    generateAuthenticationTag(iv, cipherTextBuffer) {
        const hmac = crypto.createHmac("sha256", this.dataEncryptionKey.macKeyBuffer);
        const buffer = Buffer.concat([this.version, iv, cipherTextBuffer, this.versionSize]);
        return hmac.update(buffer).digest();
    }
    validateAuthenticationTag(authenticationTag, iv, cipherText) {
        const expectedAuthTag = this.generateAuthenticationTag(iv, cipherText);
        if (!authenticationTag.equals(expectedAuthTag)) {
            throw new Error("Invalid authentication tag");
        }
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Represents the encryption setting for a specific property in an item.
 * @hidden
 */
class EncryptionSettingForProperty {
    constructor(clientEncryptionIncludedPath) {
        this.encryptionKeyId = clientEncryptionIncludedPath.clientEncryptionKeyId;
        this.encryptionType = clientEncryptionIncludedPath.encryptionType;
        this.encryptionAlgorithm = clientEncryptionIncludedPath.encryptionAlgorithm;
    }
    async buildEncryptionAlgorithm(clientEncryptionKeyProperties, encryptionManager, forceRefresh) {
        const protectedDataEncryptionKey = await this.buildProtectedDataEncryptionKey(clientEncryptionKeyProperties, encryptionManager, forceRefresh);
        const encryptionAlgorithm = new AeadAes256CbcHmacSha256Algorithm(protectedDataEncryptionKey, this.encryptionType);
        return encryptionAlgorithm;
    }
    async buildProtectedDataEncryptionKey(clientEncryptionKeyProperties, encryptionManager, forceRefresh) {
        const keyEncryptionKey = encryptionManager.keyEncryptionKeyCache.getOrCreate(clientEncryptionKeyProperties.encryptionKeyWrapMetadata.name, clientEncryptionKeyProperties.encryptionKeyWrapMetadata.value, encryptionManager.encryptionKeyStoreProvider);
        const protectedDataEncryptionKey = await encryptionManager.protectedDataEncryptionKeyCache.getOrCreate(this.encryptionKeyId, keyEncryptionKey, clientEncryptionKeyProperties.wrappedDataEncryptionKey, forceRefresh);
        return protectedDataEncryptionKey;
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
class DataEncryptionKey {
    constructor(rootKey, name) {
        this.keySizeInBits = 256;
        this.keySizeInBytes = this.keySizeInBits / 8;
        if (rootKey.length !== this.keySizeInBytes) {
            throw new Error("Invalid root key size");
        }
        this.rootKeyBuffer = rootKey;
        this.name = name;
        const encryptionKeySalt = `Microsoft SQL Server cell encryption key with encryption algorithm:AEAD_AES_256_CBC_HMAC_SHA256 and key length:${this.keySizeInBits}`;
        const macKeySalt = `Microsoft SQL Server cell MAC key with encryption algorithm:AEAD_AES_256_CBC_HMAC_SHA256 and key length:${this.keySizeInBits}`;
        const ivKeySalt = `Microsoft SQL Server cell IV key with encryption algorithm:AEAD_AES_256_CBC_HMAC_SHA256 and key length:${this.keySizeInBits}`;
        this.encryptionKeyBuffer = this.getHmacWithSha256(encryptionKeySalt, this.rootKeyBuffer);
        this.macKeyBuffer = this.getHmacWithSha256(macKeySalt, this.rootKeyBuffer);
        this.ivKeyBuffer = this.getHmacWithSha256(ivKeySalt, this.rootKeyBuffer);
    }
    getHmacWithSha256(plainText, key) {
        const hmac = crypto.createHmac("sha256", key);
        hmac.update(Buffer.from(plainText, "utf16le"));
        return hmac.digest();
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * A wrapper class around `DataEncryptionKey` that stores it in a protected form.
 * The `ProtectedDataEncryptionKey` class extends `DataEncryptionKey` and holds both the raw key and its encrypted form.
 * It also includes information about the `KeyEncryptionKey` used to encrypt the data encryption key.
 * @hidden
 */
class ProtectedDataEncryptionKey extends DataEncryptionKey {
    constructor(name, keyEncryptionKey, rawKey, encryptedKey) {
        super(rawKey, name);
        this.name = name;
        this.keyEncryptionKey = keyEncryptionKey;
        this.encryptedValue = encryptedKey;
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
class EncryptionProcessor {
    constructor(containerId, containerRid, database, clientContext, encryptionManager) {
        this.containerId = containerId;
        this.containerRid = containerRid;
        this.database = database;
        this.clientContext = clientContext;
        this.encryptionManager = encryptionManager;
    }
    async encrypt(body) {
        if (!body) {
            throw new ErrorResponse("Input body is null or undefined.");
        }
        let propertiesEncryptedCount = 0;
        const encryptionSettings = await this.getEncryptionSetting();
        if (!encryptionSettings)
            return { body, propertiesEncryptedCount };
        for (const pathToEncrypt of encryptionSettings.pathsToEncrypt) {
            const propertyName = pathToEncrypt.slice(1);
            if (!Object.prototype.hasOwnProperty.call(body, propertyName)) {
                continue;
            }
            const settingForProperty = encryptionSettings.getEncryptionSettingForProperty(pathToEncrypt);
            if (!settingForProperty) {
                throw new ErrorResponse("Invalid Encryption Setting for the Property: " + propertyName);
            }
            body[propertyName] = await this.encryptToken(body[propertyName], settingForProperty, propertyName === "id");
            propertiesEncryptedCount++;
        }
        return { body, propertiesEncryptedCount };
    }
    async isPathEncrypted(path) {
        path = extractPath(path);
        const encryptionSettings = await this.getEncryptionSetting();
        const settingForProperty = encryptionSettings.getEncryptionSettingForProperty(path);
        if (!settingForProperty)
            return false;
        return true;
    }
    async encryptProperty(path, value) {
        path = extractPath(path);
        const encryptionSettings = await this.getEncryptionSetting();
        if (!encryptionSettings)
            return value;
        const settingForProperty = encryptionSettings.getEncryptionSettingForProperty(path);
        if (!settingForProperty) {
            return value;
        }
        value = await this.encryptToken(value, settingForProperty, path === "/id");
        return value;
    }
    async getEncryptedPartitionKeyValue(partitionKeyList) {
        const encryptionSettings = await this.getEncryptionSetting();
        let encryptedCount = 0;
        if (!encryptionSettings)
            return { partitionKeyList, encryptedCount };
        const partitionKeyPaths = encryptionSettings.partitionKeyPaths;
        for (let i = 0; i < partitionKeyPaths.length; i++) {
            const partitionKeyPath = extractPath(partitionKeyPaths[i]);
            if (encryptionSettings.pathsToEncrypt.includes(partitionKeyPath)) {
                const settingForProperty = encryptionSettings.getEncryptionSettingForProperty(partitionKeyPath);
                partitionKeyList[i] = await this.encryptToken(partitionKeyList[i], settingForProperty, partitionKeyPath === "/id");
                encryptedCount++;
            }
        }
        return { partitionKeyList, encryptedCount };
    }
    async getEncryptedUrl(id) {
        const parts = id.split("/");
        const lastPart = parts[parts.length - 1];
        const encryptedLastPart = await this.getEncryptedId(lastPart);
        parts[parts.length - 1] = encryptedLastPart;
        return parts.join("/");
    }
    async getEncryptedId(id) {
        const encryptionSettings = await this.getEncryptionSetting();
        if (!encryptionSettings)
            return id;
        const settingForProperty = encryptionSettings.getEncryptionSettingForProperty("/id");
        if (!settingForProperty)
            return id;
        id = await this.encryptToken(id, settingForProperty, true);
        return id;
    }
    async encryptQueryParameter(path, value, isValueId, type) {
        if (value === null) {
            return value;
        }
        path = extractPath(path);
        const encryptionSettings = await this.getEncryptionSetting();
        if (!encryptionSettings)
            return value;
        const settingForProperty = encryptionSettings.getEncryptionSettingForProperty(path);
        if (!settingForProperty) {
            return value;
        }
        return this.encryptToken(value, settingForProperty, isValueId, type);
    }
    async encryptToken(valueToEncrypt, propertySetting, isValueId, type) {
        if (typeof valueToEncrypt === "object" && valueToEncrypt !== null) {
            for (const key in valueToEncrypt) {
                if (Object.prototype.hasOwnProperty.call(valueToEncrypt, key)) {
                    valueToEncrypt[key] = await this.encryptToken(valueToEncrypt[key], propertySetting, isValueId, type);
                }
            }
        }
        else if (Array.isArray(type)) {
            for (let i = 0; i < valueToEncrypt.length; i++) {
                valueToEncrypt[i] = await this.encryptToken(valueToEncrypt[i], propertySetting, isValueId, type);
            }
        }
        else {
            valueToEncrypt = await this.serializeAndEncryptValue(valueToEncrypt, propertySetting, isValueId, type);
        }
        return valueToEncrypt;
    }
    async serializeAndEncryptValue(valueToEncrypt, propertySetting, isValueId, type) {
        if (valueToEncrypt === null) {
            return valueToEncrypt;
        }
        const [typeMarker, serializer] = createSerializer(valueToEncrypt, type);
        const plainText = serializer.serialize(valueToEncrypt);
        const encryptionAlgorithm = await this.buildEncryptionAlgorithm(propertySetting);
        const cipherText = encryptionAlgorithm.encrypt(plainText);
        if (isValueId) {
            if (typeof valueToEncrypt !== "string") {
                throw new ErrorResponse("The id should be of string type.");
            }
        }
        const cipherTextWithTypeMarker = Buffer.alloc(cipherText.length + 1);
        cipherTextWithTypeMarker[0] = typeMarker;
        cipherText.forEach((value, index) => {
            cipherTextWithTypeMarker[index + 1] = value;
        });
        let encryptedValue = Buffer.from(cipherTextWithTypeMarker).toString("base64");
        if (isValueId) {
            encryptedValue = encryptedValue.replace(/\//g, "_").replace(/\+/g, "-");
        }
        return encryptedValue;
    }
    async decrypt(body) {
        let propertiesDecryptedCount = 0;
        if (body == null) {
            return { body, propertiesDecryptedCount };
        }
        const encryptionSettings = await this.getEncryptionSetting();
        if (!encryptionSettings)
            return { body, propertiesDecryptedCount };
        for (const pathToEncrypt of encryptionSettings.pathsToEncrypt) {
            const propertyName = pathToEncrypt.slice(1);
            if (!Object.prototype.hasOwnProperty.call(body, propertyName)) {
                continue;
            }
            const settingForProperty = encryptionSettings.getEncryptionSettingForProperty(pathToEncrypt);
            if (settingForProperty == null) {
                throw new ErrorResponse("Invalid Encryption Setting for the Path: " + pathToEncrypt);
            }
            body[propertyName] = await this.decryptToken(body[propertyName], settingForProperty, propertyName === "id");
            propertiesDecryptedCount++;
        }
        return { body, propertiesDecryptedCount };
    }
    async decryptToken(valueToDecrypt, propertySetting, isValueId) {
        if (typeof valueToDecrypt === "object") {
            for (const key in valueToDecrypt) {
                if (Object.prototype.hasOwnProperty.call(valueToDecrypt, key)) {
                    valueToDecrypt[key] = await this.decryptToken(valueToDecrypt[key], propertySetting, isValueId);
                }
            }
        }
        else if (Array.isArray(valueToDecrypt)) {
            for (let i = 0; i < valueToDecrypt.length; i++) {
                valueToDecrypt[i] = await this.decryptToken(valueToDecrypt[i], propertySetting, isValueId);
            }
        }
        else {
            valueToDecrypt = await this.deserializeAndDecryptValue(valueToDecrypt, propertySetting, isValueId);
        }
        return valueToDecrypt;
    }
    async deserializeAndDecryptValue(valueToDecrypt, propertySetting, isValueId) {
        if (isValueId) {
            valueToDecrypt = valueToDecrypt.replace(/_/g, "/").replace(/-/g, "+");
        }
        const cipherTextWithTypeMarker = Buffer.from(valueToDecrypt, "base64");
        if (cipherTextWithTypeMarker === null) {
            return null;
        }
        let cipherText = Buffer.alloc(cipherTextWithTypeMarker.length - 1);
        cipherText = Buffer.from(cipherTextWithTypeMarker.slice(1));
        const encryptionAlgorithm = await this.buildEncryptionAlgorithm(propertySetting);
        const plainText = encryptionAlgorithm.decrypt(cipherText);
        if (plainText === null) {
            throw new ErrorResponse("returned null plain text");
        }
        const serializer = createDeserializer(cipherTextWithTypeMarker[0]);
        return serializer.deserialize(plainText);
    }
    async getEncryptionSetting(forceRefresh) {
        const key = this.database._rid + "/" + this.containerRid;
        const encryptionSetting = this.encryptionManager.encryptionSettingsCache.get(key);
        if (forceRefresh || !encryptionSetting) {
            return withDiagnostics(async (diagnosticNode) => {
                const path = `/dbs/${this.database.id}/colls/${this.containerId}`;
                const id = `dbs/${this.database.id}/colls/${this.containerId}`;
                const response = await this.clientContext.read({
                    path,
                    resourceType: exports.ResourceType.container,
                    resourceId: id,
                    diagnosticNode,
                });
                if (!response || !response.result) {
                    throw new ErrorResponse("Failed to fetch container definition");
                }
                const containerRid = response.result._rid;
                const clientEncryptionPolicy = response.result.clientEncryptionPolicy;
                const partitionKeyPaths = response.result.partitionKey.paths;
                const updatedEncryptionSetting = await this.encryptionManager.encryptionSettingsCache.create(key, containerRid, partitionKeyPaths, clientEncryptionPolicy);
                return updatedEncryptionSetting;
            }, this.clientContext);
        }
        return encryptionSetting;
    }
    async buildEncryptionAlgorithm(propertySetting) {
        const key = `${this.database._rid}/${propertySetting.encryptionKeyId}`;
        let clientEncryptionKeyProperties = this.encryptionManager.clientEncryptionKeyPropertiesCache.get(key);
        if (!clientEncryptionKeyProperties) {
            clientEncryptionKeyProperties = await this.fetchClientEncryptionKey(propertySetting.encryptionKeyId);
        }
        try {
            // the buildEncryptionAlgorithm will build ProtectedDEK which calls unwrapKey  using the masterKey configured in
            // KeyEncryptionKey(created before creating Protected DEK)
            // we get wrapped key and key wrap metadata info from clientEncryptionKeyProperties.
            return await propertySetting.buildEncryptionAlgorithm(clientEncryptionKeyProperties, this.encryptionManager);
        }
        catch (err) {
            if (err.statusCode !== StatusCodes.Forbidden)
                throw err;
            // if access to key is revoked, and in case there's stale value in cache
            clientEncryptionKeyProperties = await this.fetchClientEncryptionKey(propertySetting.encryptionKeyId);
            try {
                // This will succeed after if client has rewrapped CEK and gateway cache has updated value.
                return await propertySetting.buildEncryptionAlgorithm(clientEncryptionKeyProperties, this.encryptionManager, true);
            }
            catch (retryErr) {
                if (retryErr.statusCode !== StatusCodes.Forbidden)
                    throw retryErr;
                // in case there's stale value in gateway cache. get fresh value from backend
                clientEncryptionKeyProperties = await this.fetchClientEncryptionKey(propertySetting.encryptionKeyId, clientEncryptionKeyProperties.etag);
                return propertySetting.buildEncryptionAlgorithm(clientEncryptionKeyProperties, this.encryptionManager);
            }
        }
    }
    async fetchClientEncryptionKey(cekId, cekEtag) {
        return withDiagnostics(async (diagnosticNode) => {
            const path = `/dbs/${this.database.id}/clientencryptionkeys/${cekId}`;
            const id = `dbs/${this.database.id}/clientencryptionkeys/${cekId}`;
            const options = {};
            if (cekEtag) {
                options.accessCondition = {
                    type: Constants.HttpHeaders.IfNoneMatch,
                    condition: cekEtag,
                };
            }
            options.databaseRid = this.database._rid;
            const response = await this.clientContext.read({
                path: path,
                resourceType: exports.ResourceType.clientencryptionkey,
                resourceId: id,
                options: options,
                diagnosticNode,
            });
            if (!response) {
                throw new ErrorResponse(`Failed to fetch client encryption key ${cekId}`);
            }
            if (response.code === StatusCodes.NotModified) {
                throw new ErrorResponse(`The Client Encryption Key with key id: ${cekId} on database: ${this.database.id} needs to be rewrapped with a valid Key Encryption Key using rewrapClientEncryptionKey. The Key Encryption Key used to wrap the Client Encryption Key has been revoked`);
            }
            const clientEncryptionKeyProperties = {
                id: response.result.id,
                encryptionAlgorithm: response.result.encryptionAlgorithm,
                wrappedDataEncryptionKey: new Uint8Array(Buffer.from(response.result.wrappedDataEncryptionKey, "base64")),
                encryptionKeyWrapMetadata: response.result.keyWrapMetadata,
                etag: response.result._etag,
            };
            const key = this.database._rid + "/" + cekId;
            this.encryptionManager.clientEncryptionKeyPropertiesCache.set(key, clientEncryptionKeyProperties);
            return clientEncryptionKeyProperties;
        }, this.clientContext);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * This enum represents the type of number in the Cosmos DB SDK.
 */
exports.CosmosEncryptedNumberType = void 0;
(function (CosmosEncryptedNumberType) {
    /**
     * Represents an integer number.
     */
    CosmosEncryptedNumberType["Integer"] = "Integer";
    /**
     * Represents a floating-point number.
     */
    CosmosEncryptedNumberType["Float"] = "Float";
})(exports.CosmosEncryptedNumberType || (exports.CosmosEncryptedNumberType = {}));

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Represents a builder class for building encrypted parameters in parametrized query.
 */
class EncryptionQueryBuilder {
    constructor(query) {
        this.query = query;
        this.parameters = [];
    }
    /**
     * Adds parameter to query
     */
    addParameter(name, value, path) {
        if (value === null) {
            this.parameters.push({ name: name, value: null, path: path });
            return;
        }
        switch (true) {
            case typeof value === "boolean":
                this.parameters.push({
                    name,
                    value,
                    type: TypeMarker.Boolean,
                    path,
                });
                break;
            case typeof value === "string":
                this.parameters.push({
                    name,
                    value,
                    type: TypeMarker.String,
                    path,
                });
                break;
            case value instanceof Date: {
                const date = value.toISOString();
                this.parameters.push({
                    name: name,
                    value: date,
                    type: TypeMarker.String,
                    path: path,
                });
                break;
            }
            case isCosmosEncryptedNumber(value): {
                const num = value.value;
                if (value.numberType === exports.CosmosEncryptedNumberType.Integer) {
                    this.parameters.push({
                        name,
                        value: num,
                        type: TypeMarker.Long,
                        path,
                    });
                }
                else if (value.numberType === exports.CosmosEncryptedNumberType.Float) {
                    this.parameters.push({
                        name,
                        value: num,
                        type: TypeMarker.Double,
                        path,
                    });
                }
                break;
            }
            case Array.isArray(value):
                this.parameters.push({ name, value, path });
                break;
            case typeof value === "object":
                this.parameters.push({ name, value, path });
                break;
            default:
                throw new Error(`Unsupported parameter type for parameter "${name}": ${typeof value}`);
        }
    }
    /** Adds unencrypted parameter to query */
    addUnencryptedParameter(name, value, path) {
        this.parameters.push({ name: name, value: value, path: path });
    }
    /*
     * @internal
     */
    toEncryptionSqlQuerySpec() {
        return {
            query: this.query,
            parameters: this.parameters,
        };
    }
}
function isCosmosEncryptedNumber(val) {
    return (val !== null &&
        typeof val === "object" &&
        typeof val.value === "number" &&
        typeof val.numberType === "string" &&
        (val.numberType === exports.CosmosEncryptedNumberType.Integer ||
            val.numberType === exports.CosmosEncryptedNumberType.Float));
}

/**
 * Operations for reading, replacing, or deleting a specific, existing container by id.
 *
 * @see {@link Containers} for creating new containers, and reading/querying all containers; use `.containers`.
 *
 * Note: all these operations make calls against a fixed budget.
 * You should design your system such that these calls scale sublinearly with your application.
 * For instance, do not call `container(id).read()` before every single `item.read()` call, to ensure the container exists;
 * do this once on application start up.
 */
class Container {
    /**
     * Operations for creating new items, and reading/querying all items
     *
     * For reading, replacing, or deleting an existing item, use `.item(id)`.
     *
     * @example Create a new item
     * ```typescript
     * const {body: createdItem} = await container.items.create({id: "<item id>", properties: {}});
     * ```
     */
    get items() {
        if (!this.$items) {
            this.$items = new Items(this, this.clientContext);
        }
        return this.$items;
    }
    /**
     * All operations for Stored Procedures, Triggers, and User Defined Functions
     */
    get scripts() {
        if (!this.$scripts) {
            this.$scripts = new Scripts(this, this.clientContext);
        }
        return this.$scripts;
    }
    /**
     * Operations for reading and querying conflicts for the given container.
     *
     * For reading or deleting a specific conflict, use `.conflict(id)`.
     */
    get conflicts() {
        if (!this.$conflicts) {
            this.$conflicts = new Conflicts(this, this.clientContext);
        }
        return this.$conflicts;
    }
    /**
     * Returns a reference URL to the resource. Used for linking in Permissions.
     */
    get url() {
        return createDocumentCollectionUri(this.database.id, this.id);
    }
    /**
     * Returns a container instance. Note: You should get this from `database.container(id)`, rather than creating your own object.
     * @param database - The parent {@link Database}.
     * @param id - The id of the given container.
     * @hidden
     */
    constructor(database, id, clientContext, encryptionManager, _rid) {
        this.database = database;
        this.id = id;
        this.clientContext = clientContext;
        this.encryptionManager = encryptionManager;
        this.isEncryptionInitialized = false;
        this._rid = _rid;
        if (this.clientContext.enableEncryption) {
            this.encryptionProcessor = new EncryptionProcessor(this.id, this._rid, this.database, this.clientContext, this.encryptionManager);
        }
    }
    /**
     * Used to read, replace, or delete a specific, existing {@link Item} by id.
     *
     * Use `.items` for creating new items, or querying/reading all items.
     *
     * @param id - The id of the {@link Item}.
     * @param partitionKeyValue - The value of the {@link Item} partition key
     * @example Replace an item
     * `const {body: replacedItem} = await container.item("<item id>", "<partition key value>").replace({id: "<item id>", title: "Updated post", authorID: 5});`
     */
    item(id, partitionKeyValue) {
        return new Item(this, id, this.clientContext, partitionKeyValue);
    }
    /**
     * Used to read, replace, or delete a specific, existing {@link Conflict} by id.
     *
     * Use `.conflicts` for creating new conflicts, or querying/reading all conflicts.
     * @param id - The id of the {@link Conflict}.
     */
    conflict(id, partitionKey) {
        return new Conflict(this, id, this.clientContext, partitionKey);
    }
    /** Read the container's definition */
    async read(options) {
        return withDiagnostics(async (diagnosticNode) => {
            return this.readInternal(diagnosticNode, options);
        }, this.clientContext);
    }
    /**
     * @hidden
     */
    async readInternal(diagnosticNode, options) {
        const path = getPathFromLink(this.url);
        const id = getIdFromLink(this.url);
        const response = await this.clientContext.read({
            path,
            resourceType: exports.ResourceType.container,
            resourceId: id,
            options,
            diagnosticNode,
        });
        this.clientContext.partitionKeyDefinitionCache[this.url] = response.result.partitionKey;
        return new ContainerResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
    }
    /** Replace the container's definition */
    async replace(body, options) {
        return withDiagnostics(async (diagnosticNode) => {
            const err = {};
            if (!isResourceValid(body, err)) {
                throw err;
            }
            const path = getPathFromLink(this.url);
            const id = getIdFromLink(this.url);
            const response = await this.clientContext.replace({
                body,
                path,
                resourceType: exports.ResourceType.container,
                resourceId: id,
                options,
                diagnosticNode,
            });
            return new ContainerResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /** Delete the container */
    async delete(options) {
        return withDiagnostics(async (diagnosticNode) => {
            const path = getPathFromLink(this.url);
            const id = getIdFromLink(this.url);
            const response = await this.clientContext.delete({
                path,
                resourceType: exports.ResourceType.container,
                resourceId: id,
                options,
                diagnosticNode,
            });
            return new ContainerResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * Gets the partition key definition first by looking into the cache otherwise by reading the collection.
     * @deprecated This method has been renamed to readPartitionKeyDefinition.
     */
    async getPartitionKeyDefinition() {
        return withDiagnostics(async (diagnosticNode) => {
            return this.readPartitionKeyDefinition(diagnosticNode);
        }, this.clientContext);
    }
    /**
     * Gets the partition key definition first by looking into the cache otherwise by reading the collection.
     * @hidden
     */
    async readPartitionKeyDefinition(diagnosticNode) {
        // $ISSUE-felixfan-2016-03-17: Make name based path and link based path use the same key
        // $ISSUE-felixfan-2016-03-17: Refresh partitionKeyDefinitionCache when necessary
        if (this.url in this.clientContext.partitionKeyDefinitionCache) {
            diagnosticNode.addData({ readFromCache: true });
            return new ResourceResponse(this.clientContext.partitionKeyDefinitionCache[this.url], {}, 0, getEmptyCosmosDiagnostics());
        }
        const { headers, statusCode, diagnostics } = await withMetadataDiagnostics(async (node) => {
            return this.readInternal(node);
        }, diagnosticNode, exports.MetadataLookUpType.ContainerLookUp);
        return new ResourceResponse(this.clientContext.partitionKeyDefinitionCache[this.url], headers, statusCode, diagnostics);
    }
    /**
     * Gets offer on container. If none exists, returns an OfferResponse with undefined.
     */
    async readOffer(options = {}) {
        return withDiagnostics(async (diagnosticNode) => {
            const { resource: container } = await this.read();
            const path = "/offers";
            const url = container._self;
            const response = await this.clientContext.queryFeed({
                path,
                resourceId: "",
                resourceType: exports.ResourceType.offer,
                query: `SELECT * from root where root.resource = "${url}"`,
                resultFn: (result) => result.Offers,
                options,
                diagnosticNode,
            });
            const offer = response.result[0]
                ? new Offer(this.database.client, response.result[0].id, this.clientContext)
                : undefined;
            return new OfferResponse(response.result[0], response.headers, response.code, getEmptyCosmosDiagnostics(), offer);
        }, this.clientContext);
    }
    async getQueryPlan(query) {
        return withDiagnostics(async (diagnosticNode) => {
            const path = getPathFromLink(this.url);
            return this.clientContext.getQueryPlan(path + "/docs", exports.ResourceType.item, getIdFromLink(this.url), query, {}, diagnosticNode);
        }, this.clientContext);
    }
    readPartitionKeyRanges(feedOptions) {
        feedOptions = feedOptions || {};
        return this.clientContext.queryPartitionKeyRanges(this.url, undefined, feedOptions);
    }
    /**
     *
     * @returns all the feed ranges for which changefeed could be fetched.
     */
    async getFeedRanges() {
        return withDiagnostics(async (diagnosticNode) => {
            const { resources } = await this.readPartitionKeyRanges().fetchAllInternal(diagnosticNode);
            const feedRanges = [];
            for (const resource of resources) {
                const feedRange = new FeedRangeInternal(resource.minInclusive, resource.maxExclusive);
                Object.freeze(feedRange);
                feedRanges.push(feedRange);
            }
            return feedRanges;
        }, this.clientContext);
    }
    /**
     * Delete all documents belong to the container for the provided partition key value
     * @param partitionKey - The partition key value of the items to be deleted
     */
    async deleteAllItemsForPartitionKey(partitionKey, options) {
        return withDiagnostics(async (diagnosticNode) => {
            let path = getPathFromLink(this.url);
            const id = getIdFromLink(this.url);
            path = path + "/operations/partitionkeydelete";
            if (this.clientContext.enableEncryption) {
                await this.checkAndInitializeEncryption();
                options = options || {};
                options.containerRid = this._rid;
                diagnosticNode.beginEncryptionDiagnostics(Constants.Encryption.DiagnosticsEncryptOperation);
                const partitionKeyInternal = convertToInternalPartitionKey(partitionKey);
                const { partitionKeyList, encryptedCount } = await this.encryptionProcessor.getEncryptedPartitionKeyValue(partitionKeyInternal);
                partitionKey = partitionKeyList;
                diagnosticNode.endEncryptionDiagnostics(Constants.Encryption.DiagnosticsEncryptOperation, encryptedCount);
            }
            let response;
            try {
                response = await this.clientContext.delete({
                    path,
                    resourceType: exports.ResourceType.container,
                    resourceId: id,
                    options,
                    partitionKey: partitionKey,
                    method: exports.HTTPMethod.post,
                    diagnosticNode,
                });
            }
            catch (error) {
                if (this.clientContext.enableEncryption) {
                    await this.throwIfRequestNeedsARetryPostPolicyRefresh(error);
                }
                throw error;
            }
            return new ContainerResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * Warms up encryption related caches for the container.
     */
    async initializeEncryption() {
        if (!this.clientContext.enableEncryption) {
            throw new ErrorResponse("Encryption is not enabled for the client.");
        }
        else {
            await withDiagnostics(async (diagnosticNode) => {
                const readResponse = await this.readInternal(diagnosticNode);
                if (!readResponse || !readResponse.resource) {
                    throw new ErrorResponse("Failed to initialize encryption: The container's resource definition could not be retrieved.");
                }
                this._rid = readResponse.resource._rid;
                this.encryptionProcessor.containerRid = this._rid;
                const clientEncryptionPolicy = readResponse.resource.clientEncryptionPolicy;
                if (!clientEncryptionPolicy)
                    return;
                const partitionKeyPaths = readResponse.resource.partitionKey.paths;
                const databaseResponse = await this.database.readInternal(diagnosticNode);
                if (!databaseResponse || !databaseResponse.resource) {
                    throw new ErrorResponse("Failed to initialize encryption: The database's resource definition could not be retrieved.");
                }
                this.database._rid = databaseResponse.resource._rid;
                const encryptionSettingKey = this.database._rid + "/" + this._rid;
                await this.encryptionManager.encryptionSettingsCache.create(encryptionSettingKey, this._rid, partitionKeyPaths, clientEncryptionPolicy);
                const clientEncryptionKeyIds = [
                    ...new Set(clientEncryptionPolicy.includedPaths.map((item) => item.clientEncryptionKeyId)),
                ];
                // fetch and set clientEncryptionKeys in the cache
                for (const clientEncryptionKeyId of clientEncryptionKeyIds) {
                    const res = await this.database.readClientEncryptionKey(clientEncryptionKeyId);
                    if (!res || !res.clientEncryptionKeyProperties) {
                        throw new ErrorResponse(`Failed to initialize encryption: The client encryption key ${clientEncryptionKeyId} could not be retrieved.`);
                    }
                    const encryptionKeyProperties = res.clientEncryptionKeyProperties;
                    const key = this.database._rid + "/" + clientEncryptionKeyId;
                    this.encryptionManager.clientEncryptionKeyPropertiesCache.set(key, encryptionKeyProperties);
                }
                this.isEncryptionInitialized = true;
            }, this.clientContext);
        }
    }
    /**
     * @internal
     */
    async checkAndInitializeEncryption() {
        if (!this.isEncryptionInitialized) {
            if (!this.encryptionInitializationPromise) {
                this.encryptionInitializationPromise = this.initializeEncryption();
            }
            await this.encryptionInitializationPromise;
        }
    }
    /**
     * @internal
     * This function handles the scenario where a container is deleted(say from different Client) and recreated with same Id but with different client encryption policy.
     * The idea is to have the container Rid cached and sent out as part of RequestOptions with Container Rid set in "x-ms-cosmos-intended-collection-rid" header.
     * So, when the container being referenced here gets recreated we would end up with a stale encryption settings and container Rid and this would result in BadRequest (and a substatus 1024).
     * This would allow us to refresh the encryption settings and Container Rid, on the premise that the container recreated could possibly be configured with a new encryption policy.
     */
    async throwIfRequestNeedsARetryPostPolicyRefresh(errorResponse) {
        var _a;
        const key = this.database._rid + "/" + this._rid;
        const encryptionSetting = this.encryptionManager.encryptionSettingsCache.get(key);
        if (!(errorResponse === null || errorResponse === void 0 ? void 0 : errorResponse.code) || !((_a = errorResponse === null || errorResponse === void 0 ? void 0 : errorResponse.headers) === null || _a === void 0 ? void 0 : _a[Constants.HttpHeaders.SubStatus])) {
            return;
        }
        const subStatusCode = errorResponse.headers[Constants.HttpHeaders.SubStatus];
        const isPartitionKeyMismatch = Number(subStatusCode) === SubStatusCodes.PartitionKeyMismatch;
        const isIncorrectContainerRidSubstatus = Number(subStatusCode) === SubStatusCodes.IncorrectContainerRidSubstatus;
        if (errorResponse.code === StatusCodes.BadRequest &&
            (isPartitionKeyMismatch || isIncorrectContainerRidSubstatus)) {
            // This code verifies if the partitionKeyPaths are encrypted.
            // If the paths are not encrypted, it indicates that the application passed an incorrect partition key in the request.
            // This ensures the issue is not caused by a mismatched encrypted value due to a policy error,
            // avoiding unnecessary force-refreshing of encryption settings.
            if (isPartitionKeyMismatch && encryptionSetting.partitionKeyPaths.length) {
                let encryptionSettingsForProperty = null;
                for (const path of encryptionSetting.partitionKeyPaths) {
                    const partitionKeyPath = path.split("/")[1];
                    encryptionSettingsForProperty =
                        encryptionSetting.getEncryptionSettingForProperty(partitionKeyPath);
                    if (encryptionSettingsForProperty) {
                        break;
                    }
                }
                // wrong partition key passed as partition key is not encrypted.
                if (encryptionSettingsForProperty == null) {
                    return;
                }
            }
            const currentContainerRid = encryptionSetting.containerRid;
            const forceRefresh = true;
            // fetch rid of newly created container
            const updatedContainerRid = (await this.encryptionProcessor.getEncryptionSetting(forceRefresh)).containerRid;
            // if the container was not recreated, so policy has not changed, just return the original response
            if (currentContainerRid === updatedContainerRid) {
                return;
            }
            await this.initializeEncryption();
            throw new ErrorResponse("Operation has failed due to a possible mismatch in Client Encryption Policy configured on the container. Retrying may fix the issue. Please refer to https://aka.ms/CosmosClientEncryption for more details." +
                errorResponse.message);
        }
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
function validateOffer(body) {
    if (body.throughput) {
        if (body.maxThroughput) {
            console.log("should be erroring");
            throw new Error("Cannot specify `throughput` with `maxThroughput`");
        }
        if (body.autoUpgradePolicy) {
            throw new Error("Cannot specify autoUpgradePolicy with throughput. Use `maxThroughput` instead");
        }
    }
}

/**
 * Operations for creating new containers, and reading/querying all containers
 *
 * @see {@link Container} for reading, replacing, or deleting an existing container; use `.container(id)`.
 *
 * Note: all these operations make calls against a fixed budget.
 * You should design your system such that these calls scale sublinearly with your application.
 * For instance, do not call `containers.readAll()` before every single `item.read()` call, to ensure the container exists;
 * do this once on application start up.
 */
class Containers {
    /**
     * @hidden
     * @param database - The parent {@link Database}.
     */
    constructor(database, clientContext, encryptionManager) {
        this.database = database;
        this.clientContext = clientContext;
        this.encryptionManager = encryptionManager;
    }
    query(query, options) {
        const path = getPathFromLink(this.database.url, exports.ResourceType.container);
        const id = getIdFromLink(this.database.url);
        return new QueryIterator(this.clientContext, query, options, (diagNode, innerOptions) => {
            return this.clientContext.queryFeed({
                path,
                resourceType: exports.ResourceType.container,
                resourceId: id,
                resultFn: (result) => result.DocumentCollections,
                query,
                options: innerOptions,
                diagnosticNode: diagNode,
            });
        });
    }
    /**
     * Creates a container.
     *
     * A container is a named logical container for items.
     *
     * A database may contain zero or more named containers and each container consists of
     * zero or more JSON items.
     *
     * Being schema-free, the items in a container do not need to share the same structure or fields.
     *
     *
     * Since containers are application resources, they can be authorized using either the
     * master key or resource keys.
     *
     * @param body - Represents the body of the container.
     * @param options - Use to set options like response page size, continuation tokens, etc.
     */
    async create(body, options = {}) {
        return withDiagnostics(async (diagnosticNode) => {
            return this.createInternal(diagnosticNode, body, options);
        }, this.clientContext);
    }
    /**
     * @hidden
     */
    async createInternal(diagnosticNode, body, options = {}) {
        var _a;
        const err = {};
        if (!isResourceValid(body, err)) {
            throw err;
        }
        const path = getPathFromLink(this.database.url, exports.ResourceType.container);
        const id = getIdFromLink(this.database.url);
        validateOffer(body);
        if (body.maxThroughput) {
            const autoscaleParams = {
                maxThroughput: body.maxThroughput,
            };
            if (body.autoUpgradePolicy) {
                autoscaleParams.autoUpgradePolicy = body.autoUpgradePolicy;
            }
            const autoscaleHeader = JSON.stringify(autoscaleParams);
            options.initialHeaders = Object.assign({}, options.initialHeaders, {
                [Constants.HttpHeaders.AutoscaleSettings]: autoscaleHeader,
            });
            delete body.maxThroughput;
            delete body.autoUpgradePolicy;
        }
        if (body.throughput) {
            options.initialHeaders = Object.assign({}, options.initialHeaders, {
                [Constants.HttpHeaders.OfferThroughput]: body.throughput,
            });
            delete body.throughput;
        }
        if (typeof body.partitionKey === "string") {
            if (!body.partitionKey.startsWith("/")) {
                throw new Error("Partition key must start with '/'");
            }
            body.partitionKey = {
                paths: [body.partitionKey],
            };
        }
        // If they don't specify a partition key, use the default path
        if (!body.partitionKey || !body.partitionKey.paths) {
            body.partitionKey = {
                paths: [DEFAULT_PARTITION_KEY_PATH],
            };
        }
        if (this.clientContext.enableEncryption && body.clientEncryptionPolicy) {
            body.clientEncryptionPolicy.policyFormatVersion =
                (_a = body.clientEncryptionPolicy.policyFormatVersion) !== null && _a !== void 0 ? _a : 1;
            validateClientEncryptionPolicy(body.clientEncryptionPolicy, body.partitionKey);
        }
        const response = await this.clientContext.create({
            body,
            path,
            resourceType: exports.ResourceType.container,
            resourceId: id,
            diagnosticNode,
            options,
        });
        const ref = new Container(this.database, response.result.id, this.clientContext, this.encryptionManager, response.result._rid);
        return new ContainerResponse(response.result, response.headers, response.code, ref, getEmptyCosmosDiagnostics());
    }
    /**
     * Checks if a Container exists, and, if it doesn't, creates it.
     * This will make a read operation based on the id in the `body`, then if it is not found, a create operation.
     * You should confirm that the output matches the body you passed in for non-default properties (i.e. indexing policy/etc.)
     *
     * A container is a named logical container for items.
     *
     * A database may contain zero or more named containers and each container consists of
     * zero or more JSON items.
     *
     * Being schema-free, the items in a container do not need to share the same structure or fields.
     *
     *
     * Since containers are application resources, they can be authorized using either the
     * master key or resource keys.
     *
     * @param body - Represents the body of the container.
     * @param options - Use to set options like response page size, continuation tokens, etc.
     */
    async createIfNotExists(body, options) {
        if (!body || body.id === null || body.id === undefined) {
            throw new Error("body parameter must be an object with an id property");
        }
        /*
          1. Attempt to read the Container (based on an assumption that most containers will already exist, so its faster)
          2. If it fails with NotFound error, attempt to create the container. Else, return the read results.
        */
        return withDiagnostics(async (diagnosticNode) => {
            try {
                const readResponse = await this.database
                    .container(body.id)
                    .readInternal(diagnosticNode, options);
                return readResponse;
            }
            catch (err) {
                if (err.code === StatusCodes.NotFound) {
                    const createResponse = await this.createInternal(diagnosticNode, body, options);
                    // Must merge the headers to capture RU costskaty
                    mergeHeaders(createResponse.headers, err.headers);
                    return createResponse;
                }
                else {
                    throw err;
                }
            }
        }, this.clientContext);
    }
    /**
     * Read all containers.
     * @param options - Use to set options like response page size, continuation tokens, etc.
     * @returns {@link QueryIterator} Allows you to return all containers in an array or iterate over them one at a time.
     * @example Read all containers to array.
     * ```typescript
     * const {body: containerList} = await client.database("<db id>").containers.readAll().fetchAll();
     * ```
     */
    readAll(options) {
        return this.query(undefined, options);
    }
}

class PermissionResponse extends ResourceResponse {
    constructor(resource, headers, statusCode, permission, diagnostics) {
        super(resource, headers, statusCode, diagnostics);
        this.permission = permission;
    }
}

/**
 * Use to read, replace, or delete a given {@link Permission} by id.
 *
 * @see {@link Permissions} to create, upsert, query, or read all Permissions.
 */
class Permission {
    /**
     * Returns a reference URL to the resource. Used for linking in Permissions.
     */
    get url() {
        return createPermissionUri(this.user.database.id, this.user.id, this.id);
    }
    /**
     * @hidden
     * @param user - The parent {@link User}.
     * @param id - The id of the given {@link Permission}.
     */
    constructor(user, id, clientContext) {
        this.user = user;
        this.id = id;
        this.clientContext = clientContext;
    }
    /**
     * Read the {@link PermissionDefinition} of the given {@link Permission}.
     */
    async read(options) {
        return withDiagnostics(async (diagnosticNode) => {
            const path = getPathFromLink(this.url);
            const id = getIdFromLink(this.url);
            const response = await this.clientContext.read({
                path,
                resourceType: exports.ResourceType.permission,
                resourceId: id,
                options,
                diagnosticNode,
            });
            return new PermissionResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * Replace the given {@link Permission} with the specified {@link PermissionDefinition}.
     * @param body - The specified {@link PermissionDefinition}.
     */
    async replace(body, options) {
        return withDiagnostics(async (diagnosticNode) => {
            const err = {};
            if (!isResourceValid(body, err)) {
                throw err;
            }
            const path = getPathFromLink(this.url);
            const id = getIdFromLink(this.url);
            const response = await this.clientContext.replace({
                body,
                path,
                resourceType: exports.ResourceType.permission,
                resourceId: id,
                options,
                diagnosticNode,
            });
            return new PermissionResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * Delete the given {@link Permission}.
     */
    async delete(options) {
        return withDiagnostics(async (diagnosticNode) => {
            const path = getPathFromLink(this.url);
            const id = getIdFromLink(this.url);
            const response = await this.clientContext.delete({
                path,
                resourceType: exports.ResourceType.permission,
                resourceId: id,
                options,
                diagnosticNode,
            });
            return new PermissionResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
}

/**
 * Use to create, replace, query, and read all Permissions.
 *
 * @see {@link Permission} to read, replace, or delete a specific permission by id.
 */
class Permissions {
    /**
     * @hidden
     * @param user - The parent {@link User}.
     */
    constructor(user, clientContext) {
        this.user = user;
        this.clientContext = clientContext;
    }
    query(query, options) {
        const path = getPathFromLink(this.user.url, exports.ResourceType.permission);
        const id = getIdFromLink(this.user.url);
        return new QueryIterator(this.clientContext, query, options, (diagnosticNode, innerOptions) => {
            return this.clientContext.queryFeed({
                path,
                resourceType: exports.ResourceType.permission,
                resourceId: id,
                resultFn: (result) => result.Permissions,
                query,
                options: innerOptions,
                diagnosticNode,
            });
        });
    }
    /**
     * Read all permissions.
     * @example Read all permissions to array.
     * ```typescript
     * const {body: permissionList} = await user.permissions.readAll().fetchAll();
     * ```
     */
    readAll(options) {
        return this.query(undefined, options);
    }
    /**
     * Create a permission.
     *
     * A permission represents a per-User Permission to access a specific resource
     * e.g. Item or Container.
     * @param body - Represents the body of the permission.
     */
    async create(body, options) {
        return withDiagnostics(async (diagnosticNode) => {
            const err = {};
            if (!isResourceValid(body, err)) {
                throw err;
            }
            const path = getPathFromLink(this.user.url, exports.ResourceType.permission);
            const id = getIdFromLink(this.user.url);
            const response = await this.clientContext.create({
                body,
                path,
                resourceType: exports.ResourceType.permission,
                resourceId: id,
                diagnosticNode,
                options,
            });
            const ref = new Permission(this.user, response.result.id, this.clientContext);
            return new PermissionResponse(response.result, response.headers, response.code, ref, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * Upsert a permission.
     *
     * A permission represents a per-User Permission to access a
     * specific resource e.g. Item or Container.
     */
    async upsert(body, options) {
        return withDiagnostics(async (diagnosticNode) => {
            const err = {};
            if (!isResourceValid(body, err)) {
                throw err;
            }
            const path = getPathFromLink(this.user.url, exports.ResourceType.permission);
            const id = getIdFromLink(this.user.url);
            const response = await this.clientContext.upsert({
                body,
                path,
                resourceType: exports.ResourceType.permission,
                resourceId: id,
                options,
                diagnosticNode,
            });
            const ref = new Permission(this.user, response.result.id, this.clientContext);
            return new PermissionResponse(response.result, response.headers, response.code, ref, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
}

class UserResponse extends ResourceResponse {
    constructor(resource, headers, statusCode, user, diagnostics) {
        super(resource, headers, statusCode, diagnostics);
        this.user = user;
    }
}

/**
 * Used to read, replace, and delete Users.
 *
 * Additionally, you can access the permissions for a given user via `user.permission` and `user.permissions`.
 *
 * @see {@link Users} to create, upsert, query, or read all.
 */
class User {
    /**
     * Returns a reference URL to the resource. Used for linking in Permissions.
     */
    get url() {
        return createUserUri(this.database.id, this.id);
    }
    /**
     * @hidden
     * @param database - The parent {@link Database}.
     */
    constructor(database, id, clientContext) {
        this.database = database;
        this.id = id;
        this.clientContext = clientContext;
        this.permissions = new Permissions(this, this.clientContext);
    }
    /**
     * Operations to read, replace, or delete a specific Permission by id.
     *
     * See `client.permissions` for creating, upserting, querying, or reading all operations.
     */
    permission(id) {
        return new Permission(this, id, this.clientContext);
    }
    /**
     * Read the {@link UserDefinition} for the given {@link User}.
     */
    async read(options) {
        return withDiagnostics(async (diagnosticNode) => {
            const path = getPathFromLink(this.url);
            const id = getIdFromLink(this.url);
            const response = await this.clientContext.read({
                path,
                resourceType: exports.ResourceType.user,
                resourceId: id,
                options,
                diagnosticNode,
            });
            return new UserResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * Replace the given {@link User}'s definition with the specified {@link UserDefinition}.
     * @param body - The specified {@link UserDefinition} to replace the definition.
     */
    async replace(body, options) {
        return withDiagnostics(async (diagnosticNode) => {
            const err = {};
            if (!isResourceValid(body, err)) {
                throw err;
            }
            const path = getPathFromLink(this.url);
            const id = getIdFromLink(this.url);
            const response = await this.clientContext.replace({
                body,
                path,
                resourceType: exports.ResourceType.user,
                resourceId: id,
                options,
                diagnosticNode,
            });
            return new UserResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * Delete the given {@link User}.
     */
    async delete(options) {
        return withDiagnostics(async (diagnosticNode) => {
            const path = getPathFromLink(this.url);
            const id = getIdFromLink(this.url);
            const response = await this.clientContext.delete({
                path,
                resourceType: exports.ResourceType.user,
                resourceId: id,
                options,
                diagnosticNode,
            });
            return new UserResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
}

/**
 * Used to create, upsert, query, and read all users.
 *
 * @see {@link User} to read, replace, or delete a specific User by id.
 */
class Users {
    /**
     * @hidden
     * @param database - The parent {@link Database}.
     */
    constructor(database, clientContext) {
        this.database = database;
        this.clientContext = clientContext;
    }
    query(query, options) {
        const path = getPathFromLink(this.database.url, exports.ResourceType.user);
        const id = getIdFromLink(this.database.url);
        return new QueryIterator(this.clientContext, query, options, (diagnosticNode, innerOptions) => {
            return this.clientContext.queryFeed({
                path,
                resourceType: exports.ResourceType.user,
                resourceId: id,
                resultFn: (result) => result.Users,
                query,
                options: innerOptions,
                diagnosticNode,
            });
        });
    }
    /**
     * Read all users.-
     * @example Read all users to array.
     * ```typescript
     * const {body: usersList} = await database.users.readAll().fetchAll();
     * ```
     */
    readAll(options) {
        return this.query(undefined, options);
    }
    /**
     * Create a database user with the specified {@link UserDefinition}.
     * @param body - The specified {@link UserDefinition}.
     */
    async create(body, options) {
        return withDiagnostics(async (diagnosticNode) => {
            const err = {};
            if (!isResourceValid(body, err)) {
                throw err;
            }
            const path = getPathFromLink(this.database.url, exports.ResourceType.user);
            const id = getIdFromLink(this.database.url);
            const response = await this.clientContext.create({
                body,
                path,
                resourceType: exports.ResourceType.user,
                resourceId: id,
                options,
                diagnosticNode,
            });
            const ref = new User(this.database, response.result.id, this.clientContext);
            return new UserResponse(response.result, response.headers, response.code, ref, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * Upsert a database user with a specified {@link UserDefinition}.
     * @param body - The specified {@link UserDefinition}.
     */
    async upsert(body, options) {
        return withDiagnostics(async (diagnosticNode) => {
            const err = {};
            if (!isResourceValid(body, err)) {
                throw err;
            }
            const path = getPathFromLink(this.database.url, exports.ResourceType.user);
            const id = getIdFromLink(this.database.url);
            const response = await this.clientContext.upsert({
                body,
                path,
                resourceType: exports.ResourceType.user,
                resourceId: id,
                options,
                diagnosticNode,
            });
            const ref = new User(this.database, response.result.id, this.clientContext);
            return new UserResponse(response.result, response.headers, response.code, ref, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
}

/** Response object for Database operations */
class DatabaseResponse extends ResourceResponse {
    constructor(resource, headers, statusCode, database, diagnostics) {
        super(resource, headers, statusCode, diagnostics);
        this.database = database;
    }
}

/**
 * Operations for reading or deleting an existing database.
 *
 * @see {@link Databases} for creating new databases, and reading/querying all databases; use `client.databases`.
 *
 * Note: all these operations make calls against a fixed budget.
 * You should design your system such that these calls scale sublinearly with your application.
 * For instance, do not call `database.read()` before every single `item.read()` call, to ensure the database exists;
 * do this once on application start up.
 */
class Database {
    /**
     * Returns a reference URL to the resource. Used for linking in Permissions.
     */
    get url() {
        return createDatabaseUri(this.id);
    }
    /** Returns a new {@link Database} instance.
     *
     * Note: the intention is to get this object from {@link CosmosClient} via `client.database(id)`, not to instantiate it yourself.
     * @hidden
     */
    constructor(client, id, clientContext, encryptionManager, _rid) {
        this.client = client;
        this.id = id;
        this.clientContext = clientContext;
        this.encryptionManager = encryptionManager;
        this.containers = new Containers(this, this.clientContext, this.encryptionManager);
        this.users = new Users(this, this.clientContext);
        this._rid = _rid;
    }
    /**
     * Used to read, replace, or delete a specific, existing {@link Database} by id.
     *
     * Use `.containers` creating new containers, or querying/reading all containers.
     *
     * @example Delete a container
     * ```typescript
     * await client.database("<db id>").container("<container id>").delete();
     * ```
     */
    container(id) {
        return new Container(this, id, this.clientContext, this.encryptionManager);
    }
    /**
     * Used to read, replace, or delete a specific, existing {@link User} by id.
     *
     * Use `.users` for creating new users, or querying/reading all users.
     */
    user(id) {
        return new User(this, id, this.clientContext);
    }
    /** Read the definition of the given Database. */
    async read(options) {
        return withDiagnostics(async (diagnosticNode) => {
            return this.readInternal(diagnosticNode, options);
        }, this.clientContext);
    }
    /**
     * @hidden
     */
    async readInternal(diagnosticNode, options) {
        const path = getPathFromLink(this.url);
        const id = getIdFromLink(this.url);
        const response = await this.clientContext.read({
            path,
            resourceType: exports.ResourceType.database,
            resourceId: id,
            options,
            diagnosticNode,
        });
        return new DatabaseResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
    }
    /** Delete the given Database. */
    async delete(options) {
        return withDiagnostics(async (diagnosticNode) => {
            const path = getPathFromLink(this.url);
            const id = getIdFromLink(this.url);
            const response = await this.clientContext.delete({
                path,
                resourceType: exports.ResourceType.database,
                resourceId: id,
                options,
                diagnosticNode,
            });
            return new DatabaseResponse(response.result, response.headers, response.code, this, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * Gets offer on database. If none exists, returns an OfferResponse with undefined.
     */
    async readOffer(options = {}) {
        return withDiagnostics(async (diagnosticNode) => {
            const { resource: record } = await withMetadataDiagnostics(async (node) => {
                return this.readInternal(node);
            }, diagnosticNode, exports.MetadataLookUpType.DatabaseLookUp);
            const path = "/offers";
            const url = record._self;
            const response = await this.clientContext.queryFeed({
                path,
                resourceId: "",
                resourceType: exports.ResourceType.offer,
                query: `SELECT * from root where root.resource = "${url}"`,
                resultFn: (result) => result.Offers,
                options,
                diagnosticNode,
            });
            const offer = response.result[0]
                ? new Offer(this.client, response.result[0].id, this.clientContext)
                : undefined;
            return new OfferResponse(response.result[0], response.headers, response.code, getEmptyCosmosDiagnostics(), offer);
        }, this.clientContext);
    }
    /**
     * Create Encryption key for database account
     */
    async createClientEncryptionKey(clientEncryptionKeyId, encryptionAlgorithm, keyWrapMetadata) {
        if (clientEncryptionKeyId == null || !clientEncryptionKeyId.trim()) {
            throw new Error("encryption key id cannot be null or empty");
        }
        if (encryptionAlgorithm !== exports.EncryptionAlgorithm.AEAD_AES_256_CBC_HMAC_SHA256) {
            throw new Error(`Invalid encryption algorithm '${encryptionAlgorithm}' passed.`);
        }
        if (!keyWrapMetadata) {
            throw new Error("encryptionKeyWrapMetadata cannot be null.");
        }
        if (keyWrapMetadata.algorithm !== exports.KeyEncryptionAlgorithm.RSA_OAEP) {
            throw new Error(`Invalid key wrap algorithm '${keyWrapMetadata.algorithm}' passed.`);
        }
        if (!this.clientContext.enableEncryption) {
            throw new Error("Creating a client encryption key requires the use of an encryption-enabled client.");
        }
        const keyEncryptionKey = this.encryptionManager.keyEncryptionKeyCache.getOrCreate(keyWrapMetadata.name, keyWrapMetadata.value, this.encryptionManager.encryptionKeyStoreProvider);
        const protectedDataEncryptionKey = await this.encryptionManager.protectedDataEncryptionKeyCache.getOrCreate(clientEncryptionKeyId, keyEncryptionKey);
        const wrappedDataEncryptionKey = protectedDataEncryptionKey.encryptedValue;
        const body = {
            id: clientEncryptionKeyId,
            encryptionAlgorithm: encryptionAlgorithm,
            keyWrapMetadata: keyWrapMetadata,
            wrappedDataEncryptionKey: wrappedDataEncryptionKey.toString("base64"),
        };
        return withDiagnostics(async (diagnosticNode) => {
            const path = getPathFromLink(this.url, exports.ResourceType.clientencryptionkey);
            const databaseId = getIdFromLink(this.url);
            const response = await this.clientContext.create({
                body,
                path: path,
                resourceType: exports.ResourceType.clientencryptionkey,
                resourceId: databaseId,
                diagnosticNode,
            });
            const ref = {
                id: response.result.id,
                encryptionAlgorithm: response.result.encryptionAlgorithm,
                etag: response.result._etag,
                wrappedDataEncryptionKey: new Uint8Array(Buffer.from(response.result.wrappedDataEncryptionKey, "base64")),
                encryptionKeyWrapMetadata: response.result.keyWrapMetadata,
            };
            return new ClientEncryptionKeyResponse(response.result, response.headers, response.code, ref, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * Read Encryption key for database account
     */
    async readClientEncryptionKey(clientEncryptionKeyId) {
        if (clientEncryptionKeyId == null || !clientEncryptionKeyId.trim()) {
            throw new ErrorResponse("encryption key id cannot be null or empty");
        }
        return withDiagnostics(async (diagnosticNode) => {
            if (!this._rid) {
                const databaseResponse = await this.readInternal(diagnosticNode);
                if (!databaseResponse || !databaseResponse.resource) {
                    throw new ErrorResponse(`Error reading database with id ${clientEncryptionKeyId}`);
                }
                this._rid = databaseResponse.resource._rid;
            }
            const path = getPathFromLink(this.url, exports.ResourceType.clientencryptionkey);
            const resourceid = getIdFromLink(this.url);
            const response = await this.clientContext.read({
                path: path + `/${clientEncryptionKeyId}`,
                resourceType: exports.ResourceType.clientencryptionkey,
                resourceId: resourceid + `/${exports.ResourceType.clientencryptionkey}/${clientEncryptionKeyId}`,
                options: { databaseRid: this._rid },
                diagnosticNode,
            });
            if (!response || !response.result) {
                throw new ErrorResponse(`Error reading client encryption key with id ${clientEncryptionKeyId}`);
            }
            const ref = {
                id: response.result.id,
                encryptionAlgorithm: response.result.encryptionAlgorithm,
                etag: response.result._etag,
                wrappedDataEncryptionKey: new Uint8Array(Buffer.from(response.result.wrappedDataEncryptionKey, "base64")),
                encryptionKeyWrapMetadata: response.result.keyWrapMetadata,
            };
            return new ClientEncryptionKeyResponse(response.result, response.headers, response.code, ref, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
    /**
     * rewraps a client encryption key with new key encryption key
     * @param id - client encryption key id
     * @param newKeyWrapMetadata - new encryption key wrap metadata
     * @returns rewrapped client encryption key with new customer managed key
     */
    async rewrapClientEncryptionKey(clientEncryptionKeyId, newKeyWrapMetadata) {
        if (clientEncryptionKeyId == null || !clientEncryptionKeyId.trim()) {
            throw new ErrorResponse("encryption key id cannot be null or empty");
        }
        if (!newKeyWrapMetadata) {
            throw new ErrorResponse("encryptionKeyWrapMetadata cannot be null.");
        }
        if (newKeyWrapMetadata.algorithm !== exports.KeyEncryptionAlgorithm.RSA_OAEP) {
            throw new ErrorResponse(`Invalid key wrap algorithm '${newKeyWrapMetadata.algorithm}' passed.`);
        }
        if (!this.clientContext.enableEncryption) {
            throw new ErrorResponse("Rewrapping a client encryption key requires the use of an encryption-enabled client.");
        }
        const res = await this.readClientEncryptionKey(clientEncryptionKeyId);
        if (!res || !res.clientEncryptionKeyProperties) {
            throw new ErrorResponse(`Error reading client encryption key with id ${clientEncryptionKeyId}`);
        }
        let clientEncryptionKeyProperties = res.clientEncryptionKeyProperties;
        let keyEncryptionKey = this.encryptionManager.keyEncryptionKeyCache.getOrCreate(clientEncryptionKeyProperties.encryptionKeyWrapMetadata.name, clientEncryptionKeyProperties.encryptionKeyWrapMetadata.value, this.encryptionManager.encryptionKeyStoreProvider);
        const unwrappedKey = await keyEncryptionKey.unwrapEncryptionKey(Buffer.from(clientEncryptionKeyProperties.wrappedDataEncryptionKey));
        keyEncryptionKey = this.encryptionManager.keyEncryptionKeyCache.getOrCreate(newKeyWrapMetadata.name, newKeyWrapMetadata.value, this.encryptionManager.encryptionKeyStoreProvider);
        const rewrappedKey = await keyEncryptionKey.wrapEncryptionKey(unwrappedKey);
        clientEncryptionKeyProperties = {
            id: clientEncryptionKeyId,
            encryptionAlgorithm: clientEncryptionKeyProperties.encryptionAlgorithm,
            etag: clientEncryptionKeyProperties.etag,
            wrappedDataEncryptionKey: rewrappedKey,
            encryptionKeyWrapMetadata: newKeyWrapMetadata,
        };
        const body = {
            id: clientEncryptionKeyId,
            encryptionAlgorithm: clientEncryptionKeyProperties.encryptionAlgorithm,
            keyWrapMetadata: newKeyWrapMetadata,
            wrappedDataEncryptionKey: rewrappedKey.toString("base64"),
        };
        return withDiagnostics(async (diagnosticNode) => {
            const path = getPathFromLink(this.url, exports.ResourceType.clientencryptionkey);
            const resourceid = getIdFromLink(this.url);
            const options = {
                accessCondition: { type: "IfMatch", condition: clientEncryptionKeyProperties.etag },
            };
            const response = await this.clientContext.replace({
                body,
                path: path + `/${clientEncryptionKeyId}`,
                resourceType: exports.ResourceType.clientencryptionkey,
                resourceId: resourceid + `/${exports.ResourceType.clientencryptionkey}/${clientEncryptionKeyId}`,
                options,
                diagnosticNode,
            });
            if (!response || !response.result) {
                throw new ErrorResponse(`Error rewrapping client encryption key with id ${clientEncryptionKeyId}`);
            }
            const ref = {
                id: response.result.id,
                encryptionAlgorithm: response.result.encryptionAlgorithm,
                etag: response.result._etag,
                wrappedDataEncryptionKey: new Uint8Array(Buffer.from(response.result.wrappedDataEncryptionKey, "base64")),
                encryptionKeyWrapMetadata: response.result.keyWrapMetadata,
            };
            return new ClientEncryptionKeyResponse(response.result, response.headers, response.code, ref, getEmptyCosmosDiagnostics());
        }, this.clientContext);
    }
}

/**
 * Operations for creating new databases, and reading/querying all databases
 *
 * @see {@link Database} for reading or deleting an existing database; use `client.database(id)`.
 *
 * Note: all these operations make calls against a fixed budget.
 * You should design your system such that these calls scale sublinearly with your application.
 * For instance, do not call `databases.readAll()` before every single `item.read()` call, to ensure the database exists;
 * do this once on application start up.
 */
class Databases {
    /**
     * @hidden
     * @param client - The parent {@link CosmosClient} for the Database.
     */
    constructor(client, clientContext, encryptionManager) {
        this.client = client;
        this.clientContext = clientContext;
        this.encryptionManager = encryptionManager;
    }
    query(query, options) {
        const cb = (diagNode, innerOptions) => {
            return this.clientContext.queryFeed({
                path: "/dbs",
                resourceType: exports.ResourceType.database,
                resourceId: "",
                resultFn: (result) => result.Databases,
                query,
                options: innerOptions,
                diagnosticNode: diagNode,
            });
        };
        return new QueryIterator(this.clientContext, query, options, cb);
    }
    /**
     * Send a request for creating a database.
     *
     * A database manages users, permissions and a set of containers.
     * Each Azure Cosmos DB Database Account is able to support multiple independent named databases,
     * with the database being the logical container for data.
     *
     * Each Database consists of one or more containers, each of which in turn contain one or more
     * documents. Since databases are an administrative resource, the Service Master Key will be
     * required in order to access and successfully complete any action using the User APIs.
     *
     * @param body - The {@link DatabaseDefinition} that represents the {@link Database} to be created.
     * @param options - Use to set options like response page size, continuation tokens, etc.
     */
    async create(body, options = {}) {
        return withDiagnostics(async (diagnosticNode) => {
            return this.createInternal(diagnosticNode, body, options);
        }, this.clientContext);
    }
    /**
     * @hidden
     */
    async createInternal(diagnosticNode, body, options = {}) {
        const err = {};
        if (!isResourceValid(body, err)) {
            throw err;
        }
        validateOffer(body);
        if (body.maxThroughput) {
            const autoscaleParams = {
                maxThroughput: body.maxThroughput,
            };
            if (body.autoUpgradePolicy) {
                autoscaleParams.autoUpgradePolicy = body.autoUpgradePolicy;
            }
            const autoscaleHeaders = JSON.stringify(autoscaleParams);
            options.initialHeaders = Object.assign({}, options.initialHeaders, {
                [Constants.HttpHeaders.AutoscaleSettings]: autoscaleHeaders,
            });
            delete body.maxThroughput;
            delete body.autoUpgradePolicy;
        }
        if (body.throughput) {
            options.initialHeaders = Object.assign({}, options.initialHeaders, {
                [Constants.HttpHeaders.OfferThroughput]: body.throughput,
            });
            delete body.throughput;
        }
        const path = "/dbs"; // TODO: constant
        const response = await this.clientContext.create({
            body,
            path,
            resourceType: exports.ResourceType.database,
            resourceId: undefined,
            diagnosticNode,
            options,
        });
        const ref = new Database(this.client, body.id, this.clientContext, this.encryptionManager, response.result._rid);
        return new DatabaseResponse(response.result, response.headers, response.code, ref, getEmptyCosmosDiagnostics());
    }
    /**
     * Check if a database exists, and if it doesn't, create it.
     * This will make a read operation based on the id in the `body`, then if it is not found, a create operation.
     *
     * A database manages users, permissions and a set of containers.
     * Each Azure Cosmos DB Database Account is able to support multiple independent named databases,
     * with the database being the logical container for data.
     *
     * Each Database consists of one or more containers, each of which in turn contain one or more
     * documents. Since databases are an an administrative resource, the Service Master Key will be
     * required in order to access and successfully complete any action using the User APIs.
     *
     * @param body - The {@link DatabaseDefinition} that represents the {@link Database} to be created.
     * @param options - Additional options for the request
     */
    async createIfNotExists(body, options) {
        if (!body || body.id === null || body.id === undefined) {
            throw new Error("body parameter must be an object with an id property");
        }
        /*
          1. Attempt to read the Database (based on an assumption that most databases will already exist, so its faster)
          2. If it fails with NotFound error, attempt to create the db. Else, return the read results.
        */
        return withDiagnostics(async (diagnosticNode) => {
            try {
                const readResponse = await this.client
                    .database(body.id)
                    .readInternal(diagnosticNode, options);
                return readResponse;
            }
            catch (err) {
                if (err.code === StatusCodes.NotFound) {
                    const createResponse = await this.createInternal(diagnosticNode, body, options);
                    // Must merge the headers to capture RU costskaty
                    mergeHeaders(createResponse.headers, err.headers);
                    return createResponse;
                }
                else {
                    throw err;
                }
            }
        }, this.clientContext);
    }
    // TODO: DatabaseResponse for QueryIterator?
    /**
     * Reads all databases.
     * @param options - Use to set options like response page size, continuation tokens, etc.
     * @returns {@link QueryIterator} Allows you to return all databases in an array or iterate over them one at a time.
     * @example Read all databases to array.
     * ```typescript
     * const {body: databaseList} = await client.databases.readAll().fetchAll();
     * ```
     */
    readAll(options) {
        return this.query(undefined, options);
    }
}

/**
 * Used to specify which type of events to execute this plug in on.
 *
 * @hidden
 */
exports.PluginOn = void 0;
(function (PluginOn) {
    /**
     * Will be executed per network request
     */
    PluginOn["request"] = "request";
    /**
     * Will be executed per API operation
     */
    PluginOn["operation"] = "operation";
})(exports.PluginOn || (exports.PluginOn = {}));
/**
 * @internal
 */
async function executePlugins(diagnosticNode, requestContext, next, on) {
    if (!requestContext.plugins) {
        return next(requestContext, diagnosticNode, undefined);
    }
    let level = 0;
    const _ = (inner) => {
        if (++level >= inner.plugins.length) {
            return next(requestContext, diagnosticNode, undefined);
        }
        else if (inner.plugins[level].on !== on) {
            return _(requestContext);
        }
        else {
            return inner.plugins[level].plugin(inner, diagnosticNode, _);
        }
    };
    if (requestContext.plugins[level].on !== on) {
        return _(requestContext);
    }
    else {
        return requestContext.plugins[level].plugin(requestContext, diagnosticNode, _);
    }
}

/**
 * @hidden
 */
// Windows Socket Error Codes
const WindowsInterruptedFunctionCall = 10004;
/**
 * @hidden
 */
const WindowsFileHandleNotValid = 10009;
/**
 * @hidden
 */
const WindowsPermissionDenied = 10013;
/**
 * @hidden
 */
const WindowsBadAddress = 10014;
/**
 * @hidden
 */
const WindowsInvalidArgumnet = 10022;
/**
 * @hidden
 */
const WindowsResourceTemporarilyUnavailable = 10035;
/**
 * @hidden
 */
const WindowsOperationNowInProgress = 10036;
/**
 * @hidden
 */
const WindowsAddressAlreadyInUse = 10048;
/**
 * @hidden
 */
const WindowsConnectionResetByPeer = 10054;
/**
 * @hidden
 */
const WindowsCannotSendAfterSocketShutdown = 10058;
/**
 * @hidden
 */
const WindowsConnectionTimedOut = 10060;
/**
 * @hidden
 */
const WindowsConnectionRefused = 10061;
/**
 * @hidden
 */
const WindowsNameTooLong = 10063;
/**
 * @hidden
 */
const WindowsHostIsDown = 10064;
/**
 * @hidden
 */
const WindowsNoRouteTohost = 10065;
/**
 * @hidden
 */
// Linux Error Codes
/**
 * @hidden
 */
const LinuxConnectionReset = "ECONNRESET";
// Node Error Codes
/**
 * @hidden
 */
const BrokenPipe = "EPIPE";
/**
 * @hidden
 */
const CONNECTION_ERROR_CODES = [
    WindowsInterruptedFunctionCall,
    WindowsFileHandleNotValid,
    WindowsPermissionDenied,
    WindowsBadAddress,
    WindowsInvalidArgumnet,
    WindowsResourceTemporarilyUnavailable,
    WindowsOperationNowInProgress,
    WindowsAddressAlreadyInUse,
    WindowsConnectionResetByPeer,
    WindowsCannotSendAfterSocketShutdown,
    WindowsConnectionTimedOut,
    WindowsConnectionRefused,
    WindowsNameTooLong,
    WindowsHostIsDown,
    WindowsNoRouteTohost,
    LinuxConnectionReset,
    TimeoutErrorCode,
    BrokenPipe,
];
/**
 * @hidden
 */
function needsRetry(operationType, code) {
    if ((operationType === exports.OperationType.Read || operationType === exports.OperationType.Query) &&
        CONNECTION_ERROR_CODES.indexOf(code) !== -1) {
        return true;
    }
    else {
        return false;
    }
}
/**
 * This class implements the default connection retry policy for requests.
 * @hidden
 */
class DefaultRetryPolicy {
    constructor(operationType) {
        this.operationType = operationType;
        this.maxTries = 10;
        this.currentRetryAttemptCount = 0;
        this.retryAfterInMs = 1000;
    }
    /**
     * Determines whether the request should be retried or not.
     * @param err - Error returned by the request.
     */
    async shouldRetry(err, diagnosticNode) {
        if (err) {
            if (this.currentRetryAttemptCount < this.maxTries &&
                needsRetry(this.operationType, err.code)) {
                diagnosticNode.addData({ successfulRetryPolicy: "default" });
                this.currentRetryAttemptCount++;
                return true;
            }
        }
        return false;
    }
}

/**
 * This class implements the retry policy for endpoint discovery.
 * @hidden
 */
class EndpointDiscoveryRetryPolicy {
    /**
     * @param globalEndpointManager - The GlobalEndpointManager instance.
     */
    constructor(globalEndpointManager, operationType) {
        this.globalEndpointManager = globalEndpointManager;
        this.operationType = operationType;
        this.maxTries = EndpointDiscoveryRetryPolicy.maxTries;
        this.currentRetryAttemptCount = 0;
        this.retryAfterInMs = EndpointDiscoveryRetryPolicy.retryAfterInMs;
    }
    /**
     * Determines whether the request should be retried or not.
     * @param err - Error returned by the request.
     */
    async shouldRetry(err, diagnosticNode, retryContext, locationEndpoint) {
        if (!err) {
            return false;
        }
        if (!retryContext || !locationEndpoint) {
            return false;
        }
        if (!this.globalEndpointManager.enableEndpointDiscovery) {
            return false;
        }
        if (this.currentRetryAttemptCount >= this.maxTries) {
            return false;
        }
        this.currentRetryAttemptCount++;
        if (isReadRequest(this.operationType)) {
            await this.globalEndpointManager.markCurrentLocationUnavailableForRead(diagnosticNode, locationEndpoint);
        }
        else {
            await this.globalEndpointManager.markCurrentLocationUnavailableForWrite(diagnosticNode, locationEndpoint);
        }
        retryContext.retryCount = this.currentRetryAttemptCount;
        retryContext.clearSessionTokenNotAvailable = false;
        retryContext.retryRequestOnPreferredLocations = false;
        diagnosticNode.addData({ successfulRetryPolicy: "endpointDiscovery" });
        return true;
    }
}
EndpointDiscoveryRetryPolicy.maxTries = 120; // TODO: Constant?
EndpointDiscoveryRetryPolicy.retryAfterInMs = 1000;

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * This class implements the resource throttle retry policy for requests.
 * @hidden
 */
class ResourceThrottleRetryPolicy {
    constructor(options) {
        var _a, _b, _c;
        /** Current retry attempt count. */
        this.currentRetryAttemptCount = 0;
        /** Cummulative wait time in milliseconds for a request while the retries are happening. */
        this.cummulativeWaitTimeinMs = 0;
        /** Retry interval in milliseconds to wait before the next request will be sent. */
        this.retryAfterInMs = 0;
        this.maxTries = (_a = options.maxRetryAttemptCount) !== null && _a !== void 0 ? _a : Constants.ThrottledRequestMaxRetryAttemptCount;
        this.fixedRetryIntervalInMs =
            (_b = options.fixedRetryIntervalInMilliseconds) !== null && _b !== void 0 ? _b : Constants.ThrottledRequestFixedRetryIntervalInMs;
        const timeoutInSeconds = (_c = options.maxWaitTimeInSeconds) !== null && _c !== void 0 ? _c : Constants.ThrottledRequestMaxWaitTimeInSeconds;
        this.timeoutInMs = timeoutInSeconds * 1000;
        this.currentRetryAttemptCount = 0;
        this.cummulativeWaitTimeinMs = 0;
    }
    /**
     * Determines whether the request should be retried or not.
     * @param err - Error returned by the request.
     */
    async shouldRetry(err, diagnosticNode) {
        // TODO: any custom error object
        if (err) {
            if (this.currentRetryAttemptCount < this.maxTries) {
                this.currentRetryAttemptCount++;
                this.retryAfterInMs = 0;
                if (this.fixedRetryIntervalInMs) {
                    this.retryAfterInMs = this.fixedRetryIntervalInMs;
                }
                else if (err.retryAfterInMs) {
                    this.retryAfterInMs = err.retryAfterInMs;
                }
                if (this.cummulativeWaitTimeinMs < this.timeoutInMs) {
                    this.cummulativeWaitTimeinMs += this.retryAfterInMs;
                    diagnosticNode.addData({ successfulRetryPolicy: "resourceThrottle" });
                    return true;
                }
            }
        }
        return false;
    }
}

/**
 * This class implements the retry policy for session consistent reads.
 * @hidden
 */
class SessionRetryPolicy {
    /**
     * @param globalEndpointManager - The GlobalEndpointManager instance.
     */
    constructor(globalEndpointManager, resourceType, operationType, connectionPolicy) {
        this.globalEndpointManager = globalEndpointManager;
        this.resourceType = resourceType;
        this.operationType = operationType;
        this.connectionPolicy = connectionPolicy;
        /** Current retry attempt count. */
        this.currentRetryAttemptCount = 0;
        /** Retry interval in milliseconds. */
        this.retryAfterInMs = 0;
    }
    /**
     * Determines whether the request should be retried or not.
     * @param err - Error returned by the request.
     * @param callback - The callback function which takes bool argument which specifies whether the request
     * will be retried or not.
     */
    async shouldRetry(err, diagnosticNode, retryContext) {
        if (!err) {
            return false;
        }
        if (!retryContext) {
            return false;
        }
        if (!this.connectionPolicy.enableEndpointDiscovery) {
            return false;
        }
        if (this.globalEndpointManager.canUseMultipleWriteLocations(this.resourceType, this.operationType)) {
            // If we can write to multiple locations, we should against every write endpoint until we succeed
            const endpoints = isReadRequest(this.operationType)
                ? await this.globalEndpointManager.getReadEndpoints()
                : await this.globalEndpointManager.getWriteEndpoints();
            if (this.currentRetryAttemptCount > endpoints.length) {
                return false;
            }
            else {
                this.currentRetryAttemptCount++;
                retryContext.retryCount++;
                retryContext.retryRequestOnPreferredLocations = this.currentRetryAttemptCount > 1;
                retryContext.clearSessionTokenNotAvailable =
                    this.currentRetryAttemptCount === endpoints.length;
                diagnosticNode.addData({ successfulRetryPolicy: "session" });
                return true;
            }
        }
        else {
            if (this.currentRetryAttemptCount > 1) {
                return false;
            }
            else {
                this.currentRetryAttemptCount++;
                retryContext.retryCount++;
                retryContext.retryRequestOnPreferredLocations = false; // Forces all operations to primary write endpoint
                retryContext.clearSessionTokenNotAvailable = true;
                diagnosticNode.addData({ successfulRetryPolicy: "session" });
                return true;
            }
        }
    }
}

/**
 * This class TimeoutFailoverRetryPolicy handles retries for read operations
 * (including data plane,metadata, and query plan) in case of request timeouts
 * (TimeoutError) or service unavailability (503 status code) by performing failover
 * and retrying on other regions.
 * @hidden
 */
class TimeoutFailoverRetryPolicy {
    constructor(globalEndpointManager, headers, methodType, resourceType, operationType, enableEndPointDiscovery) {
        this.globalEndpointManager = globalEndpointManager;
        this.headers = headers;
        this.methodType = methodType;
        this.resourceType = resourceType;
        this.operationType = operationType;
        this.enableEndPointDiscovery = enableEndPointDiscovery;
        this.maxRetryAttemptCount = 120;
        this.maxServiceUnavailableRetryCount = 1;
        this.retryAfterInMs = 0;
        this.failoverRetryCount = 0;
    }
    /**
     * Checks if a timeout request is valid for the timeout failover retry policy.
     * A valid request should be a data plane, metadata, or query plan request.
     * @returns
     */
    isValidRequestForTimeoutError() {
        const isQuery = Constants.HttpHeaders.IsQuery in this.headers;
        const isQueryPlan = Constants.HttpHeaders.IsQueryPlan in this.headers;
        if (this.methodType === exports.HTTPMethod.get || isQuery || isQueryPlan) {
            return true;
        }
        return false;
    }
    async shouldRetry(err, diagnosticNode, retryContext, locationEndpoint) {
        if (!err) {
            return false;
        }
        if (!retryContext || !locationEndpoint) {
            return false;
        }
        // Check if the error is a timeout error (TimeoutErrorCode) and if it is not a valid HTTP network timeout request
        if (err.code === TimeoutErrorCode && !this.isValidRequestForTimeoutError()) {
            return false;
        }
        if (!this.enableEndPointDiscovery) {
            return false;
        }
        if (err.code === StatusCodes.ServiceUnavailable &&
            this.failoverRetryCount >= this.maxServiceUnavailableRetryCount) {
            return false;
        }
        if (this.failoverRetryCount >= this.maxRetryAttemptCount) {
            return false;
        }
        const canUseMultipleWriteLocations = this.globalEndpointManager.canUseMultipleWriteLocations(this.resourceType, this.operationType);
        const readRequest = isReadRequest(this.operationType);
        if (!canUseMultipleWriteLocations && !readRequest) {
            // Write requests on single master cannot be retried, no other regions available
            return false;
        }
        this.failoverRetryCount++;
        // Setting the retryLocationIndex to the next available location for retry.
        // The retryLocationIndex is determined based on the failoverRetryCount, starting from zero.
        retryContext.retryLocationServerIndex = await this.findEndpointIndex(this.failoverRetryCount);
        diagnosticNode.addData({ successfulRetryPolicy: "timeout-failover" });
        return true;
    }
    /**
     * Determines index of endpoint to be used for retry based upon failoverRetryCount and avalable locations
     * @param failoverRetryCount - count of failovers
     * @returns
     */
    async findEndpointIndex(failoverRetryCount) {
        // count of preferred locations specified by user
        const preferredLocationsCount = this.globalEndpointManager.preferredLocationsCount;
        const readRequest = isReadRequest(this.operationType);
        let endpointIndex = 0;
        // If preferredLocationsCount is not zero, it indicates that the user has specified preferred locations.
        if (preferredLocationsCount !== 0) {
            // The endpointIndex is set based on the preferred location and the failover retry count.
            endpointIndex = failoverRetryCount % preferredLocationsCount;
        }
        else {
            // In the absence of preferred locations, the endpoint selection is based on the failover count and the number of available locations.
            if (readRequest) {
                const getReadEndpoints = await this.globalEndpointManager.getReadEndpoints();
                if (getReadEndpoints && getReadEndpoints.length > 0) {
                    endpointIndex = failoverRetryCount % getReadEndpoints.length;
                }
            }
            else {
                const getWriteEndpoints = await this.globalEndpointManager.getWriteEndpoints();
                if (getWriteEndpoints && getWriteEndpoints.length > 0) {
                    endpointIndex = failoverRetryCount % getWriteEndpoints.length;
                }
            }
        }
        return endpointIndex;
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @hidden
 */
async function execute({ diagnosticNode, retryContext = { retryCount: 0 }, retryPolicies, requestContext, executeRequest, }) {
    // TODO: any response
    return addDignosticChild(async (localDiagnosticNode) => {
        var _a;
        localDiagnosticNode.addData({ requestAttempNumber: retryContext.retryCount });
        if (!retryPolicies) {
            retryPolicies = {
                endpointDiscoveryRetryPolicy: new EndpointDiscoveryRetryPolicy(requestContext.globalEndpointManager, requestContext.operationType),
                resourceThrottleRetryPolicy: new ResourceThrottleRetryPolicy((_a = requestContext.connectionPolicy.retryOptions) !== null && _a !== void 0 ? _a : {}),
                sessionReadRetryPolicy: new SessionRetryPolicy(requestContext.globalEndpointManager, requestContext.resourceType, requestContext.operationType, requestContext.connectionPolicy),
                defaultRetryPolicy: new DefaultRetryPolicy(requestContext.operationType),
                timeoutFailoverRetryPolicy: new TimeoutFailoverRetryPolicy(requestContext.globalEndpointManager, requestContext.headers, requestContext.method, requestContext.resourceType, requestContext.operationType, requestContext.connectionPolicy.enableEndpointDiscovery),
            };
        }
        if (retryContext && retryContext.clearSessionTokenNotAvailable) {
            requestContext.client.clearSessionToken(requestContext.path);
            delete requestContext.headers["x-ms-session-token"];
        }
        if (retryContext && retryContext.retryLocationServerIndex) {
            requestContext.endpoint = await requestContext.globalEndpointManager.resolveServiceEndpoint(localDiagnosticNode, requestContext.resourceType, requestContext.operationType, retryContext.retryLocationServerIndex);
        }
        else {
            requestContext.endpoint = await requestContext.globalEndpointManager.resolveServiceEndpoint(localDiagnosticNode, requestContext.resourceType, requestContext.operationType);
        }
        const startTimeUTCInMs = getCurrentTimestampInMs();
        const correlatedActivityId = requestContext.headers[Constants.HttpHeaders.CorrelatedActivityId];
        try {
            const response = await executeRequest(localDiagnosticNode, requestContext);
            response.headers[Constants.ThrottleRetryCount] =
                retryPolicies.resourceThrottleRetryPolicy.currentRetryAttemptCount;
            response.headers[Constants.ThrottleRetryWaitTimeInMs] =
                retryPolicies.resourceThrottleRetryPolicy.cummulativeWaitTimeinMs;
            if (correlatedActivityId) {
                response.headers[Constants.HttpHeaders.CorrelatedActivityId] = correlatedActivityId;
            }
            return response;
        }
        catch (err) {
            // TODO: any error
            let retryPolicy = null;
            const headers = err.headers || {};
            if (correlatedActivityId) {
                headers[Constants.HttpHeaders.CorrelatedActivityId] = correlatedActivityId;
            }
            if (err.code === StatusCodes.ENOTFOUND ||
                err.code === "REQUEST_SEND_ERROR" ||
                (err.code === StatusCodes.Forbidden &&
                    (err.substatus === SubStatusCodes.DatabaseAccountNotFound ||
                        err.substatus === SubStatusCodes.WriteForbidden))) {
                retryPolicy = retryPolicies.endpointDiscoveryRetryPolicy;
            }
            else if (err.code === StatusCodes.TooManyRequests) {
                retryPolicy = retryPolicies.resourceThrottleRetryPolicy;
            }
            else if (err.code === StatusCodes.NotFound &&
                err.substatus === SubStatusCodes.ReadSessionNotAvailable) {
                retryPolicy = retryPolicies.sessionReadRetryPolicy;
            }
            else if (err.code === StatusCodes.ServiceUnavailable || err.code === TimeoutErrorCode) {
                retryPolicy = retryPolicies.timeoutFailoverRetryPolicy;
            }
            else {
                retryPolicy = retryPolicies.defaultRetryPolicy;
            }
            const results = await retryPolicy.shouldRetry(err, localDiagnosticNode, retryContext, requestContext.endpoint);
            if (!results) {
                headers[Constants.ThrottleRetryCount] =
                    retryPolicies.resourceThrottleRetryPolicy.currentRetryAttemptCount;
                headers[Constants.ThrottleRetryWaitTimeInMs] =
                    retryPolicies.resourceThrottleRetryPolicy.cummulativeWaitTimeinMs;
                err.headers = Object.assign(Object.assign({}, err.headers), headers);
                throw err;
            }
            else {
                requestContext.retryCount++;
                const newUrl = results[1]; // TODO: any hack
                if (newUrl !== undefined) {
                    requestContext.endpoint = newUrl;
                }
                localDiagnosticNode.recordFailedNetworkCall(startTimeUTCInMs, requestContext, retryContext.retryCount, err.code, err.subsstatusCode, headers);
                await sleep(retryPolicy.retryAfterInMs);
                return execute({
                    diagnosticNode,
                    executeRequest,
                    requestContext,
                    retryContext,
                    retryPolicies,
                });
            }
        }
    }, diagnosticNode, exports.DiagnosticNodeType.HTTP_REQUEST);
}

/**
 * @hidden
 */
let defaultHttpsAgent;
const https = require("https"); // eslint-disable-line @typescript-eslint/no-require-imports
const tls = require("tls"); // eslint-disable-line @typescript-eslint/no-require-imports
// minVersion only available in Node 10+
if (tls.DEFAULT_MIN_VERSION) {
    defaultHttpsAgent = new https.Agent({
        keepAlive: true,
        minVersion: "TLSv1.2",
    });
}
else {
    // Remove when Node 8 support has been dropped
    defaultHttpsAgent = new https.Agent({
        keepAlive: true,
        secureProtocol: "TLSv1_2_method",
    });
}
const http = require("http"); // eslint-disable-line @typescript-eslint/no-require-imports
/**
 * @internal
 */
const defaultHttpAgent = new http.Agent({
    keepAlive: true,
});

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
let cachedHttpClient;
function getCachedDefaultHttpClient() {
    if (!cachedHttpClient) {
        cachedHttpClient = coreRestPipeline.createDefaultHttpClient();
    }
    return cachedHttpClient;
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
const logger$1 = logger$5.createClientLogger("RequestHandler");
async function executeRequest(diagnosticNode, requestContext) {
    return executePlugins(diagnosticNode, requestContext, httpRequest, exports.PluginOn.request);
}
/**
 * @hidden
 */
async function httpRequest(requestContext, diagnosticNode) {
    var _a;
    const controller = new AbortController();
    const signal = controller.signal;
    // Wrap users passed abort events and call our own internal abort()
    const userSignal = requestContext.options && requestContext.options.abortSignal;
    if (userSignal) {
        if (userSignal.aborted) {
            controller.abort();
        }
        else {
            userSignal.addEventListener("abort", () => {
                controller.abort();
            });
        }
    }
    const timeout = setTimeout(() => {
        controller.abort();
    }, requestContext.connectionPolicy.requestTimeout);
    let response;
    if (requestContext.body) {
        requestContext.body = bodyFromData(requestContext.body);
    }
    const httpsClient = (_a = requestContext.httpClient) !== null && _a !== void 0 ? _a : getCachedDefaultHttpClient();
    const url = prepareURL(requestContext.endpoint, requestContext.path);
    const reqHeaders = coreRestPipeline.createHttpHeaders(requestContext.headers);
    const pipelineRequest = coreRestPipeline.createPipelineRequest({
        url,
        headers: reqHeaders,
        method: requestContext.method,
        abortSignal: signal,
        body: requestContext.body,
    });
    if (requestContext.requestAgent) {
        pipelineRequest.agent = requestContext.requestAgent;
    }
    else {
        const parsedUrl = new URL(url);
        pipelineRequest.agent = parsedUrl.protocol === "http:" ? defaultHttpAgent : defaultHttpsAgent;
        pipelineRequest.allowInsecureConnection = parsedUrl.protocol === "http:";
    }
    const startTimeUTCInMs = getCurrentTimestampInMs();
    try {
        if (requestContext.pipeline) {
            response = await requestContext.pipeline.sendRequest(httpsClient, pipelineRequest);
        }
        else {
            response = await httpsClient.sendRequest(pipelineRequest);
        }
    }
    catch (error) {
        if (error.name === "AbortError") {
            // If the user passed signal caused the abort, cancel the timeout and rethrow the error
            if (userSignal && userSignal.aborted === true) {
                clearTimeout(timeout);
                throw error;
            }
            // If the user didn't cancel, it must be an abort we called due to timeout
            throw new TimeoutError(`Timeout Error! Request took more than ${requestContext.connectionPolicy.requestTimeout} ms`);
        }
        throw error;
    }
    clearTimeout(timeout);
    const result = response.status === 204 || response.status === 304 || response.bodyAsText === ""
        ? null
        : JSON.parse(response.bodyAsText);
    const responseHeaders = response.headers.toJSON();
    const substatus = responseHeaders[Constants.HttpHeaders.SubStatus]
        ? parseInt(responseHeaders[Constants.HttpHeaders.SubStatus], 10)
        : undefined;
    diagnosticNode.recordSuccessfulNetworkCall(startTimeUTCInMs, requestContext, response, substatus, url);
    if (response.status >= 400) {
        const errorResponse = new ErrorResponse(result.message);
        logger$1.warning(response.status +
            " " +
            requestContext.endpoint +
            " " +
            requestContext.path +
            " " +
            result.message);
        errorResponse.code = response.status;
        errorResponse.body = result;
        errorResponse.headers = responseHeaders;
        if (Constants.HttpHeaders.ActivityId in responseHeaders) {
            errorResponse.activityId = responseHeaders[Constants.HttpHeaders.ActivityId];
        }
        if (Constants.HttpHeaders.SubStatus in responseHeaders) {
            errorResponse.substatus = substatus;
        }
        if (Constants.HttpHeaders.RetryAfterInMs in responseHeaders) {
            errorResponse.retryAfterInMs = parseInt(responseHeaders[Constants.HttpHeaders.RetryAfterInMs], 10);
            Object.defineProperty(errorResponse, "retryAfterInMilliseconds", {
                get: () => {
                    return errorResponse.retryAfterInMs;
                },
            });
        }
        throw errorResponse;
    }
    return {
        headers: responseHeaders,
        result,
        code: response.status,
        substatus,
    };
}
/**
 * @hidden
 */
async function request(requestContext, diagnosticNode) {
    if (requestContext.body) {
        requestContext.body = bodyFromData(requestContext.body);
        if (!requestContext.body) {
            throw new Error("parameter data must be a javascript object, string, or Buffer");
        }
    }
    return addDignosticChild(async (childNode) => {
        return execute({
            diagnosticNode: childNode,
            requestContext,
            executeRequest,
        });
    }, diagnosticNode, exports.DiagnosticNodeType.REQUEST_ATTEMPTS);
}
const RequestHandler = {
    request,
};

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
function atob(str) {
    return Buffer.from(str, "base64").toString("binary");
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Models vector clock bases session token. Session token has the following format:
 * `{Version}#{GlobalLSN}#{RegionId1}={LocalLsn1}#{RegionId2}={LocalLsn2}....#{RegionIdN}={LocalLsnN}`
 * 'Version' captures the configuration number of the partition which returned this session token.
 * 'Version' is incremented everytime topology of the partition is updated (say due to Add/Remove/Failover).
 *
 * The choice of separators '#' and '=' is important. Separators ';' and ',' are used to delimit
 * per-partitionKeyRange session token
 * @hidden
 *
 */
class VectorSessionToken {
    constructor(version, globalLsn, localLsnByregion, sessionToken) {
        this.version = version;
        this.globalLsn = globalLsn;
        this.localLsnByregion = localLsnByregion;
        this.sessionToken = sessionToken;
        if (!this.sessionToken) {
            const regionAndLocalLsn = [];
            for (const [key, value] of this.localLsnByregion.entries()) {
                regionAndLocalLsn.push(`${key}${VectorSessionToken.REGION_PROGRESS_SEPARATOR}${value}`);
            }
            const regionProgress = regionAndLocalLsn.join(VectorSessionToken.SEGMENT_SEPARATOR);
            if (regionProgress === "") {
                this.sessionToken = `${this.version}${VectorSessionToken.SEGMENT_SEPARATOR}${this.globalLsn}`;
            }
            else {
                this.sessionToken = `${this.version}${VectorSessionToken.SEGMENT_SEPARATOR}${this.globalLsn}${VectorSessionToken.SEGMENT_SEPARATOR}${regionProgress}`;
            }
        }
    }
    static create(sessionToken) {
        const [versionStr, globalLsnStr, ...regionSegments] = sessionToken.split(VectorSessionToken.SEGMENT_SEPARATOR);
        const version = parseInt(versionStr, 10);
        const globalLsn = parseFloat(globalLsnStr);
        if (typeof version !== "number" || typeof globalLsn !== "number") {
            return null;
        }
        const lsnByRegion = new Map();
        for (const regionSegment of regionSegments) {
            const [regionIdStr, localLsnStr] = regionSegment.split(VectorSessionToken.REGION_PROGRESS_SEPARATOR);
            if (!regionIdStr || !localLsnStr) {
                return null;
            }
            const regionId = parseInt(regionIdStr, 10);
            let localLsn;
            try {
                localLsn = localLsnStr;
            }
            catch (err) {
                // TODO: log error
                return null;
            }
            if (typeof regionId !== "number") {
                return null;
            }
            lsnByRegion.set(regionId, localLsn);
        }
        return new VectorSessionToken(version, globalLsn, lsnByRegion, sessionToken);
    }
    equals(other) {
        return !other
            ? false
            : this.version === other.version &&
                this.globalLsn === other.globalLsn &&
                this.areRegionProgressEqual(other.localLsnByregion);
    }
    merge(other) {
        if (other == null) {
            throw new Error("other (Vector Session Token) must not be null");
        }
        if (this.version === other.version &&
            this.localLsnByregion.size !== other.localLsnByregion.size) {
            throw new Error(`Compared session tokens ${this.sessionToken} and ${other.sessionToken} have unexpected regions`);
        }
        const [higherVersionSessionToken, lowerVersionSessionToken] = this.version < other.version ? [other, this] : [this, other];
        const highestLocalLsnByRegion = new Map();
        for (const [regionId, highLocalLsn] of higherVersionSessionToken.localLsnByregion.entries()) {
            const lowLocalLsn = lowerVersionSessionToken.localLsnByregion.get(regionId);
            if (lowLocalLsn) {
                highestLocalLsnByRegion.set(regionId, max(highLocalLsn, lowLocalLsn));
            }
            else if (this.version === other.version) {
                throw new Error(`Compared session tokens have unexpected regions. Session 1: ${this.sessionToken} - Session 2: ${this.sessionToken}`);
            }
            else {
                highestLocalLsnByRegion.set(regionId, highLocalLsn);
            }
        }
        return new VectorSessionToken(Math.max(this.version, other.version), Math.max(this.globalLsn, other.globalLsn), highestLocalLsnByRegion);
    }
    toString() {
        return this.sessionToken;
    }
    areRegionProgressEqual(other) {
        if (this.localLsnByregion.size !== other.size) {
            return false;
        }
        for (const [regionId, localLsn] of this.localLsnByregion.entries()) {
            const otherLocalLsn = other.get(regionId);
            if (localLsn !== otherLocalLsn) {
                return false;
            }
        }
        return true;
    }
}
VectorSessionToken.SEGMENT_SEPARATOR = "#";
VectorSessionToken.REGION_PROGRESS_SEPARATOR = "=";
/**
 * @hidden
 */
function max(int1, int2) {
    // NOTE: This only works for positive numbers
    if (int1.length === int2.length) {
        return int1 > int2 ? int1 : int2;
    }
    else if (int1.length > int2.length) {
        return int1;
    }
    else {
        return int2;
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/** @hidden */
class SessionContainer {
    constructor(collectionNameToCollectionResourceId = new Map(), collectionResourceIdToSessionTokens = new Map()) {
        this.collectionNameToCollectionResourceId = collectionNameToCollectionResourceId;
        this.collectionResourceIdToSessionTokens = collectionResourceIdToSessionTokens;
    }
    get(request) {
        if (!request) {
            throw new Error("request cannot be null");
        }
        const collectionName = getContainerLink(trimSlashes(request.resourceAddress));
        const rangeIdToTokenMap = this.getPartitionKeyRangeIdToTokenMap(collectionName);
        return SessionContainer.getCombinedSessionTokenString(rangeIdToTokenMap);
    }
    remove(request) {
        let collectionResourceId;
        const resourceAddress = trimSlashes(request.resourceAddress);
        const collectionName = getContainerLink(resourceAddress);
        if (collectionName) {
            collectionResourceId = this.collectionNameToCollectionResourceId.get(collectionName);
            this.collectionNameToCollectionResourceId.delete(collectionName);
        }
        if (collectionResourceId !== undefined) {
            this.collectionResourceIdToSessionTokens.delete(collectionResourceId);
        }
    }
    set(request, resHeaders) {
        // TODO: we check the master logic a few different places. Might not need it.
        if (!resHeaders ||
            SessionContainer.isReadingFromMaster(request.resourceType, request.operationType)) {
            return;
        }
        const sessionTokenString = resHeaders[Constants.HttpHeaders.SessionToken];
        if (!sessionTokenString) {
            return;
        }
        const containerName = this.getContainerName(request, resHeaders);
        const ownerId = !request.isNameBased
            ? request.resourceId
            : resHeaders[Constants.HttpHeaders.OwnerId] || request.resourceId;
        if (!ownerId) {
            return;
        }
        if (containerName && this.validateOwnerID(ownerId)) {
            if (!this.collectionResourceIdToSessionTokens.has(ownerId)) {
                this.collectionResourceIdToSessionTokens.set(ownerId, new Map());
            }
            if (!this.collectionNameToCollectionResourceId.has(containerName)) {
                this.collectionNameToCollectionResourceId.set(containerName, ownerId);
            }
            const containerSessionContainer = this.collectionResourceIdToSessionTokens.get(ownerId);
            SessionContainer.compareAndSetToken(sessionTokenString, containerSessionContainer);
        }
    }
    validateOwnerID(ownerId) {
        // If ownerId contains exactly 8 bytes it represents a unique database+collection identifier. Otherwise it represents another resource
        // The first 4 bytes are the database. The last 4 bytes are the collection.
        // Cosmos rids potentially contain "-" which is an invalid character in the browser atob implementation
        // See https://en.wikipedia.org/wiki/Base64#Filenames
        return atob(ownerId.replace(/-/g, "/")).length === 8;
    }
    getPartitionKeyRangeIdToTokenMap(collectionName) {
        let rangeIdToTokenMap = null;
        if (collectionName && this.collectionNameToCollectionResourceId.has(collectionName)) {
            rangeIdToTokenMap = this.collectionResourceIdToSessionTokens.get(this.collectionNameToCollectionResourceId.get(collectionName));
        }
        return rangeIdToTokenMap;
    }
    static getCombinedSessionTokenString(tokens) {
        if (!tokens || tokens.size === 0) {
            return SessionContainer.EMPTY_SESSION_TOKEN;
        }
        let result = "";
        for (const [range, token] of tokens.entries()) {
            result +=
                range +
                    SessionContainer.SESSION_TOKEN_PARTITION_SPLITTER +
                    token.toString() +
                    SessionContainer.SESSION_TOKEN_SEPARATOR;
        }
        return result.slice(0, -1);
    }
    static compareAndSetToken(newTokenString, containerSessionTokens) {
        if (!newTokenString) {
            return;
        }
        const partitionsParts = newTokenString.split(SessionContainer.SESSION_TOKEN_SEPARATOR);
        for (const partitionPart of partitionsParts) {
            const newTokenParts = partitionPart.split(SessionContainer.SESSION_TOKEN_PARTITION_SPLITTER);
            if (newTokenParts.length !== 2) {
                return;
            }
            const range = newTokenParts[0];
            const newToken = VectorSessionToken.create(newTokenParts[1]);
            const tokenForRange = !containerSessionTokens.get(range)
                ? newToken
                : containerSessionTokens.get(range).merge(newToken);
            containerSessionTokens.set(range, tokenForRange);
        }
    }
    // TODO: have a assert if the type doesn't mastch known types
    static isReadingFromMaster(resourceType, operationType) {
        if (resourceType === Constants.Path.OffersPathSegment ||
            resourceType === Constants.Path.DatabasesPathSegment ||
            resourceType === Constants.Path.UsersPathSegment ||
            resourceType === Constants.Path.PermissionsPathSegment ||
            resourceType === Constants.Path.TopologyPathSegment ||
            resourceType === Constants.Path.DatabaseAccountPathSegment ||
            resourceType === Constants.Path.PartitionKeyRangesPathSegment ||
            (resourceType === Constants.Path.CollectionsPathSegment &&
                operationType === exports.OperationType.Query)) {
            return true;
        }
        return false;
    }
    getContainerName(request, headers) {
        let ownerFullName = headers[Constants.HttpHeaders.OwnerFullName];
        if (!ownerFullName) {
            ownerFullName = trimSlashes(request.resourceAddress);
        }
        return getContainerLink(ownerFullName);
    }
}
SessionContainer.EMPTY_SESSION_TOKEN = "";
SessionContainer.SESSION_TOKEN_SEPARATOR = ",";
SessionContainer.SESSION_TOKEN_PARTITION_SPLITTER = ":";

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
function checkURL(testString) {
    return new URL(testString);
}
function sanitizeEndpoint(url) {
    return new URL(url).href.replace(/\/$/, "");
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
function supportedQueryFeaturesBuilder(disableNonStreamingOrderByQuery) {
    if (disableNonStreamingOrderByQuery) {
        return Object.keys(QueryFeature)
            .filter((k) => k !== QueryFeature.NonStreamingOrderBy)
            .join(", ");
    }
    else {
        return Object.keys(QueryFeature).join(", ");
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Implementation of DiagnosticWriter, which uses \@azure/logger to write
 * diagnostics.
 * @hidden
 */
class LogDiagnosticWriter {
    constructor() {
        this.logger = logger$5.createClientLogger("CosmosDBDiagnostics");
    }
    async write(diagnosticsData) {
        this.logger.verbose(diagnosticsData);
    }
}
/**
 * Implementation of a no-op DiagnosticWriter.
 * @hidden
 */
class NoOpDiagnosticWriter {
    async write(_diagnosticsData) {
        // No op
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
class DefaultDiagnosticFormatter {
    format(cosmosDiagnostic) {
        return JSON.stringify(cosmosDiagnostic);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @hidden
 */
function getUserAgent(suffix, hostFramework) {
    let ua = `${userAgentDetails()} ${Constants.SDKName}/${Constants.SDKVersion}`;
    if (hostFramework) {
        ua = ua + " " + hostFramework;
    }
    if (suffix) {
        ua = ua + " " + suffix;
    }
    return ua;
}
// TODO: Standardize across other platforms from @azure/core-util
function userAgentDetails() {
    let userAgentDetail = "<environment undetectable>";
    if (globalThis.navigator && globalThis.navigator.userAgent) {
        userAgentDetail = globalThis.navigator.userAgent;
    }
    if (globalThis.process && globalThis.process.version) {
        userAgentDetail = `Node.js/${process.version.slice(1)} (${process.platform}; ${process.arch})`;
    }
    return userAgentDetail;
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
const logger = logger$5.createClientLogger("ClientContext");
const QueryJsonContentType = "application/query+json";
const HttpHeaders = Constants.HttpHeaders;
/**
 * @hidden
 * @hidden
 */
class ClientContext {
    constructor(cosmosClientOptions, globalEndpointManager, clientConfig, diagnosticLevel) {
        this.cosmosClientOptions = cosmosClientOptions;
        this.globalEndpointManager = globalEndpointManager;
        this.clientConfig = clientConfig;
        this.diagnosticLevel = diagnosticLevel;
        /** boolean flag to support operations with client-side encryption */
        this.enableEncryption = false;
        if (cosmosClientOptions.clientEncryptionOptions) {
            this.enableEncryption = true;
        }
        this.connectionPolicy = cosmosClientOptions.connectionPolicy;
        this.sessionContainer = new SessionContainer();
        this.partitionKeyDefinitionCache = {};
        this.pipeline = null;
        if (cosmosClientOptions.aadCredentials) {
            this.pipeline = coreRestPipeline.createEmptyPipeline();
            const hrefEndpoint = sanitizeEndpoint(cosmosClientOptions.endpoint);
            const scope = `${hrefEndpoint}/.default`;
            this.pipeline.addPolicy(coreRestPipeline.bearerTokenAuthenticationPolicy({
                credential: cosmosClientOptions.aadCredentials,
                scopes: scope,
                challengeCallbacks: {
                    async authorizeRequest({ request, getAccessToken }) {
                        const tokenResponse = await getAccessToken([scope], {});
                        const AUTH_PREFIX = `type=aad&ver=1.0&sig=`;
                        const authorizationToken = `${AUTH_PREFIX}${tokenResponse.token}`;
                        request.headers.set("Authorization", authorizationToken);
                    },
                },
            }));
        }
        this.initializeDiagnosticSettings(diagnosticLevel);
    }
    /** @hidden */
    async read({ path, resourceType, resourceId, options = {}, partitionKey, diagnosticNode, }) {
        try {
            const request = Object.assign(Object.assign({}, this.getContextDerivedPropsForRequestCreation()), { method: exports.HTTPMethod.get, path, operationType: exports.OperationType.Read, resourceId,
                options,
                resourceType,
                partitionKey });
            diagnosticNode.addData({
                operationType: exports.OperationType.Read,
                resourceType,
            });
            request.headers = await this.buildHeaders(request);
            if (resourceType === exports.ResourceType.clientencryptionkey) {
                request.headers[HttpHeaders.AllowCachedReadsHeader] = true;
                if (options.databaseRid) {
                    request.headers[HttpHeaders.DatabaseRidHeader] = options.databaseRid;
                }
            }
            this.applySessionToken(request);
            // read will use ReadEndpoint since it uses GET operation
            request.endpoint = await this.globalEndpointManager.resolveServiceEndpoint(diagnosticNode, request.resourceType, request.operationType);
            const response = await executePlugins(diagnosticNode, request, RequestHandler.request, exports.PluginOn.operation);
            this.captureSessionToken(undefined, path, exports.OperationType.Read, response.headers);
            return response;
        }
        catch (err) {
            this.captureSessionToken(err, path, exports.OperationType.Upsert, err.headers);
            throw err;
        }
    }
    async queryFeed({ path, resourceType, resourceId, resultFn, query, options, diagnosticNode, partitionKeyRangeId, partitionKey, startEpk, endEpk, correlatedActivityId, }) {
        // Query operations will use ReadEndpoint even though it uses
        // GET(for queryFeed) and POST(for regular query operations)
        const request = Object.assign(Object.assign({}, this.getContextDerivedPropsForRequestCreation()), { method: exports.HTTPMethod.get, path, operationType: exports.OperationType.Query, partitionKeyRangeId,
            resourceId,
            resourceType,
            options, body: query, partitionKey });
        diagnosticNode.addData({
            operationType: exports.OperationType.Query,
            resourceType,
        });
        const requestId = coreUtil.randomUUID();
        if (query !== undefined) {
            request.method = exports.HTTPMethod.post;
        }
        request.endpoint = await this.globalEndpointManager.resolveServiceEndpoint(diagnosticNode, request.resourceType, request.operationType);
        request.headers = await this.buildHeaders(request);
        if (startEpk !== undefined && endEpk !== undefined) {
            request.headers[HttpHeaders.StartEpk] = startEpk;
            request.headers[HttpHeaders.EndEpk] = endEpk;
            request.headers[HttpHeaders.ReadFeedKeyType] = "EffectivePartitionKeyRange";
        }
        if (query !== undefined) {
            if (correlatedActivityId !== undefined) {
                request.headers[HttpHeaders.CorrelatedActivityId] = correlatedActivityId;
            }
            request.headers[HttpHeaders.IsQuery] = "true";
            request.headers[HttpHeaders.ContentType] = QueryJsonContentType;
            if (typeof query === "string") {
                request.body = { query }; // Converts query text to query object.
            }
        }
        this.applySessionToken(request);
        logger.info("query " +
            requestId +
            " started" +
            (request.partitionKeyRangeId ? " pkrid: " + request.partitionKeyRangeId : ""));
        logger.verbose(request);
        const start = Date.now();
        const response = await RequestHandler.request(request, diagnosticNode);
        logger.info("query " + requestId + " finished - " + (Date.now() - start) + "ms");
        this.captureSessionToken(undefined, path, exports.OperationType.Query, response.headers);
        return this.processQueryFeedResponse(response, !!query, resultFn);
    }
    async getQueryPlan(path, resourceType, resourceId, query, options = {}, diagnosticNode, correlatedActivityId) {
        const request = Object.assign(Object.assign({}, this.getContextDerivedPropsForRequestCreation()), { method: exports.HTTPMethod.post, path, operationType: exports.OperationType.Read, resourceId,
            resourceType,
            options, body: query });
        diagnosticNode.addData({
            operationType: exports.OperationType.Read,
            resourceType,
        });
        request.endpoint = await this.globalEndpointManager.resolveServiceEndpoint(diagnosticNode, request.resourceType, request.operationType);
        request.headers = await this.buildHeaders(request);
        if (correlatedActivityId !== undefined) {
            request.headers[HttpHeaders.CorrelatedActivityId] = correlatedActivityId;
        }
        request.headers[HttpHeaders.IsQueryPlan] = "True";
        request.headers[HttpHeaders.QueryVersion] = "1.4";
        request.headers[HttpHeaders.ContentType] = QueryJsonContentType;
        request.headers[HttpHeaders.SupportedQueryFeatures] = supportedQueryFeaturesBuilder(options.disableNonStreamingOrderByQuery);
        if (typeof query === "string") {
            request.body = { query }; // Converts query text to query object.
        }
        this.applySessionToken(request);
        const response = await RequestHandler.request(request, diagnosticNode);
        this.captureSessionToken(undefined, path, exports.OperationType.Query, response.headers);
        return response;
    }
    queryPartitionKeyRanges(collectionLink, query, options) {
        const path = getPathFromLink(collectionLink, exports.ResourceType.pkranges);
        const id = getIdFromLink(collectionLink);
        const cb = async (diagNode, innerOptions) => {
            const response = await this.queryFeed({
                path,
                resourceType: exports.ResourceType.pkranges,
                resourceId: id,
                resultFn: (result) => result.PartitionKeyRanges,
                query,
                options: innerOptions,
                diagnosticNode: diagNode,
            });
            return response;
        };
        return new QueryIterator(this, query, options, cb);
    }
    async delete({ path, resourceType, resourceId, options = {}, partitionKey, method = exports.HTTPMethod.delete, diagnosticNode, }) {
        try {
            const request = Object.assign(Object.assign({}, this.getContextDerivedPropsForRequestCreation()), { method: method, operationType: exports.OperationType.Delete, path,
                resourceType,
                options,
                resourceId,
                partitionKey });
            diagnosticNode.addData({
                operationType: exports.OperationType.Delete,
                resourceType,
            });
            request.headers = await this.buildHeaders(request);
            this.applySessionToken(request);
            // deleteResource will use WriteEndpoint since it uses DELETE operation
            request.endpoint = await this.globalEndpointManager.resolveServiceEndpoint(diagnosticNode, request.resourceType, request.operationType);
            const response = await executePlugins(diagnosticNode, request, RequestHandler.request, exports.PluginOn.operation);
            if (parseLink(path).type !== "colls") {
                this.captureSessionToken(undefined, path, exports.OperationType.Delete, response.headers);
            }
            else {
                this.clearSessionToken(path);
            }
            return response;
        }
        catch (err) {
            this.captureSessionToken(err, path, exports.OperationType.Upsert, err.headers);
            throw err;
        }
    }
    async patch({ body, path, resourceType, resourceId, options = {}, partitionKey, diagnosticNode, }) {
        try {
            const request = Object.assign(Object.assign({}, this.getContextDerivedPropsForRequestCreation()), { method: exports.HTTPMethod.patch, operationType: exports.OperationType.Patch, path,
                resourceType,
                body,
                resourceId,
                options,
                partitionKey });
            diagnosticNode.addData({
                operationType: exports.OperationType.Patch,
                resourceType,
            });
            request.headers = await this.buildHeaders(request);
            this.applySessionToken(request);
            // patch will use WriteEndpoint
            request.endpoint = await this.globalEndpointManager.resolveServiceEndpoint(diagnosticNode, request.resourceType, request.operationType);
            const response = await executePlugins(diagnosticNode, request, RequestHandler.request, exports.PluginOn.operation);
            this.captureSessionToken(undefined, path, exports.OperationType.Patch, response.headers);
            return response;
        }
        catch (err) {
            this.captureSessionToken(err, path, exports.OperationType.Upsert, err.headers);
            throw err;
        }
    }
    async create({ body, path, resourceType, resourceId, diagnosticNode, options = {}, partitionKey, }) {
        try {
            const request = Object.assign(Object.assign({}, this.getContextDerivedPropsForRequestCreation()), { method: exports.HTTPMethod.post, operationType: exports.OperationType.Create, path,
                resourceType,
                resourceId,
                body,
                options,
                partitionKey });
            diagnosticNode.addData({
                operationType: exports.OperationType.Create,
                resourceType,
            });
            request.headers = await this.buildHeaders(request);
            // create will use WriteEndpoint since it uses POST operation
            this.applySessionToken(request);
            request.endpoint = await this.globalEndpointManager.resolveServiceEndpoint(diagnosticNode, request.resourceType, request.operationType);
            const response = await executePlugins(diagnosticNode, request, RequestHandler.request, exports.PluginOn.operation);
            this.captureSessionToken(undefined, path, exports.OperationType.Create, response.headers);
            return response;
        }
        catch (err) {
            this.captureSessionToken(err, path, exports.OperationType.Upsert, err.headers);
            throw err;
        }
    }
    processQueryFeedResponse(res, isQuery, resultFn) {
        if (isQuery) {
            return {
                result: resultFn(res.result),
                headers: res.headers,
                code: res.code,
            };
        }
        else {
            const newResult = resultFn(res.result).map((body) => body);
            return {
                result: newResult,
                headers: res.headers,
                code: res.code,
            };
        }
    }
    applySessionToken(requestContext) {
        const request = this.getSessionParams(requestContext.path);
        if (requestContext.headers && requestContext.headers[HttpHeaders.SessionToken]) {
            return;
        }
        const sessionConsistency = requestContext.headers[HttpHeaders.ConsistencyLevel];
        if (!sessionConsistency) {
            return;
        }
        if (sessionConsistency !== exports.ConsistencyLevel.Session) {
            return;
        }
        if (request.resourceAddress) {
            const sessionToken = this.sessionContainer.get(request);
            if (sessionToken) {
                requestContext.headers[HttpHeaders.SessionToken] = sessionToken;
            }
        }
    }
    async replace({ body, path, resourceType, resourceId, options = {}, partitionKey, diagnosticNode, }) {
        try {
            const request = Object.assign(Object.assign({}, this.getContextDerivedPropsForRequestCreation()), { method: exports.HTTPMethod.put, operationType: exports.OperationType.Replace, path,
                resourceType,
                body,
                resourceId,
                options,
                partitionKey });
            diagnosticNode.addData({
                operationType: exports.OperationType.Replace,
                resourceType,
            });
            request.headers = await this.buildHeaders(request);
            this.applySessionToken(request);
            // replace will use WriteEndpoint since it uses PUT operation
            request.endpoint = await this.globalEndpointManager.resolveServiceEndpoint(diagnosticNode, request.resourceType, request.operationType);
            const response = await executePlugins(diagnosticNode, request, RequestHandler.request, exports.PluginOn.operation);
            this.captureSessionToken(undefined, path, exports.OperationType.Replace, response.headers);
            return response;
        }
        catch (err) {
            this.captureSessionToken(err, path, exports.OperationType.Upsert, err.headers);
            throw err;
        }
    }
    async upsert({ body, path, resourceType, resourceId, options = {}, partitionKey, diagnosticNode, }) {
        try {
            const request = Object.assign(Object.assign({}, this.getContextDerivedPropsForRequestCreation()), { method: exports.HTTPMethod.post, operationType: exports.OperationType.Upsert, path,
                resourceType,
                body,
                resourceId,
                options,
                partitionKey });
            diagnosticNode.addData({
                operationType: exports.OperationType.Upsert,
                resourceType,
            });
            request.headers = await this.buildHeaders(request);
            request.headers[HttpHeaders.IsUpsert] = true;
            this.applySessionToken(request);
            // upsert will use WriteEndpoint since it uses POST operation
            request.endpoint = await this.globalEndpointManager.resolveServiceEndpoint(diagnosticNode, request.resourceType, request.operationType);
            const response = await executePlugins(diagnosticNode, request, RequestHandler.request, exports.PluginOn.operation);
            this.captureSessionToken(undefined, path, exports.OperationType.Upsert, response.headers);
            return response;
        }
        catch (err) {
            this.captureSessionToken(err, path, exports.OperationType.Upsert, err.headers);
            throw err;
        }
    }
    async execute({ sprocLink, params, options = {}, partitionKey, diagnosticNode, }) {
        // Accept a single parameter or an array of parameters.
        // Didn't add type annotation for this because we should legacy this behavior
        if (params !== null && params !== undefined && !Array.isArray(params)) {
            params = [params];
        }
        const path = getPathFromLink(sprocLink);
        const id = getIdFromLink(sprocLink);
        const request = Object.assign(Object.assign({}, this.getContextDerivedPropsForRequestCreation()), { method: exports.HTTPMethod.post, operationType: exports.OperationType.Execute, path, resourceType: exports.ResourceType.sproc, options, resourceId: id, body: params, partitionKey });
        diagnosticNode.addData({
            operationType: exports.OperationType.Execute,
            resourceType: exports.ResourceType.sproc,
        });
        request.headers = await this.buildHeaders(request);
        // executeStoredProcedure will use WriteEndpoint since it uses POST operation
        request.endpoint = await this.globalEndpointManager.resolveServiceEndpoint(diagnosticNode, request.resourceType, request.operationType);
        const response = await executePlugins(diagnosticNode, request, RequestHandler.request, exports.PluginOn.operation);
        return response;
    }
    /**
     * Gets the Database account information.
     * @param options - `urlConnection` in the options is the endpoint url whose database account needs to be retrieved.
     * If not present, current client's url will be used.
     */
    async getDatabaseAccount(diagnosticNode, options = {}) {
        const endpoint = options.urlConnection || this.cosmosClientOptions.endpoint;
        const request = Object.assign(Object.assign({}, this.getContextDerivedPropsForRequestCreation()), { endpoint, method: exports.HTTPMethod.get, operationType: exports.OperationType.Read, path: "", resourceType: exports.ResourceType.none, options });
        diagnosticNode.addData({
            operationType: exports.OperationType.Read,
            resourceType: exports.ResourceType.none,
        });
        request.headers = await this.buildHeaders(request);
        // await options.beforeOperation({ endpoint, request, headers: requestHeaders });
        const { result, headers, code, substatus, diagnostics } = await executePlugins(diagnosticNode, request, RequestHandler.request, exports.PluginOn.operation);
        const databaseAccount = new DatabaseAccount(result, headers);
        return {
            result: databaseAccount,
            headers,
            diagnostics,
            code: code,
            substatus: substatus,
        };
    }
    getWriteEndpoint(diagnosticNode) {
        return this.globalEndpointManager.getWriteEndpoint(diagnosticNode);
    }
    getReadEndpoint(diagnosticNode) {
        return this.globalEndpointManager.getReadEndpoint(diagnosticNode);
    }
    getWriteEndpoints() {
        return this.globalEndpointManager.getWriteEndpoints();
    }
    getReadEndpoints() {
        return this.globalEndpointManager.getReadEndpoints();
    }
    async batch({ body, path, partitionKey, resourceId, options = {}, diagnosticNode, }) {
        try {
            const request = Object.assign(Object.assign({}, this.getContextDerivedPropsForRequestCreation()), { method: exports.HTTPMethod.post, operationType: exports.OperationType.Batch, path,
                body, resourceType: exports.ResourceType.item, resourceId,
                options,
                partitionKey });
            diagnosticNode.addData({
                operationType: exports.OperationType.Batch,
                resourceType: exports.ResourceType.item,
            });
            request.headers = await this.buildHeaders(request);
            request.headers[HttpHeaders.IsBatchRequest] = true;
            request.headers[HttpHeaders.IsBatchAtomic] = true;
            this.applySessionToken(request);
            request.endpoint = await this.globalEndpointManager.resolveServiceEndpoint(diagnosticNode, request.resourceType, request.operationType);
            const response = await executePlugins(diagnosticNode, request, RequestHandler.request, exports.PluginOn.operation);
            this.captureSessionToken(undefined, path, exports.OperationType.Batch, response.headers);
            response.diagnostics = diagnosticNode.toDiagnostic(this.getClientConfig());
            return response;
        }
        catch (err) {
            this.captureSessionToken(err, path, exports.OperationType.Upsert, err.headers);
            throw err;
        }
    }
    async bulk({ body, path, partitionKeyRangeId, resourceId, bulkOptions = {}, options = {}, diagnosticNode, }) {
        var _a;
        try {
            const request = Object.assign(Object.assign({}, this.getContextDerivedPropsForRequestCreation()), { method: exports.HTTPMethod.post, operationType: exports.OperationType.Batch, path,
                body, resourceType: exports.ResourceType.item, resourceId,
                options });
            diagnosticNode.addData({
                operationType: exports.OperationType.Batch,
                resourceType: exports.ResourceType.item,
            });
            request.headers = await this.buildHeaders(request);
            request.headers[HttpHeaders.IsBatchRequest] = true;
            request.headers[HttpHeaders.PartitionKeyRangeID] = partitionKeyRangeId;
            request.headers[HttpHeaders.IsBatchAtomic] = false;
            request.headers[HttpHeaders.BatchContinueOnError] = (_a = bulkOptions.continueOnError) !== null && _a !== void 0 ? _a : true;
            this.applySessionToken(request);
            request.endpoint = await this.globalEndpointManager.resolveServiceEndpoint(diagnosticNode, request.resourceType, request.operationType);
            const response = await executePlugins(diagnosticNode, request, RequestHandler.request, exports.PluginOn.operation);
            this.captureSessionToken(undefined, path, exports.OperationType.Batch, response.headers);
            return response;
        }
        catch (err) {
            this.captureSessionToken(err, path, exports.OperationType.Upsert, err.headers);
            throw err;
        }
    }
    captureSessionToken(err, path, operationType, resHeaders) {
        const request = this.getSessionParams(path);
        request.operationType = operationType;
        if (!err ||
            (!this.isMasterResource(request.resourceType) &&
                (err.code === StatusCodes.PreconditionFailed ||
                    err.code === StatusCodes.Conflict ||
                    (err.code === StatusCodes.NotFound &&
                        err.substatus !== SubStatusCodes.ReadSessionNotAvailable)))) {
            this.sessionContainer.set(request, resHeaders);
        }
    }
    clearSessionToken(path) {
        const request = this.getSessionParams(path);
        this.sessionContainer.remove(request);
    }
    recordDiagnostics(diagnostic) {
        const formatted = this.diagnosticFormatter.format(diagnostic);
        this.diagnosticWriter.write(formatted);
    }
    initializeDiagnosticSettings(diagnosticLevel) {
        this.diagnosticFormatter = new DefaultDiagnosticFormatter();
        switch (diagnosticLevel) {
            case exports.CosmosDbDiagnosticLevel.info:
                this.diagnosticWriter = new NoOpDiagnosticWriter();
                break;
            default:
                this.diagnosticWriter = new LogDiagnosticWriter();
        }
    }
    // TODO: move
    getSessionParams(resourceLink) {
        const resourceId = null;
        let resourceAddress = null;
        const parserOutput = parseLink(resourceLink);
        resourceAddress = parserOutput.objectBody.self;
        const resourceType = parserOutput.type;
        return {
            resourceId,
            resourceAddress,
            resourceType,
            isNameBased: true,
        };
    }
    isMasterResource(resourceType) {
        if (resourceType === Constants.Path.OffersPathSegment ||
            resourceType === Constants.Path.DatabasesPathSegment ||
            resourceType === Constants.Path.UsersPathSegment ||
            resourceType === Constants.Path.PermissionsPathSegment ||
            resourceType === Constants.Path.TopologyPathSegment ||
            resourceType === Constants.Path.DatabaseAccountPathSegment ||
            resourceType === Constants.Path.PartitionKeyRangesPathSegment ||
            resourceType === Constants.Path.CollectionsPathSegment) {
            return true;
        }
        return false;
    }
    buildHeaders(requestContext) {
        return getHeaders({
            clientOptions: this.cosmosClientOptions,
            defaultHeaders: Object.assign(Object.assign({}, this.cosmosClientOptions.defaultHeaders), requestContext.options.initialHeaders),
            verb: requestContext.method,
            path: requestContext.path,
            resourceId: requestContext.resourceId,
            resourceType: requestContext.resourceType,
            options: requestContext.options,
            partitionKeyRangeId: requestContext.partitionKeyRangeId,
            useMultipleWriteLocations: this.connectionPolicy.useMultipleWriteLocations,
            partitionKey: requestContext.partitionKey !== undefined
                ? convertToInternalPartitionKey(requestContext.partitionKey)
                : undefined, // TODO: Move this check from here to PartitionKey
        });
    }
    /**
     * Returns collection of properties which are derived from the context for Request Creation.
     * These properties have client wide scope, as opposed to request specific scope.
     * @returns
     */
    getContextDerivedPropsForRequestCreation() {
        return {
            globalEndpointManager: this.globalEndpointManager,
            requestAgent: this.cosmosClientOptions.agent,
            connectionPolicy: this.connectionPolicy,
            client: this,
            plugins: this.cosmosClientOptions.plugins,
            pipeline: this.pipeline,
            httpClient: this.cosmosClientOptions.httpClient,
        };
    }
    getClientConfig() {
        return this.clientConfig;
    }
    /**
     * @internal
     */
    refreshUserAgent(hostFramework) {
        const updatedUserAgent = getUserAgent(this.cosmosClientOptions.userAgentSuffix, hostFramework);
        this.cosmosClientOptions.defaultHeaders[Constants.HttpHeaders.UserAgent] = updatedUserAgent;
        this.cosmosClientOptions.defaultHeaders[Constants.HttpHeaders.CustomUserAgent] =
            updatedUserAgent;
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
function isNonEmptyString(variable) {
    return typeof variable === "string" && variable.trim().length > 0;
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
const diagnosticLevelFromEnv = process$1.env[Constants.CosmosDbDiagnosticLevelEnvVarName];

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
const DefaultDiagnosticLevelValue = exports.CosmosDbDiagnosticLevel.info;
const acceptableDiagnosticLevelValues = Object.values(exports.CosmosDbDiagnosticLevel).map((x) => x.toString());
let cosmosDiagnosticLevel;
if (isNonEmptyString(diagnosticLevelFromEnv)) {
    // avoid calling setDiagnosticLevel because we don't want a mis-set environment variable to crash
    if (isCosmosDiagnosticLevel(diagnosticLevelFromEnv)) {
        setDiagnosticLevel(diagnosticLevelFromEnv);
    }
    else {
        console.error(`${Constants.CosmosDbDiagnosticLevelEnvVarName} set to unknown diagnostic level '${diagnosticLevelFromEnv}'; Setting Cosmos Db diagnostic level to info. Acceptable values: ${acceptableDiagnosticLevelValues.join(", ")}.`);
    }
}
function setDiagnosticLevel(level) {
    if (level && !isCosmosDiagnosticLevel(level)) {
        throw new Error(`Unknown diagnostic level '${level}'. Acceptable values: ${acceptableDiagnosticLevelValues.join(",")}`);
    }
    cosmosDiagnosticLevel = level;
}
function getDiagnosticLevelFromEnvironment() {
    return cosmosDiagnosticLevel;
}
function isCosmosDiagnosticLevel(diagnosticLevel) {
    return acceptableDiagnosticLevelValues.includes(diagnosticLevel);
}
function determineDiagnosticLevel(diagnosticLevelFromClientConfig, diagnosticLevelFromEnvironment) {
    const diagnosticLevelFromEnvOrClient = diagnosticLevelFromEnvironment !== null && diagnosticLevelFromEnvironment !== void 0 ? diagnosticLevelFromEnvironment : diagnosticLevelFromClientConfig; // Diagnostic Setting from environment gets first priority.
    return diagnosticLevelFromEnvOrClient !== null && diagnosticLevelFromEnvOrClient !== void 0 ? diagnosticLevelFromEnvOrClient : DefaultDiagnosticLevelValue; // Diagnostic Setting supplied in Client config gets second priority.
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * The cache used to store the protected data encryption key.
 * see {@link ProtectedDataEncryptionKey}
 * @hidden
 */
class ProtectedDataEncryptionKeyCache {
    constructor(cacheTimeToLive) {
        this.cacheTimeToLive = cacheTimeToLive;
        this.cache = new Map();
        this.clearCacheOnTtlExpiry();
    }
    get(key) {
        if (!this.cache.has(key)) {
            return undefined;
        }
        return this.cache.get(key)[1];
    }
    set(key, protectedDataEncryptionKey) {
        if (this.cacheTimeToLive === 0) {
            return;
        }
        this.cache.set(key, [new Date(), protectedDataEncryptionKey]);
    }
    async clearCacheOnTtlExpiry() {
        this.cacheRefresher = setInterval(() => {
            const now = new Date();
            for (const key of this.cache.keys()) {
                if (now.getTime() - this.cache.get(key)[0].getTime() > this.cacheTimeToLive) {
                    this.cache.delete(key);
                }
            }
        }, Constants.EncryptionCacheRefreshIntervalInMs);
    }
    async createProtectedDataEncryptionKey(name, keyEncryptionKey, encryptedValue) {
        let rawKey;
        let encryptedKey;
        if (encryptedValue) {
            rawKey = await keyEncryptionKey.unwrapEncryptionKey(encryptedValue);
            encryptedKey = encryptedValue;
        }
        else {
            rawKey = this.generateColumnEncryptionKey();
            encryptedKey = await keyEncryptionKey.wrapEncryptionKey(rawKey);
        }
        const newKey = new ProtectedDataEncryptionKey(name, keyEncryptionKey, rawKey, encryptedKey);
        if (this.cacheTimeToLive !== 0) {
            const key = JSON.stringify([
                name,
                keyEncryptionKey.name,
                keyEncryptionKey.path,
                encryptedKey.toString("hex"),
            ]);
            this.set(key, newKey);
        }
        return newKey;
    }
    async getOrCreate(name, keyEncryptionKey, encryptedValue, forceRefresh) {
        const encryptedValueBuffer = encryptedValue ? Buffer.from(encryptedValue) : undefined;
        if (this.cacheTimeToLive === 0 || forceRefresh) {
            return this.createProtectedDataEncryptionKey(name, keyEncryptionKey, encryptedValueBuffer);
        }
        if (encryptedValueBuffer) {
            const key = JSON.stringify([
                name,
                keyEncryptionKey.name,
                keyEncryptionKey.path,
                encryptedValueBuffer.toString("hex"),
            ]);
            const protectedDataEncryptionKey = this.get(key);
            if (protectedDataEncryptionKey) {
                return protectedDataEncryptionKey;
            }
        }
        return this.createProtectedDataEncryptionKey(name, keyEncryptionKey, encryptedValueBuffer);
    }
    generateColumnEncryptionKey() {
        return crypto.randomBytes(32);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * The cache used to store the key encryption keys.
 * see {@link KeyEncryptionKey}
 * @hidden
 */
class KeyEncryptionKeyCache {
    constructor() {
        this.cache = new Map();
    }
    getOrCreate(name, path, keyStoreProvider) {
        const key = JSON.stringify([name, path]);
        let keyEncryptionKey = this.get(key);
        if (!keyEncryptionKey) {
            keyEncryptionKey = new KeyEncryptionKey(name, path, keyStoreProvider);
            this.set(key, keyEncryptionKey);
        }
        return keyEncryptionKey;
    }
    get(key) {
        return this.cache.get(key);
    }
    set(key, keyEncryptionKey) {
        this.cache.set(key, keyEncryptionKey);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * The cache used to store encryption settings for a container.
 * see {@link EncryptionSettings}
 * @hidden
 */
class EncryptionSettingsCache {
    constructor() {
        this.cache = new Map();
    }
    async create(id, containerRid, partitionKeyPaths, clientEncryptionPolicy) {
        const encryptionSettings = new EncryptionSettings(id, containerRid, partitionKeyPaths);
        if (!clientEncryptionPolicy)
            return;
        for (const includedPath of clientEncryptionPolicy.includedPaths) {
            const encryptionSettingForProperty = new EncryptionSettingForProperty(includedPath);
            encryptionSettings.pathsToEncrypt.push(includedPath.path);
            encryptionSettings.setEncryptionSettingForProperty(includedPath.path, encryptionSettingForProperty);
        }
        this.set(id, encryptionSettings);
        return encryptionSettings;
    }
    get(key) {
        return this.cache.get(key);
    }
    set(key, encryptionSettings) {
        this.cache.set(key, encryptionSettings);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * The cache used to store the properties of the client encryption key
 * see {@link ClientEncryptionKeyProperties}
 * @hidden
 */
class ClientEncryptionKeyPropertiesCache {
    constructor() {
        this.clientEncryptionKeyPropertiesCache = new Map();
    }
    get(key) {
        return this.clientEncryptionKeyPropertiesCache.get(key);
    }
    set(key, clientEncryptionKeyProperties) {
        this.clientEncryptionKeyPropertiesCache.set(key, clientEncryptionKeyProperties);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Cache manager for encryption related caches.
 * @hidden
 */
class EncryptionManager {
    constructor(encryptionKeyResolver, cacheTimeToLive) {
        this.cacheTimeToLive =
            cacheTimeToLive !== undefined
                ? cacheTimeToLive
                : Constants.DefaultEncryptionCacheTimeToLiveInSeconds;
        const cacheTtlInMs = this.getCacheTTlInMs();
        this.encryptionKeyStoreProvider = new EncryptionKeyStoreProvider(encryptionKeyResolver, cacheTtlInMs);
        this.protectedDataEncryptionKeyCache = new ProtectedDataEncryptionKeyCache(cacheTtlInMs);
        this.keyEncryptionKeyCache = new KeyEncryptionKeyCache();
        this.encryptionSettingsCache = new EncryptionSettingsCache();
        this.clientEncryptionKeyPropertiesCache = new ClientEncryptionKeyPropertiesCache();
    }
    /**
     * Converts the EncryptionTimeToLive instance to a number (milliseconds).
     */
    getCacheTTlInMs() {
        const millisecondsPerSecond = 1000;
        return Number(this.cacheTimeToLive * millisecondsPerSecond);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * @hidden
 * This internal class implements the logic for endpoint management for geo-replicated database accounts.
 */
class GlobalEndpointManager {
    /**
     * @param options - The document client instance.
     * @internal
     */
    constructor(options, readDatabaseAccount) {
        this.readDatabaseAccount = readDatabaseAccount;
        this.writeableLocations = [];
        this.readableLocations = [];
        this.unavailableReadableLocations = [];
        this.unavailableWriteableLocations = [];
        this.options = options;
        this.defaultEndpoint = options.endpoint;
        this.enableEndpointDiscovery = options.connectionPolicy.enableEndpointDiscovery;
        this.isRefreshing = false;
        this.preferredLocations = this.options.connectionPolicy.preferredLocations;
        this.preferredLocationsCount = this.preferredLocations ? this.preferredLocations.length : 0;
    }
    /**
     * Gets the current read endpoint from the endpoint cache.
     */
    async getReadEndpoint(diagnosticNode) {
        return this.resolveServiceEndpoint(diagnosticNode, exports.ResourceType.item, exports.OperationType.Read);
    }
    /**
     * Gets the current write endpoint from the endpoint cache.
     */
    async getWriteEndpoint(diagnosticNode) {
        return this.resolveServiceEndpoint(diagnosticNode, exports.ResourceType.item, exports.OperationType.Replace);
    }
    async getReadEndpoints() {
        return this.readableLocations.map((loc) => loc.databaseAccountEndpoint);
    }
    async getWriteEndpoints() {
        return this.writeableLocations.map((loc) => loc.databaseAccountEndpoint);
    }
    async markCurrentLocationUnavailableForRead(diagnosticNode, endpoint) {
        await this.refreshEndpointList(diagnosticNode);
        const location = this.readableLocations.find((loc) => loc.databaseAccountEndpoint === endpoint);
        if (location) {
            location.unavailable = true;
            location.lastUnavailabilityTimestampInMs = Date.now();
            this.unavailableReadableLocations.push(location);
        }
    }
    async markCurrentLocationUnavailableForWrite(diagnosticNode, endpoint) {
        await this.refreshEndpointList(diagnosticNode);
        const location = this.writeableLocations.find((loc) => loc.databaseAccountEndpoint === endpoint);
        if (location) {
            location.unavailable = true;
            location.lastUnavailabilityTimestampInMs = Date.now();
            this.unavailableWriteableLocations.push(location);
        }
    }
    canUseMultipleWriteLocations(resourceType, operationType) {
        let canUse = this.options.connectionPolicy.useMultipleWriteLocations;
        if (resourceType) {
            canUse =
                canUse &&
                    (resourceType === exports.ResourceType.item ||
                        (resourceType === exports.ResourceType.sproc && operationType === exports.OperationType.Execute));
        }
        return canUse;
    }
    async resolveServiceEndpoint(diagnosticNode, resourceType, operationType, startServiceEndpointIndex = 0) {
        // If endpoint discovery is disabled, always use the user provided endpoint
        if (!this.options.connectionPolicy.enableEndpointDiscovery) {
            diagnosticNode.addData({ readFromCache: true }, "default_endpoint");
            diagnosticNode.recordEndpointResolution(this.defaultEndpoint);
            return this.defaultEndpoint;
        }
        // If getting the database account, always use the user provided endpoint
        if (resourceType === exports.ResourceType.none) {
            diagnosticNode.addData({ readFromCache: true }, "none_resource");
            diagnosticNode.recordEndpointResolution(this.defaultEndpoint);
            return this.defaultEndpoint;
        }
        if (this.readableLocations.length === 0 || this.writeableLocations.length === 0) {
            const resourceResponse = await withMetadataDiagnostics(async (metadataNode) => {
                return this.readDatabaseAccount(metadataNode, {
                    urlConnection: this.defaultEndpoint,
                });
            }, diagnosticNode, exports.MetadataLookUpType.DatabaseAccountLookUp);
            this.writeableLocations = resourceResponse.resource.writableLocations;
            this.readableLocations = resourceResponse.resource.readableLocations;
        }
        const locations = isReadRequest(operationType)
            ? this.readableLocations
            : this.writeableLocations;
        let location;
        // If we have preferred locations, try each one in order and use the first available one
        if (this.preferredLocations &&
            this.preferredLocations.length > 0 &&
            startServiceEndpointIndex < this.preferredLocations.length) {
            for (let i = startServiceEndpointIndex; i < this.preferredLocations.length; i++) {
                const preferredLocation = this.preferredLocations[i];
                location = locations.find((loc) => loc.unavailable !== true &&
                    normalizeEndpoint(loc.name) === normalizeEndpoint(preferredLocation));
                if (location) {
                    break;
                }
            }
        }
        // If no preferred locations or one did not match, just grab the first one that is available
        if (!location) {
            const startIndexValid = startServiceEndpointIndex >= 0 && startServiceEndpointIndex < locations.length;
            const locationsToSearch = startIndexValid
                ? locations.slice(startServiceEndpointIndex)
                : locations;
            location = locationsToSearch.find((loc) => {
                return loc.unavailable !== true;
            });
        }
        location = location ? location : { name: "", databaseAccountEndpoint: this.defaultEndpoint };
        diagnosticNode.recordEndpointResolution(location.databaseAccountEndpoint);
        return location.databaseAccountEndpoint;
    }
    /**
     * Refreshes the endpoint list by clearning stale unavailability and then
     *  retrieving the writable and readable locations from the geo-replicated database account
     *  and then updating the locations cache.
     *  We skip the refreshing if enableEndpointDiscovery is set to False
     */
    async refreshEndpointList(diagnosticNode) {
        if (!this.isRefreshing && this.enableEndpointDiscovery) {
            this.isRefreshing = true;
            const databaseAccount = await this.getDatabaseAccountFromAnyEndpoint(diagnosticNode);
            if (databaseAccount) {
                this.refreshStaleUnavailableLocations();
                this.refreshEndpoints(databaseAccount);
            }
            this.isRefreshing = false;
        }
    }
    refreshEndpoints(databaseAccount) {
        for (const location of databaseAccount.writableLocations) {
            const existingLocation = this.writeableLocations.find((loc) => loc.name === location.name);
            if (!existingLocation) {
                this.writeableLocations.push(location);
            }
        }
        for (const location of databaseAccount.readableLocations) {
            const existingLocation = this.readableLocations.find((loc) => loc.name === location.name);
            if (!existingLocation) {
                this.readableLocations.push(location);
            }
        }
    }
    refreshStaleUnavailableLocations() {
        const now = Date.now();
        this.updateLocation(now, this.unavailableReadableLocations, this.readableLocations);
        this.unavailableReadableLocations = this.cleanUnavailableLocationList(now, this.unavailableReadableLocations);
        this.updateLocation(now, this.unavailableWriteableLocations, this.writeableLocations);
        this.unavailableWriteableLocations = this.cleanUnavailableLocationList(now, this.unavailableWriteableLocations);
    }
    /**
     * update the locationUnavailability to undefined if the location is available again
     * @param now - current time
     * @param unavailableLocations - list of unavailable locations
     * @param allLocations - list of all locations
     */
    updateLocation(now, unavailableLocations, allLocations) {
        for (const location of unavailableLocations) {
            const unavaialableLocation = allLocations.find((loc) => loc.name === location.name);
            if (unavaialableLocation &&
                now - unavaialableLocation.lastUnavailabilityTimestampInMs >
                    Constants.LocationUnavailableExpirationTimeInMs) {
                unavaialableLocation.unavailable = false;
            }
        }
    }
    cleanUnavailableLocationList(now, unavailableLocations) {
        return unavailableLocations.filter((loc) => {
            if (loc &&
                now - loc.lastUnavailabilityTimestampInMs >= Constants.LocationUnavailableExpirationTimeInMs) {
                return false;
            }
            return true;
        });
    }
    /**
     * Gets the database account first by using the default endpoint, and if that doesn't returns
     * use the endpoints for the preferred locations in the order they are specified to get
     * the database account.
     */
    async getDatabaseAccountFromAnyEndpoint(diagnosticNode) {
        try {
            const options = { urlConnection: this.defaultEndpoint };
            const { resource: databaseAccount } = await this.readDatabaseAccount(diagnosticNode, options);
            return databaseAccount;
            // If for any reason(non - globaldb related), we are not able to get the database
            // account from the above call to readDatabaseAccount,
            // we would try to get this information from any of the preferred locations that the user
            // might have specified (by creating a locational endpoint)
            // and keeping eating the exception until we get the database account and return None at the end,
            // if we are not able to get that info from any endpoints
        }
        catch (err) {
            // TODO: Tracing
        }
        if (this.preferredLocations) {
            for (const location of this.preferredLocations) {
                try {
                    const locationalEndpoint = GlobalEndpointManager.getLocationalEndpoint(this.defaultEndpoint, location);
                    const options = { urlConnection: locationalEndpoint };
                    const { resource: databaseAccount } = await this.readDatabaseAccount(diagnosticNode, options);
                    if (databaseAccount) {
                        return databaseAccount;
                    }
                }
                catch (err) {
                    // TODO: Tracing
                }
            }
        }
    }
    /**
     * Gets the locational endpoint using the location name passed to it using the default endpoint.
     *
     * @param defaultEndpoint - The default endpoint to use for the endpoint.
     * @param locationName    - The location name for the azure region like "East US".
     */
    static getLocationalEndpoint(defaultEndpoint, locationName) {
        // For defaultEndpoint like 'https://contoso.documents.azure.com:443/' parse it to generate URL format
        // This defaultEndpoint should be global endpoint(and cannot be a locational endpoint)
        // and we agreed to document that
        const endpointUrl = new URL(defaultEndpoint);
        // hostname attribute in endpointUrl will return 'contoso.documents.azure.com'
        if (endpointUrl.hostname) {
            const hostnameParts = endpointUrl.hostname.toString().toLowerCase().split(".");
            if (hostnameParts) {
                // globalDatabaseAccountName will return 'contoso'
                const globalDatabaseAccountName = hostnameParts[0];
                // Prepare the locationalDatabaseAccountName as contoso-EastUS for location_name 'East US'
                const locationalDatabaseAccountName = globalDatabaseAccountName + "-" + locationName.replace(" ", "");
                // Replace 'contoso' with 'contoso-EastUS' and
                // return locationalEndpoint as https://contoso-EastUS.documents.azure.com:443/
                const locationalEndpoint = defaultEndpoint
                    .toLowerCase()
                    .replace(globalDatabaseAccountName, locationalDatabaseAccountName);
                return locationalEndpoint;
            }
        }
        return null;
    }
}
function normalizeEndpoint(endpoint) {
    return endpoint.split(" ").join("").toLowerCase();
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Provides a client-side logical representation of the Azure Cosmos DB database account.
 * This client is used to configure and execute requests in the Azure Cosmos DB database service.
 * @example Instantiate a client and create a new database
 * ```typescript
 * const client = new CosmosClient({endpoint: "<URL HERE>", key: "<KEY HERE>"});
 * await client.databases.create({id: "<database name here>"});
 * ```
 * @example Instantiate a client with custom Connection Policy
 * ```typescript
 * const client = new CosmosClient({
 *    endpoint: "<URL HERE>",
 *    key: "<KEY HERE>",
 *    connectionPolicy: {
 *     requestTimeout: 10000,
 *    },
 * });
 * ```
 */
class CosmosClient {
    constructor(optionsOrConnectionString) {
        var _a, _b;
        if (typeof optionsOrConnectionString === "string") {
            optionsOrConnectionString = parseConnectionString(optionsOrConnectionString);
        }
        else if (optionsOrConnectionString.connectionString) {
            const { endpoint, key } = parseConnectionString(optionsOrConnectionString.connectionString);
            optionsOrConnectionString.endpoint = endpoint;
            optionsOrConnectionString.key = key;
        }
        const endpoint = checkURL(optionsOrConnectionString.endpoint);
        if (!endpoint) {
            throw new Error("Invalid endpoint specified");
        }
        if (optionsOrConnectionString.clientEncryptionOptions) {
            if (!optionsOrConnectionString.clientEncryptionOptions.keyEncryptionKeyResolver) {
                throw new Error("KeyEncryptionKeyResolver needs to be provided to enable client-side encryption.");
            }
            if (optionsOrConnectionString.clientEncryptionOptions.encryptionKeyTimeToLiveInSeconds &&
                optionsOrConnectionString.clientEncryptionOptions.encryptionKeyTimeToLiveInSeconds < 60) {
                throw new Error("EncryptionKeyTimeToLiveInSeconds needs to be >= 60 seconds.");
            }
            this.encryptionManager = new EncryptionManager(optionsOrConnectionString.clientEncryptionOptions.keyEncryptionKeyResolver, optionsOrConnectionString.clientEncryptionOptions.encryptionKeyTimeToLiveInSeconds);
        }
        const clientConfig = this.initializeClientConfigDiagnostic(optionsOrConnectionString);
        optionsOrConnectionString.connectionPolicy = Object.assign({}, defaultConnectionPolicy, optionsOrConnectionString.connectionPolicy);
        optionsOrConnectionString.defaultHeaders = optionsOrConnectionString.defaultHeaders || {};
        optionsOrConnectionString.defaultHeaders[Constants.HttpHeaders.CacheControl] = "no-cache";
        optionsOrConnectionString.defaultHeaders[Constants.HttpHeaders.Version] =
            Constants.CurrentVersion;
        if (optionsOrConnectionString.consistencyLevel !== undefined) {
            optionsOrConnectionString.defaultHeaders[Constants.HttpHeaders.ConsistencyLevel] =
                optionsOrConnectionString.consistencyLevel;
        }
        if (optionsOrConnectionString.throughputBucket !== undefined) {
            optionsOrConnectionString.defaultHeaders[Constants.HttpHeaders.ThroughputBucket] =
                optionsOrConnectionString.throughputBucket;
        }
        const userAgent = getUserAgent(optionsOrConnectionString.userAgentSuffix);
        optionsOrConnectionString.defaultHeaders[Constants.HttpHeaders.UserAgent] = userAgent;
        optionsOrConnectionString.defaultHeaders[Constants.HttpHeaders.CustomUserAgent] = userAgent;
        const globalEndpointManager = new GlobalEndpointManager(optionsOrConnectionString, async (diagnosticNode, opts) => this.getDatabaseAccountInternal(diagnosticNode, opts));
        this.clientContext = new ClientContext(optionsOrConnectionString, globalEndpointManager, clientConfig, determineDiagnosticLevel(optionsOrConnectionString.diagnosticLevel, getDiagnosticLevelFromEnvironment()));
        if (((_a = optionsOrConnectionString.connectionPolicy) === null || _a === void 0 ? void 0 : _a.enableEndpointDiscovery) &&
            ((_b = optionsOrConnectionString.connectionPolicy) === null || _b === void 0 ? void 0 : _b.enableBackgroundEndpointRefreshing)) {
            this.backgroundRefreshEndpointList(globalEndpointManager, optionsOrConnectionString.connectionPolicy.endpointRefreshRateInMs ||
                defaultConnectionPolicy.endpointRefreshRateInMs);
        }
        this.databases = new Databases(this, this.clientContext, this.encryptionManager);
        this.offers = new Offers(this, this.clientContext);
    }
    initializeClientConfigDiagnostic(optionsOrConnectionString) {
        return {
            endpoint: optionsOrConnectionString.endpoint,
            resourceTokensConfigured: optionsOrConnectionString.resourceTokens !== undefined,
            tokenProviderConfigured: optionsOrConnectionString.tokenProvider !== undefined,
            aadCredentialsConfigured: optionsOrConnectionString.aadCredentials !== undefined,
            connectionPolicyConfigured: optionsOrConnectionString.connectionPolicy !== undefined,
            consistencyLevel: optionsOrConnectionString.consistencyLevel,
            defaultHeaders: optionsOrConnectionString.defaultHeaders,
            agentConfigured: optionsOrConnectionString.agent !== undefined,
            userAgentSuffix: optionsOrConnectionString.userAgentSuffix,
            diagnosticLevel: optionsOrConnectionString.diagnosticLevel,
            pluginsConfigured: optionsOrConnectionString.plugins !== undefined,
            sDKVersion: Constants.SDKVersion,
        };
    }
    /**
     * Get information about the current {@link DatabaseAccount} (including which regions are supported, etc.)
     */
    async getDatabaseAccount(options) {
        return withDiagnostics(async (diagnosticNode) => {
            return this.getDatabaseAccountInternal(diagnosticNode, options);
        }, this.clientContext);
    }
    /**
     * @hidden
     */
    async getDatabaseAccountInternal(diagnosticNode, options) {
        const response = await this.clientContext.getDatabaseAccount(diagnosticNode, options);
        return new ResourceResponse(response.result, response.headers, response.code, getEmptyCosmosDiagnostics(), response.substatus);
    }
    /**
     * Gets the currently used write endpoint url. Useful for troubleshooting purposes.
     *
     * The url may contain a region suffix (e.g. "-eastus") if we're using location specific endpoints.
     */
    async getWriteEndpoint() {
        return withDiagnostics(async (diagnosticNode) => {
            return this.clientContext.getWriteEndpoint(diagnosticNode);
        }, this.clientContext);
    }
    /**
     * Gets the currently used read endpoint. Useful for troubleshooting purposes.
     *
     * The url may contain a region suffix (e.g. "-eastus") if we're using location specific endpoints.
     */
    async getReadEndpoint() {
        return withDiagnostics(async (diagnosticNode) => {
            return this.clientContext.getReadEndpoint(diagnosticNode);
        }, this.clientContext);
    }
    /**
     * Gets the known write endpoints. Useful for troubleshooting purposes.
     *
     * The urls may contain a region suffix (e.g. "-eastus") if we're using location specific endpoints.
     */
    getWriteEndpoints() {
        return this.clientContext.getWriteEndpoints();
    }
    /**
     * Gets the currently used read endpoint. Useful for troubleshooting purposes.
     *
     * The url may contain a region suffix (e.g. "-eastus") if we're using location specific endpoints.
     */
    getReadEndpoints() {
        return this.clientContext.getReadEndpoints();
    }
    /**
     * Used for reading, updating, or deleting a existing database by id or accessing containers belonging to that database.
     *
     * This does not make a network call. Use `.read` to get info about the database after getting the {@link Database} object.
     *
     * @param id - The id of the database.
     * @example Create a new container off of an existing database
     * ```typescript
     * const container = client.database("<database id>").containers.create("<container id>");
     * ```
     *
     * @example Delete an existing database
     * ```typescript
     * await client.database("<id here>").delete();
     * ```
     */
    database(id) {
        return new Database(this, id, this.clientContext, this.encryptionManager);
    }
    /**
     * Used for reading, or updating a existing offer by id.
     * @param id - The id of the offer.
     */
    offer(id) {
        return new Offer(this, id, this.clientContext);
    }
    /**
     * Clears background endpoint refresher. Use client.dispose() when destroying the CosmosClient within another process.
     */
    dispose() {
        clearTimeout(this.endpointRefresher);
        if (this.clientContext.enableEncryption) {
            clearTimeout(this.encryptionManager.encryptionKeyStoreProvider.cacheRefresher);
            clearTimeout(this.encryptionManager.protectedDataEncryptionKeyCache.cacheRefresher);
        }
    }
    async backgroundRefreshEndpointList(globalEndpointManager, refreshRate) {
        this.endpointRefresher = setInterval(() => {
            try {
                return withDiagnostics(async (diagnosticNode) => {
                    return globalEndpointManager.refreshEndpointList(diagnosticNode);
                }, this.clientContext, exports.DiagnosticNodeType.BACKGROUND_REFRESH_THREAD);
            }
            catch (e) {
                console.warn("Failed to refresh endpoints", e);
            }
        }, refreshRate);
        if (this.endpointRefresher.unref && typeof this.endpointRefresher.unref === "function") {
            this.endpointRefresher.unref();
        }
    }
    /**
     * Update the host framework. If provided host framework will be used to generate the defualt SDK user agent.
     * @param hostFramework - A custom string.
     * @internal
     */
    async updateHostFramework(hostFramework) {
        this.clientContext.refreshUserAgent(hostFramework);
    }
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
class SasTokenProperties {
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/// <reference lib="dom"/>
function encodeUTF8(str) {
    const bytes = new Uint8Array(str.length);
    for (let i = 0; i < str.length; i++) {
        bytes[i] = str.charCodeAt(i);
    }
    return bytes;
}

// Copyright (c) Microsoft Corporation.
// Licensed under the MIT License.
/**
 * Experimental internal only
 * Generates the payload representing the permission configuration for the sas token.
 */
async function createAuthorizationSasToken(masterKey, sasTokenProperties) {
    let resourcePrefixPath = "";
    if (typeof sasTokenProperties.databaseName === "string" &&
        sasTokenProperties.databaseName !== "") {
        resourcePrefixPath += `/${Constants.Path.DatabasesPathSegment}/${sasTokenProperties.databaseName}`;
    }
    if (typeof sasTokenProperties.containerName === "string" &&
        sasTokenProperties.containerName !== "") {
        if (sasTokenProperties.databaseName === "") {
            throw new Error(`illegalArgumentException : ${sasTokenProperties.databaseName} \
                          is an invalid database name`);
        }
        resourcePrefixPath += `/${Constants.Path.CollectionsPathSegment}/${sasTokenProperties.containerName}`;
    }
    if (typeof sasTokenProperties.resourceName === "string" &&
        sasTokenProperties.resourceName !== "") {
        if (sasTokenProperties.containerName === "") {
            throw new Error(`illegalArgumentException : ${sasTokenProperties.containerName} \
                          is an invalid container name`);
        }
        switch (sasTokenProperties.resourceKind) {
            case "ITEM":
                resourcePrefixPath += `${Constants.Path.Root}${Constants.Path.DocumentsPathSegment}`;
                break;
            case "STORED_PROCEDURE":
                resourcePrefixPath += `${Constants.Path.Root}${Constants.Path.StoredProceduresPathSegment}`;
                break;
            case "USER_DEFINED_FUNCTION":
                resourcePrefixPath += `${Constants.Path.Root}${Constants.Path.UserDefinedFunctionsPathSegment}`;
                break;
            case "TRIGGER":
                resourcePrefixPath += `${Constants.Path.Root}${Constants.Path.TriggersPathSegment}`;
                break;
            default:
                throw new Error(`illegalArgumentException : ${sasTokenProperties.resourceKind} \
                          is an invalid resource kind`);
        }
        resourcePrefixPath += `${Constants.Path.Root}${sasTokenProperties.resourceName}${Constants.Path.Root}`;
    }
    sasTokenProperties.resourcePath = resourcePrefixPath.toString();
    let partitionRanges = "";
    if (sasTokenProperties.partitionKeyValueRanges !== undefined &&
        sasTokenProperties.partitionKeyValueRanges.length > 0) {
        if (typeof sasTokenProperties.resourceKind !== "string" &&
            sasTokenProperties.resourceKind !== "ITEM") {
            throw new Error(`illegalArgumentException : ${sasTokenProperties.resourceKind} \
                          is an invalid partition key value range`);
        }
        sasTokenProperties.partitionKeyValueRanges.forEach((range) => {
            partitionRanges += `${encodeUTF8(range)},`;
        });
    }
    if (sasTokenProperties.controlPlaneReaderScope === 0) {
        sasTokenProperties.controlPlaneReaderScope += exports.SasTokenPermissionKind.ContainerReadAny;
        sasTokenProperties.controlPlaneWriterScope += exports.SasTokenPermissionKind.ContainerReadAny;
    }
    if (sasTokenProperties.dataPlaneReaderScope === 0 &&
        sasTokenProperties.dataPlaneWriterScope === 0) {
        sasTokenProperties.dataPlaneReaderScope = exports.SasTokenPermissionKind.ContainerFullAccess;
        sasTokenProperties.dataPlaneWriterScope = exports.SasTokenPermissionKind.ContainerFullAccess;
    }
    if (typeof sasTokenProperties.keyType !== "number" ||
        typeof sasTokenProperties.keyType === "undefined") {
        switch (sasTokenProperties.keyType) {
            case CosmosKeyType.PrimaryMaster:
                sasTokenProperties.keyType = 1;
                break;
            case CosmosKeyType.SecondaryMaster:
                sasTokenProperties.keyType = 2;
                break;
            case CosmosKeyType.PrimaryReadOnly:
                sasTokenProperties.keyType = 3;
                break;
            case CosmosKeyType.SecondaryReadOnly:
                sasTokenProperties.keyType = 4;
                break;
            default:
                throw new Error(`illegalArgumentException : ${sasTokenProperties.keyType} \
                          is an invalid key type`);
        }
    }
    const payload = sasTokenProperties.user +
        "\n" +
        sasTokenProperties.userTag +
        "\n" +
        sasTokenProperties.resourcePath +
        "\n" +
        partitionRanges +
        "\n" +
        utcsecondsSinceEpoch(sasTokenProperties.startTime).toString(16) +
        "\n" +
        utcsecondsSinceEpoch(sasTokenProperties.expiryTime).toString(16) +
        "\n" +
        sasTokenProperties.keyType +
        "\n" +
        sasTokenProperties.controlPlaneReaderScope.toString(16) +
        "\n" +
        sasTokenProperties.controlPlaneWriterScope.toString(16) +
        "\n" +
        sasTokenProperties.dataPlaneReaderScope.toString(16) +
        "\n" +
        sasTokenProperties.dataPlaneWriterScope.toString(16) +
        "\n";
    const signedPayload = await hmac(masterKey, Buffer.from(payload).toString("base64"));
    return "type=sas&ver=1.0&sig=" + signedPayload + ";" + Buffer.from(payload).toString("base64");
}
/**
 * @hidden
 */
// TODO: utcMilllisecondsSinceEpoch
function utcsecondsSinceEpoch(date) {
    return Math.round(date.getTime() / 1000);
}

Object.defineProperty(exports, "RestError", {
    enumerable: true,
    get: function () { return coreRestPipeline.RestError; }
});
Object.defineProperty(exports, "AbortError", {
    enumerable: true,
    get: function () { return abortController.AbortError; }
});
exports.AzureKeyVaultEncryptionKeyResolver = AzureKeyVaultEncryptionKeyResolver;
exports.BulkOperationType = BulkOperationType;
exports.ChangeFeedIterator = ChangeFeedIterator;
exports.ChangeFeedIteratorResponse = ChangeFeedIteratorResponse;
exports.ChangeFeedPolicy = ChangeFeedPolicy;
exports.ChangeFeedResponse = ChangeFeedResponse;
exports.ChangeFeedRetentionTimeSpan = ChangeFeedRetentionTimeSpan;
exports.ChangeFeedStartFrom = ChangeFeedStartFrom;
exports.ClientContext = ClientContext;
exports.ClientEncryptionKeyResponse = ClientEncryptionKeyResponse;
exports.ClientSideMetrics = ClientSideMetrics;
exports.Conflict = Conflict;
exports.ConflictResponse = ConflictResponse;
exports.Conflicts = Conflicts;
exports.Constants = Constants;
exports.Container = Container;
exports.ContainerResponse = ContainerResponse;
exports.Containers = Containers;
exports.CosmosClient = CosmosClient;
exports.CosmosDiagnostics = CosmosDiagnostics;
exports.DEFAULT_PARTITION_KEY_PATH = DEFAULT_PARTITION_KEY_PATH;
exports.Database = Database;
exports.DatabaseAccount = DatabaseAccount;
exports.DatabaseResponse = DatabaseResponse;
exports.Databases = Databases;
exports.DiagnosticNodeInternal = DiagnosticNodeInternal;
exports.EncryptionQueryBuilder = EncryptionQueryBuilder;
exports.ErrorResponse = ErrorResponse;
exports.FeedRange = FeedRange;
exports.FeedResponse = FeedResponse;
exports.GlobalEndpointManager = GlobalEndpointManager;
exports.Item = Item;
exports.ItemResponse = ItemResponse;
exports.Items = Items;
exports.Offer = Offer;
exports.OfferResponse = OfferResponse;
exports.Offers = Offers;
exports.PartitionKeyBuilder = PartitionKeyBuilder;
exports.PatchOperationType = PatchOperationType;
exports.Permission = Permission;
exports.PermissionResponse = PermissionResponse;
exports.Permissions = Permissions;
exports.QueryIterator = QueryIterator;
exports.QueryMetrics = QueryMetrics;
exports.QueryMetricsConstants = QueryMetricsConstants;
exports.QueryPreparationTimes = QueryPreparationTimes;
exports.ResourceResponse = ResourceResponse;
exports.RuntimeExecutionTimes = RuntimeExecutionTimes;
exports.SasTokenProperties = SasTokenProperties;
exports.Scripts = Scripts;
exports.StatusCodes = StatusCodes;
exports.StoredProcedure = StoredProcedure;
exports.StoredProcedureResponse = StoredProcedureResponse;
exports.StoredProcedures = StoredProcedures;
exports.TimeSpan = TimeSpan;
exports.TimeoutError = TimeoutError;
exports.Trigger = Trigger;
exports.TriggerResponse = TriggerResponse;
exports.Triggers = Triggers;
exports.User = User;
exports.UserDefinedFunction = UserDefinedFunction;
exports.UserDefinedFunctionResponse = UserDefinedFunctionResponse;
exports.UserDefinedFunctions = UserDefinedFunctions;
exports.UserResponse = UserResponse;
exports.Users = Users;
exports.createAuthorizationSasToken = createAuthorizationSasToken;
exports.setAuthorizationTokenHeaderUsingMasterKey = setAuthorizationTokenHeaderUsingMasterKey;
//# sourceMappingURL=index.js.map
